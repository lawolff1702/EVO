import torch
import random

class LinearModel:
    """
    A simple linear model for binary classification.
    """

    def __init__(self):
        self.w = None 


    def score(self, X):
        """
        Compute the scores for each data point in the feature matrix X. 
        The formula for the ith entry of s is s[i] = <self.w, x[i]>. 

        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. 

        ARGUMENTS: 
            X, torch.Tensor: the feature matrix. X.size() == (n, p), 
            where n is the number of data points and p is the 
            number of features. This implementation always assumes 
            that the final column of X is a constant column of 1s. 

        RETURNS: 
            s torch.Tensor: vector of scores. s.size() = (n,)
        """
        if self.w is None:
            self.w = torch.rand((X.size(1)))
        return X @ self.w

    def predict(self, X):
        """
        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. 

        ARGUMENTS: 
            X, torch.Tensor: the feature matrix. X.size() == (n, p), 
            where n is the number of data points and p is the 
            number of features. This implementation always assumes 
            that the final column of X is a constant column of 1s. 

        RETURNS: 
            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)
        """
        score = self.score(X)
        return (score > 0).float()
    
class LogisticRegression(LinearModel):
    """
    Logistic regression model for binary classification.
    Inherits from LinearModel.
    """
    def __init__(self):
        super().__init__()
        self.diversity_coeff = 0.0
        self.optimizer = None

    def set_optimizer(self, optimizer):
        """
        Set the optimizer for the logistic regression model.
        :param optimizer: An instance of an optimizer class.
        """
        self.optimizer = optimizer
    
    def set_diversity_coeff(self, diversity_coeff):
        """
        Set the diversity coefficient for the logistic regression model.
        :param diversity_coeff: A float value representing the diversity coefficient.
        """
        self.diversity_coeff = diversity_coeff

    def sigmoid(self, x):
        """
        Compute the sigmoid function for each element in x.
        """
        return 1 / (1 + torch.exp(-x))

    def loss(self, X, y, w=None):
        """
        Compute the binary cross-entropy loss for the logistic regression model.
        The loss is defined as:
        L(w) = -1/n * sum(y_i * log(sigmoid(X_i @ w)) + (1 - y_i) * log(1 - sigmoid(X_i @ w)))
        where n is the number of samples, X_i is the i-th sample, and y_i is the corresponding label.
        The loss is averaged over all samples.
        If w is not provided, the model's current weights are used.
        """
        if w is None:
            w = self.w
        w = w.to(X.device)  # âœ… Ensure same device

        preds = torch.clamp(self.sigmoid(X @ w), 1e-7, 1 - 1e-7)  # Avoid log(0)

        # Adding a term to penalize the model for low diversity in the population
        diversity_term = self.optimizer.average_pairwise_distance()

        return (-y * torch.log(preds) - (1 - y) * torch.log(1 - preds)).mean() - (self.diversity_coeff * diversity_term)

    
    def grad(self, X, y):
        """
        Compute the gradient of the loss function with respect to the weights w.
        The gradient is defined as:
        grad(w) = 1/n * sum((sigmoid(X_i @ w) - y_i) * X_i)
        where n is the number of samples, X_i is the i-th sample, and y_i is the corresponding label.
        The gradient is averaged over all samples.
        """
        sigmoid = self.sigmoid(self.score(X))
        grad = (sigmoid - y)[:, None] * X
        return grad.mean(0)
    

class DeepNeuralNetwork:
    def __init__(self, layer_dims):
        self.layer_dims = layer_dims
        self.diversity_coeff = 0.0
        self.optimizer = None
        self.curr_bce = None
        self.curr_diversity = None
        device = torch.device("cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu"))
        self.device = device

        self.shapes = []
        total_params = 0
        for i in range(len(layer_dims) - 1):
            in_dim = layer_dims[i]
            out_dim = layer_dims[i+1]
            self.shapes.append((in_dim, out_dim))
            total_params += in_dim * out_dim + out_dim

        self.w = torch.rand(total_params, device=self.device)

    def set_optimizer(self, optimizer):
        self.optimizer = optimizer
        

    def set_diversity_coeff(self, diversity_coeff):
        self.diversity_coeff = diversity_coeff

    def forward(self, X, w=None):
        if w is None:
            w = self.w
        offset = 0
        out = X
        for in_dim, out_dim in self.shapes[:-1]:
            W = w[offset:offset + in_dim * out_dim].view(in_dim, out_dim)
            offset += in_dim * out_dim
            b = w[offset:offset + out_dim]
            offset += out_dim
            out = torch.relu(out @ W + b)

        in_dim, out_dim = self.shapes[-1]
        W = w[offset:offset + in_dim * out_dim].view(in_dim, out_dim)
        offset += in_dim * out_dim
        b = w[offset:offset + out_dim]
        logits = out @ W + b
        return torch.sigmoid(logits).squeeze()

    def predict(self, X):
        with torch.no_grad():
            return (self.forward(X) > 0.5).float()

    def loss(self, X, y, w=None):
        if w is None:
            w = self.w
        preds = torch.clamp(self.forward(X, w), 1e-7, 1 - 1e-7)
        bce = (-y * torch.log(preds) - (1 - y) * torch.log(1 - preds)).mean()
        diversity_term = self.optimizer.average_pairwise_distance() if self.optimizer else 0
        self.curr_bce = bce.item()
        self.curr_diversity = diversity_term.item() * self.diversity_coeff
        return bce - self.diversity_coeff * diversity_term



import torch
import random
import heapq

class EvolutionOptimizer():
    """
    Evolutionary algorithm optimizer for the logistic regression model.
    This optimizer uses a population of individuals (weight vectors) and evolves
    them over generations.
    """
    def __init__(self, model):
        self.model = model
        self.population = []
        self.mutation_rate = 0.1
        self.diversity_coeff = 0.5
        self.model.set_diversity_coeff(self.diversity_coeff)
        self.population_size = 100
        self.mutation_intensity = 0.1
        # Device: default to CPU if no device is available.
        self.device = torch.device("cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu"))

    def set_mutation_rate(self, mutation_rate):
        self.mutation_rate = mutation_rate
    
    def set_mutation_intensity(self, mutation_intensity):
        self.mutation_intensity = mutation_intensity
    
    def set_population_size(self, population_size):
        self.population_size = population_size

    def set_diversity_coeff(self, diversity_coeff):
        self.diversity_coeff = diversity_coeff
        self.model.set_diversity_coeff(self.diversity_coeff)

    def average_pairwise_distance(self):
        n = len(self.population)
        if n < 2:
            return 0
        dists = [torch.norm(self.population[i] - self.population[j])
                for i in range(n) for j in range(i + 1, n)]
        return torch.stack(dists).mean()
    def average_cosine_dissimilarity(self):
        n = len(self.population)
        total = 0.0
        count = 0
        for i in range(n):
            for j in range(i+1, n):
                # Ensure non-zero norms
                norm_i = torch.norm(self.population[i])
                norm_j = torch.norm(self.population[j])
                if norm_i > 0 and norm_j > 0:
                    cos_sim = torch.dot(self.population[i], self.population[j]) / (norm_i * norm_j)
                else:
                    cos_sim = 0.0
                total += (1 - cos_sim)
                count += 1
        return total / count if count > 0 else 0

    def step(self, X, y):
        # Ensure X and y are on the target device.
        X = X.to(self.device)
        y = y.to(self.device)

        if len(self.population) == 0:
            # Initialize population with random weight vectors.
            self.population = [torch.rand(X.size(1), device=self.device) 
                            for _ in range(self.population_size)]

        # Build tuples containing (loss, unique_id, candidate) so that ties can be broken.
        pop_with_losses = [(self.model.loss(X, y, w).item(), i, w) 
                        for i, w in enumerate(self.population)]
        # Use heapq to extract the best half.
        best_half = [w for (_, _, w) in heapq.nsmallest(self.population_size // 2, pop_with_losses)]

        new_population = []
        # Generate new candidates using single-parent reproduction (with crossover)
        for _ in range(self.population_size): 
            parent1 = random.choice(best_half)
            parent2 = random.choice(best_half)

            # Inherit half from each parent
            mask = torch.rand_like(parent1) < 0.5
            child = torch.where(mask, parent1, parent2)

            mutation_mask = torch.rand_like(child) < self.mutation_rate
            # Specify device for mutation_values so it's created on the same device.
            mutation_values = torch.normal(mean=0.0, std=self.mutation_intensity,
                                        size=child.size(), device=self.device)
            child = torch.where(mutation_mask, child + mutation_values, child)

            new_population.append(child)

        self.population = new_population
        # Select the best individual from the new population using the same tie-breaker.
        pop_with_losses = [(self.model.loss(X, y, w).item(), i, w) 
                        for i, w in enumerate(new_population)]
        best = min(pop_with_losses, key=lambda tup: (tup[0], tup[1]))[2]
        self.model.w = best


    

class GradientDescentOptimizer():
    """
    Gradient descent optimizer for the logistic regression model.
    """
    def __init__(self, model):
        self.model = model
        self.prev_w = None  

    def step(self, X, y, alpha, beta):
        """
        Compute one step of the gradient descent update using the feature matrix X
        and target vector y.
        The update rule is:
        w_new = w_old - alpha * grad + beta * (w_old - w_prev)
        where alpha is the learning rate, beta is the momentum coefficient,
        grad is the gradient of the loss function, and w_prev is the previous weight vector.
        """
        grad = self.model.grad(X, y)

        if self.prev_w is None:
            self.prev_w = self.model.w.clone()

        momentum = beta * (self.model.w - self.prev_w)

        new_w = self.model.w - alpha * grad + momentum

        self.prev_w = self.model.w.clone()
        self.model.w = new_w


def average_pairwise_distance(population):
    n = len(population)
    total_dist = 0
    count = 0

    for i in range(n):
        for j in range(i + 1, n):
            dist = torch.norm(population[i] - population[j])
            total_dist += dist
            count += 1

    return total_dist / count if count > 0 else 0