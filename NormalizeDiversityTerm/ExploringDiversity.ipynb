{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from new_EVO import LogisticRegression, DeepNeuralNetwork, EvolutionOptimizer, GradientDescentOptimizer\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\"  if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will investigate how different diversity metrics can be used to evaluate and guide the evolution of weight vectors in an evolutionary optimization algorithm. Maintaining diversity in a population is important to avoid early convergence and ensuring a wide search of the solution space.\n",
    "\n",
    "I'll compare three key metrics:\n",
    "- Euclidean Distance: Average pairwise L2 distance between weight vectors.\n",
    "- Cosine Dissimilarity: Measures angular difference between vectors, emphasizing directional diversity.\n",
    "- Standard Deviation: Measures per-dimension spread across the population.\n",
    "\n",
    "Using a trained EvolutionOptimizer, I will:\n",
    "\n",
    "- Quantify diversity using these metrics at a given generation.\n",
    "- Visualize how these metrics compare.\n",
    "- Track how diversity evolves across multiple generations.\n",
    "\n",
    "This exploration will help us better understand which diversity metrics align with better performance and how they might influence future adaptations to the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Define a transform that converts images to a tensor and flattens them.\n",
    "transform = transforms.Compose([\n",
    "    # MNIST images are [1, 28, 28]\n",
    "    transforms.ToTensor(),\n",
    "    # Flatten to [784]\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Load the MNIST training and test sets.\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Build training tensors\n",
    "X_train = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "y_train = torch.tensor([float(train_dataset[i][1]) for i in range(len(train_dataset))], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Select random sample of 10000 images\n",
    "train_num_samples = 10000\n",
    "train_random_indices = torch.randperm(len(train_dataset))[:train_num_samples]\n",
    "\n",
    "subset = Subset(train_dataset, train_random_indices)\n",
    "X_train = torch.stack([subset[i][0] for i in range(len(subset))])\n",
    "y_train = torch.tensor([float(subset[i][1]) for i in range(len(subset))], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Build test tensors\n",
    "test_num_samples = 300\n",
    "test_random_indices = torch.randperm(len(test_dataset))[:test_num_samples]\n",
    "\n",
    "subset = Subset(test_dataset, test_random_indices)\n",
    "X_test = torch.stack([test_dataset[i][0] for i in range(len(test_dataset))])\n",
    "y_test = torch.tensor([float(test_dataset[i][1]) for i in range(len(test_dataset))], dtype=torch.long)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Binary to Multiclass Classification\n",
    "\n",
    "In prior versions of our source code, our DeepNeuralNetwork model used binary cross entropy loss because it was solving a binary classification - i.e. whether an MNIST image had a digit <= 4 or >4.\n",
    "\n",
    "Binary cross entropy works when there are two target values (like 0 and 1) and a classification model outputs a single score per input to aid in a classification, which we have usually normalized to a value between 0 and 1 using the sigmoid function.\n",
    "\n",
    "However, moving forward into this project, we are trying to solve multiclass classification problems. In other words, there are more than two possible target values.\n",
    "\n",
    "In the MNIST dataset, each handwritten image could be a digit from 0 to 9. As such, we need 10 possible classes - 0, 1, 2, 3... 9 - instead of just 2.\n",
    "\n",
    "For a multiclass problem, we can use Cross Entropy Loss. This is different from BCE as it accepts multiple output scores from the model (these are called logits).\n",
    "\n",
    "The Cross Entropy function automatically applies what is called a SoftMax function to the logits which it receives, which turns those logits into probabilities. It then can be used to compute the loss based on how much probability the model assigned to the correct class.\n",
    "\n",
    "In our DeepNeuralNetwork class, we currently used PyTorch's implementation of CrossEntropy - torch.nn.CrossEntropyLoss - to handle this.\n",
    "\n",
    "Below is an example of how to use CrossEntropyLoss for a multiclass problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "Imagine we have three images in our dataset,\n",
    "and had our model produce 10 logits for each image.\n",
    "\"\"\"\n",
    "\n",
    "logits_right = torch.tensor([\n",
    "    [2.0, 1.0, 0.1, -1.0, 3.0, 0.5, -0.5, 1.2, 2.2, 0.0],\n",
    "    [0.5, 2.2, 1.5, -0.5, 0.1, 3.0, 1.0, -1.0, 0.7, 2.5],\n",
    "    [1.0, 0.8, 2.0, 1.5, 0.2, 0.5, -0.2, 1.0, 2.5, 0.1]\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "From these logits, we can see that our model predicted image 1\n",
    "to be a 4, image 2 to be a 5, and image 3 to be an 8. This is\n",
    "because the highest logit value can be found at their corresponding\n",
    "indices in the logit lists.\n",
    "\n",
    "However, it did not do so with total confidence. In other words,\n",
    "the model predicted that there was a smaller but existing probability\n",
    "that each image could contain another image.\n",
    "\n",
    "So, let's see how that affects the Cross Entropy Loss\n",
    "\"\"\"\n",
    "labels = torch.tensor([4, 5, 8])\n",
    "\n",
    "# Create loss function obj for Cross Entropy\n",
    "CE = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute the loss\n",
    "loss_right = CE(logits_right, labels)\n",
    "\n",
    "print(f\"Cross Entropy Loss (Correct Classification): {loss_right.item():.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "But what if it made an incorrect prediction?\n",
    "\"\"\"\n",
    "\n",
    "logits_wrong = torch.tensor([\n",
    "    [2.0, 1.0, 0.1, -1.0, 1.5, 0.5, -0.5, 1.2, 2.2, 0.0],  # Image 1\n",
    "    [0.5, 2.2, 1.5, -0.5, 0.1, 2.5, 1.0, -1.0, 0.7, 3.0],  # Image 2\n",
    "    [1.0, 0.8, 2.0, 2.5, 0.2, 0.5, -0.2, 1.0, 2.0, 0.1]   # Image 3\n",
    "])\n",
    "\n",
    "loss_wrong = CE(logits_wrong, labels)\n",
    "\n",
    "print(f\"Cross Entropy Loss (Wrong Classification): {loss_wrong.item():.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "And now, what if the model's predictions were perfect?\n",
    "(i.e. the correct class logit is very positive, and very\n",
    "negative for all other classes)\n",
    "\"\"\"\n",
    "logits_perfect = torch.tensor([\n",
    "    [-10.0, -10.0, -10.0, -10.0, 1000.0, -10.0, -10.0, -10.0, -10.0, -10.0],  # Image 1\n",
    "    [-10.0, -10.0, -10.0, -10.0, -10.0, 1000.0, -10.0, -10.0, -10.0, -10.0],  # Image 2\n",
    "    [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 1000.0, -10.0]   # Image 3\n",
    "])\n",
    "\n",
    "loss_perfect = CE(logits_perfect, labels)\n",
    "\n",
    "print(f\"Cross Entropy Loss (Wrong Classification): {loss_perfect.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLAIN ABOVE EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Diversity Metrics: The Diversity Metrics We Chose in this Experiment\n",
    "\n",
    "### *In this section of our project, we implemented four different diversity metrics to help guide the evolutionary optimization process for our Deep Neural Network (DNN). We used diversity as a penalty/bonus in our loss function to encourage the weight vector population to stay varied, preventing premature convergance on a non-optimal weight vector solution, and promoting wide exploration of possible solutions. Below is an explanation of each metric and how it is implemented:*\n",
    "\n",
    "1. Euclidean Distance: Euclidean distance tells use the average \"straight-line\" distance between pairs of individuals in the population. In our case, this is done by computing the total distance - the square root of the sum of constituent pairwise distances - between each pair of vectors in the population. In our code, we do this by normalizing the difference between pairs of weight vectors in our population (`python torch.norm(weight_vector_i - weight_vector_j)) and then averaging that value for all weight vectors in the population. Higher output values for this metric represent that individuals are spread out in space - that they have diverse weights between them - and thus that they have a higher diversity.\n",
    "\n",
    "2. Cosine Dissimilarity: Cosine Dissimilarity tells us about the difference between weight vectors based on the angles of those vectors in space (not including magnitude). I implemented this by normalizing our vectors, to eliminate the effect of their magnitudes, and creating a matrix with all of our weight vectors. I then perform matrix multiplication between this matrix and its transpose, resulting in a matrix where each entry is the cosine similarity between two vectors (as the dot product of two normalized vectors is their cosine similarity). Then, we subtract this value from 1 for every entry in the matrix, and return the mean of this to get the average cosine dissimilarity for all vectors in our population. A high value here means that individual weight vectors point in different directions/have different angles in feature space.\n",
    "\n",
    "3. Standard Deviation: Standard deviation measures how spread out our weights are in each dimension, and then averaging this value out across all dimensions. In other words, it tells us how much variation there is across the population for each individual weight. If all weight vectors vary significantly in the same weight component, then the standard deviation will be large. It is a simple and computationally cheap approximation of diversity, and is implemented with the torch.std() function that calculates standard deviation across a tensor. A high standard deviation means we have more dispersed weights.\n",
    "\n",
    "4. Variance: Variance is similar to standard deviation in that is measures the spread of weights in our feature dimensions, but keeps the square value of the spread to emphasize larger differences. To clarify, variance is the square of standard deviation. Thus, while it similarly measures variation across each weight, it puts more emphasis on outliers. As such, variance can be more helpful in penalizing tight clustering than standard deviation. This is implemented by using torch.var() across a weight vector population, and then averaging this across all dimensions to calculate average variance. Again, high variance means high diversity.\n",
    "\n",
    "In our EvolutionOptimizer class, the diversity metric can dynamically be set using the set_diversity_metric() function. When we then compute diversity, the model automatically adjusts the loss function by abstractly calculating the diversity term (diversity_term = self.optimizer.compute_diversity()). In our model's loss function, we include this diversity term to introduce a diversity penalty - i.e. a less diverse population will result in higher loss - alongside traditional classification loss. Here is the key line of code which can be found in the source code:\n",
    "\n",
    "`return loss - (self.diversity_coeff * diversity_term)`\n",
    "\n",
    "In this code, `loss` is the actual loss which is calculated using the traditional Cross Entropy loss function from torch.nn. The `self.diversity_coeff` is a scalar indicates how strongly we reward high diversity - or really how much we punish low diversity. The `diversity_term` measures how spread our population is. This, when diversity is low, the diversity term is small and loss will be higher. If diversity is high, then more will be subtracted from loss, rewarding us with lower total loss. These will both be amplified by a higher diversity_coeff value. All of this encourages the optimizer to keep the populating diverse, promoting deeper exploration. Ultimately, this can be understood as a form of regularization which penalizes a lack of diversity rather than large weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Training Loops: How Diversity Metrix Impacts Model Performance/Training\n",
    "\n",
    "This section compares how different diversity metrics affect model performance during evolution-optimized DNN training. We will hold all parameters other than diversity metric constant, and track accuracy, cross-entropy loss (adjusted for diversity), and diversity values over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Function\n",
    "def run_diversity_experiment(diversity_metric,\n",
    "                            generations=200,\n",
    "                            population_size=30,\n",
    "                            mutation_rate=0.3,\n",
    "                            mutation_intensity=0.4,\n",
    "                            diversity_coeff=0.1,\n",
    "                            test_sample_size=300,\n",
    "                            ):\n",
    "    # Set up model and optimizer\n",
    "    layer_dimensions = [784, 64, 10]\n",
    "    DNN = DeepNeuralNetwork(layer_dimensions)\n",
    "    EVO_OPT = EvolutionOptimizer(DNN)\n",
    "    DNN.set_optimizer(EVO_OPT)\n",
    "    EVO_OPT.population = []\n",
    "\n",
    "    # Set Diversity Settings\n",
    "    EVO_OPT.set_population_size(population_size)\n",
    "    EVO_OPT.set_mutation_rate(mutation_rate)\n",
    "    EVO_OPT.set_mutation_intensity(mutation_intensity)\n",
    "    EVO_OPT.set_diversity_coeff(diversity_coeff)\n",
    "    EVO_OPT.set_diversity_metric(diversity_metric)\n",
    "    DNN.use_diversity_loss = True\n",
    "\n",
    "    # Set up performance/value tracking arrays\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    diversities = []\n",
    "\n",
    "    # Training Loop\n",
    "    for gen in range(generations + 1):\n",
    "        # Perform one step on population\n",
    "        print(f\"Generation {gen}/{generations}...\")\n",
    "        EVO_OPT.step(X_train, y_train)\n",
    "\n",
    "        # Evaluate current DNN state on Test Set\n",
    "        with torch.no_grad():\n",
    "            logits = DNN.forward(X_test[:test_sample_size])\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = (preds == y_test[:test_sample_size].to(DNN.device)).float().mean().item()\n",
    "\n",
    "        # Log every 10 generations\n",
    "        if gen % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                accuracies.append(acc * 100)\n",
    "                losses.append(DNN.curr_loss)\n",
    "                diversities.append(DNN.curr_diversity)\n",
    "        \n",
    "        if gen % 5 == 0:\n",
    "            gc.collect()\n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "    del DNN, EVO_OPT, logits, preds\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return (accuracies, losses, diversities)\n",
    "\n",
    "# Because not all diversity metrics produce values in same range, normalize them for comparison\n",
    "def normalize_diversities(diversities):\n",
    "    diversities_min = min(diversities)\n",
    "    diversities_max = max(diversities)\n",
    "    return [(x - diversities_min) / (diversities_max - diversities_min + 1e-8) for x in diversities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for All Metrics\n",
    "\n",
    "all_results = {}\n",
    "diversity_metrics = [\"euclidean\", \"cosine\", \"std\", \"variance\"]\n",
    "\n",
    "for metric in diversity_metrics:\n",
    "    print(f\"Running Baseline for {metric}\")\n",
    "    accuracies, losses, diversities = run_diversity_experiment(metric)\n",
    "    all_results[metric] = {\n",
    "        \"accuracies\": accuracies,\n",
    "        \"losses\": losses,\n",
    "        \"raw_diversities\": diversities,\n",
    "        \"normalized_diversities\": normalize_diversities(diversities)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set x-axis (generations every 10 steps)\n",
    "generations = [i * 10 for i in range(len(all_results[metric]['accuracies']))]\n",
    "metrics = list(all_results.keys())\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "for metric in metrics:\n",
    "    axs[0].plot(generations, all_results[metric]['accuracies'], label=metric)\n",
    "axs[0].set_title(\"Test Accuracy over Generations\")\n",
    "axs[0].set_xlabel(\"Generation\")\n",
    "axs[0].set_ylabel(\"Accuracy (%)\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot Cross-Entropy Loss\n",
    "for metric in metrics:\n",
    "    axs[1].plot(generations, all_results[metric]['losses'], label=metric)\n",
    "axs[1].set_title(\"Cross Entropy Loss over Generations\")\n",
    "axs[1].set_xlabel(\"Generation\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot Normalized Diversity\n",
    "for metric in metrics:\n",
    "    axs[2].plot(generations, all_results[metric]['normalized_diversities'], label=metric)\n",
    "axs[2].set_title(\"Normalized Diversity over Generations\")\n",
    "axs[2].set_xlabel(\"Generation\")\n",
    "axs[2].set_ylabel(\"Normalized Diversity (0â€“1)\")\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.suptitle(\"Diversity Metric Comparison in Evolutionary Training\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_parameter_results(metric, \n",
    "                              accuracies, \n",
    "                              losses, \n",
    "                              diversities,\n",
    "                              diversity_coeff, \n",
    "                              mutation_rate, \n",
    "                              mutation_intensity, \n",
    "                              population_size,  \n",
    "                              generations_logged=None\n",
    "                              ):\n",
    "    \n",
    "    if generations_logged is None:\n",
    "        generations_logged = list(range(0, len(accuracies) * 10, 10))\n",
    "    \n",
    "    print(f\"FINAL RESULTS\")\n",
    "    print(f\"  Final Accuracy:  {accuracies[-1]:.2f}%\")\n",
    "    print(f\"  Final Loss:      {losses[-1]:.4f}\")\n",
    "    print(f\"  Final Diversity: {diversities[-1]:.4f}\")\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    axs[0].plot(generations_logged, accuracies, marker='o')\n",
    "    axs[0].set_title(f\"Accuracy over Generations ({metric})\")\n",
    "    axs[0].set_xlabel(\"Generation\")\n",
    "    axs[0].set_ylabel(\"Accuracy (%)\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Losses Plot\n",
    "    axs[1].plot(generations_logged, losses, marker='x', color=\"red\")\n",
    "    axs[1].set_title(f\"Cross Entropy Loss ({metric})\")\n",
    "    axs[1].set_xlabel(\"Generation\")\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # Diversities Plot\n",
    "    axs[2].plot(generations_logged, diversities, marker='s', color=\"green\")\n",
    "    axs[2].set_title(f\"Diversity ({metric})\")\n",
    "    axs[2].set_xlabel(\"Generation\")\n",
    "    axs[2].set_ylabel(\"Diversity Value\")\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    plt.suptitle(f\"Results for Hyperparameter Experiment \"\n",
    "                 f\"Metric: {metric} | Diversity Coefficient: {diversity_coeff} | Mutation Rate: {mutation_rate} |\"\n",
    "                 f\"Mutation Intensity: {mutation_intensity} | Population Size: {population_size}\",\n",
    "                 fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 1: Baseline\")\n",
    "\n",
    "acc1, loss1, div1 = run_diversity_experiment(diversity_metric=\"cosine\",\n",
    "    diversity_coeff=0.1,\n",
    "    population_size=50,\n",
    "    mutation_rate=0.4,\n",
    "    mutation_intensity=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_parameter_results(\"cosine\", acc1, loss1, div1, 0.1, 0.4, 0.5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 2: No Diversity Reward\")\n",
    "\n",
    "acc2, loss2, div2 = run_diversity_experiment(\n",
    "    diversity_metric=\"cosine\",\n",
    "    diversity_coeff=0.0,\n",
    "    population_size=50,\n",
    "    mutation_rate=0.4,\n",
    "    mutation_intensity=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_parameter_results(\"cosine\", acc2, loss2, div2, 0.0, 0.4, 0.5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 3: Larger Population\")\n",
    "\n",
    "acc3, loss3, div3 = run_diversity_experiment(\n",
    "    diversity_metric=\"cosine\",\n",
    "    diversity_coeff=0.1,\n",
    "    population_size=100,\n",
    "    mutation_rate=0.4,\n",
    "    mutation_intensity=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_parameter_results(\"cosine\", acc2, loss2, div2, 0.1, 0.4, 0.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 4: Stronger Diversity Penalty\")\n",
    "\n",
    "acc4, loss4, div4 = run_diversity_experiment(\n",
    "    diversity_metric=\"cosine\",\n",
    "    diversity_coeff=0.3,\n",
    "    population_size=50,\n",
    "    mutation_rate=0.4,\n",
    "    mutation_intensity=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_parameter_results(\"cosine\", acc2, loss2, div2, 0.3, 0.4, 0.5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment 5: High Mutation\")\n",
    "\n",
    "acc5, loss5, div5 = run_diversity_experiment(\n",
    "    diversity_metric=\"cosine\",\n",
    "    diversity_coeff=0.1,\n",
    "    population_size=50,\n",
    "    mutation_rate=0.7,\n",
    "    mutation_intensity=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_parameter_results(\"cosine\", acc2, loss2, div2, 0.1, 0.7, 0.8, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
