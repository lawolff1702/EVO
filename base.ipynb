{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee01e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ac1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "from EVO import LogisticRegression, EvolutionOptimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139e65d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_exp shape: torch.Size([60000, 7850])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a transform that converts images to a tensor and flattens them.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                    # MNIST images are [1, 28, 28]\n",
    "    transforms.Lambda(lambda x: x.view(-1))     # Flatten to [784]\n",
    "])\n",
    "\n",
    "# Load the MNIST training and test sets.\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def add_bias(X):\n",
    "    # X is of shape (N, 784), append a column of ones to yield shape (N, 785)\n",
    "    N = X.size(0)\n",
    "    bias = torch.ones(N, 1)\n",
    "    return torch.cat([X, bias], dim=1)\n",
    "\n",
    "# Build full training tensors.\n",
    "X_train = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "X_train = add_bias(X_train)  # Now shape: (N_train, 785)\n",
    "y_train = torch.tensor([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "\n",
    "# Build full test tensors.\n",
    "X_test = torch.stack([test_dataset[i][0] for i in range(len(test_dataset))])\n",
    "X_test = add_bias(X_test)   # Now shape: (N_test, 785)\n",
    "y_test = torch.tensor([test_dataset[i][1] for i in range(len(test_dataset))])\n",
    "\n",
    "def expand_features(X, num_classes=10):\n",
    "    \"\"\"\n",
    "    Expand features from shape (N, d) to (N, d * num_classes) by forming blocks.\n",
    "    Here we multiply each block by a unique constant so that each block is distinct.\n",
    "    \"\"\"\n",
    "    N, d = X.shape\n",
    "    blocks = []\n",
    "    for c in range(num_classes):\n",
    "        # Multiply the original features by (c+1)\n",
    "        blocks.append( (c+1) * X )\n",
    "    return torch.cat(blocks, dim=1)\n",
    "\n",
    "# Expand the feature matrices so that each sample now has 7850 features.\n",
    "X_train_exp = expand_features(X_train, num_classes=10)  # shape: (N_train, 7850)\n",
    "X_test_exp  = expand_features(X_test, num_classes=10)   # shape: (N_test, 7850)\n",
    "\n",
    "# (Optional) Visualize one original image.\n",
    "img = X_train[0][:-1].view(28, 28)  # exclude bias from visualization\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"True Label: {y_train[0].item()}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"X_train_exp shape:\", X_train_exp.shape)  # Should be (N_train, 7850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d92d31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiClassLogisticRegressionWrapper:\n",
    "    def __init__(self, input_dim=785, num_classes=10, device=torch.device(\"cpu\")):\n",
    "        \"\"\"\n",
    "        :param input_dim: the original feature dimension (e.g. 785 = 784 pixels + bias)\n",
    "        :param num_classes: number of classes (e.g. 10 for MNIST)\n",
    "        :param device: device on which to perform computations (e.g. mps, cuda, or cpu)\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.w = None  # This will be a flat weight vector of length input_dim * num_classes.\n",
    "        self.population = []  # For the evolutionary optimizer\n",
    "\n",
    "    def score_with(self, X_exp, w):\n",
    "        \"\"\"\n",
    "        Compute the per-class scores using candidate weight vector w.\n",
    "        :param X_exp: Expanded feature matrix of shape (N, input_dim * num_classes)\n",
    "        :param w: Candidate flat weight vector of shape (input_dim * num_classes,)\n",
    "        :return: Tensor of scores of shape (N, num_classes)\n",
    "        \"\"\"\n",
    "        # Move X_exp to the proper device.\n",
    "        X_exp = X_exp.to(self.device)\n",
    "        # Reshape candidate weight vector into a (input_dim, num_classes) matrix.\n",
    "        W = w.view(self.input_dim, self.num_classes)\n",
    "        N = X_exp.size(0)\n",
    "        # Reshape X_exp into (N, num_classes, input_dim). That is, each sample has num_classes blocks.\n",
    "        X_chunks = X_exp.view(N, self.num_classes, self.input_dim)\n",
    "        scores = []\n",
    "        for c in range(self.num_classes):\n",
    "            X_c = X_chunks[:, c, :]    # shape: (N, input_dim)\n",
    "            W_c = W[:, c]              # shape: (input_dim,)\n",
    "            # Compute the inner product for class c.\n",
    "            score_c = (X_c * W_c).sum(dim=1)  # (N,)\n",
    "            scores.append(score_c)\n",
    "        # Stack scores to form (N, num_classes)\n",
    "        return torch.stack(scores, dim=1)\n",
    "\n",
    "    def score(self, X_exp):\n",
    "        \"\"\"\n",
    "        Compute scores using the currently stored weight vector (self.w).\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            # Initialize self.w if not yet initialized.\n",
    "            self.w = torch.rand(self.input_dim * self.num_classes, device=self.device)\n",
    "        return self.score_with(X_exp, self.w)\n",
    "\n",
    "    def predict(self, X_exp):\n",
    "        \"\"\"\n",
    "        Predict the class (as an integer between 0 and num_classes-1)\n",
    "        \"\"\"\n",
    "        scores = self.score(X_exp)\n",
    "        return torch.argmax(scores, dim=1)\n",
    "\n",
    "    def loss(self, X_exp, y, w=None, diversity_weight=0.5):\n",
    "        \"\"\"\n",
    "        Compute the cross-entropy loss for candidate weight vector w (or self.w if w is None),\n",
    "        using the expanded feature matrix X_exp and the integer label vector y.\n",
    "        Additionally, add a diversity term to encourage diverse solutions.\n",
    "        :param diversity_weight: Weight for the diversity term in the loss.\n",
    "        \"\"\"\n",
    "        if w is None:\n",
    "            w = self.w\n",
    "        # Ensure the candidate is on the correct device.\n",
    "        w = w.to(self.device)\n",
    "        # Compute scores using the candidate w.\n",
    "        scores = self.score_with(X_exp, w)\n",
    "        ce_loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        # Compute diversity term based on pairwise distances in the population.\n",
    "        diversity_term = 0\n",
    "        if self.population:\n",
    "            for candidate in self.population:\n",
    "                diversity_term += torch.norm(w - candidate)\n",
    "            diversity_term /= len(self.population)\n",
    "\n",
    "        # Combine cross-entropy loss with diversity term.\n",
    "        total_loss = ce_loss - diversity_weight * diversity_term\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9c5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Epoch 01: Loss = 194.6558, Training Accuracy = 11.09%\n",
      "Epoch 02: Loss = 211.5122, Training Accuracy = 12.08%\n",
      "Epoch 03: Loss = 217.3628, Training Accuracy = 11.76%\n",
      "Epoch 04: Loss = 206.1252, Training Accuracy = 11.12%\n",
      "Epoch 05: Loss = 224.4288, Training Accuracy = 13.36%\n",
      "Epoch 06: Loss = 222.8795, Training Accuracy = 10.56%\n",
      "Epoch 07: Loss = 231.4462, Training Accuracy = 12.18%\n",
      "Epoch 08: Loss = 226.9002, Training Accuracy = 11.26%\n",
      "Epoch 09: Loss = 239.5161, Training Accuracy = 9.27%\n",
      "Epoch 10: Loss = 248.2211, Training Accuracy = 10.15%\n",
      "Epoch 11: Loss = 245.6895, Training Accuracy = 11.46%\n",
      "Epoch 12: Loss = 259.1178, Training Accuracy = 8.60%\n",
      "Epoch 13: Loss = 252.5709, Training Accuracy = 9.12%\n",
      "Epoch 14: Loss = 255.2487, Training Accuracy = 10.88%\n",
      "Epoch 15: Loss = 239.6623, Training Accuracy = 9.68%\n",
      "Epoch 16: Loss = 257.1241, Training Accuracy = 10.40%\n",
      "Epoch 17: Loss = 257.0001, Training Accuracy = 12.80%\n",
      "Epoch 18: Loss = 260.1583, Training Accuracy = 9.74%\n",
      "Epoch 19: Loss = 263.0589, Training Accuracy = 12.39%\n",
      "Epoch 20: Loss = 272.4787, Training Accuracy = 14.69%\n",
      "Epoch 21: Loss = 273.6218, Training Accuracy = 9.54%\n",
      "Epoch 22: Loss = 268.8105, Training Accuracy = 10.45%\n",
      "Epoch 23: Loss = 262.0297, Training Accuracy = 11.16%\n",
      "Epoch 24: Loss = 263.7150, Training Accuracy = 11.10%\n",
      "Epoch 25: Loss = 260.5540, Training Accuracy = 16.98%\n",
      "Epoch 26: Loss = 270.7638, Training Accuracy = 15.91%\n",
      "Epoch 27: Loss = 261.1159, Training Accuracy = 19.98%\n",
      "Epoch 28: Loss = 253.3955, Training Accuracy = 20.67%\n",
      "Epoch 29: Loss = 251.0036, Training Accuracy = 22.02%\n",
      "Epoch 30: Loss = 257.9463, Training Accuracy = 21.15%\n",
      "Epoch 31: Loss = 250.0438, Training Accuracy = 23.87%\n",
      "Epoch 32: Loss = 259.5003, Training Accuracy = 24.07%\n",
      "Epoch 33: Loss = 259.1061, Training Accuracy = 22.89%\n",
      "Epoch 34: Loss = 251.9814, Training Accuracy = 22.07%\n",
      "Epoch 35: Loss = 260.2309, Training Accuracy = 20.50%\n",
      "Epoch 36: Loss = 262.6116, Training Accuracy = 18.61%\n",
      "Epoch 37: Loss = 262.3758, Training Accuracy = 25.47%\n",
      "Epoch 38: Loss = 261.6156, Training Accuracy = 19.31%\n",
      "Epoch 39: Loss = 265.6575, Training Accuracy = 19.72%\n",
      "Epoch 40: Loss = 269.7855, Training Accuracy = 19.64%\n",
      "Epoch 41: Loss = 269.4764, Training Accuracy = 19.64%\n",
      "Epoch 42: Loss = 272.8239, Training Accuracy = 20.33%\n",
      "Epoch 43: Loss = 272.1317, Training Accuracy = 20.50%\n",
      "Epoch 44: Loss = 262.1723, Training Accuracy = 22.24%\n",
      "Epoch 45: Loss = 272.2392, Training Accuracy = 20.31%\n",
      "Epoch 46: Loss = 267.0581, Training Accuracy = 21.43%\n",
      "Epoch 47: Loss = 263.3197, Training Accuracy = 21.92%\n",
      "Epoch 48: Loss = 260.5484, Training Accuracy = 21.98%\n",
      "Epoch 49: Loss = 257.6477, Training Accuracy = 22.89%\n",
      "Epoch 50: Loss = 258.6834, Training Accuracy = 23.14%\n",
      "Epoch 51: Loss = 251.7340, Training Accuracy = 24.56%\n",
      "Epoch 52: Loss = 254.9819, Training Accuracy = 25.80%\n",
      "Epoch 53: Loss = 253.4280, Training Accuracy = 24.99%\n",
      "Epoch 54: Loss = 250.6348, Training Accuracy = 27.20%\n",
      "Epoch 55: Loss = 253.8892, Training Accuracy = 27.69%\n",
      "Epoch 56: Loss = 252.4162, Training Accuracy = 26.21%\n",
      "Epoch 57: Loss = 256.1096, Training Accuracy = 26.88%\n",
      "Epoch 58: Loss = 258.6613, Training Accuracy = 25.29%\n",
      "Epoch 59: Loss = 258.0391, Training Accuracy = 25.19%\n",
      "Epoch 60: Loss = 252.3396, Training Accuracy = 30.02%\n",
      "Epoch 61: Loss = 246.9163, Training Accuracy = 30.54%\n",
      "Epoch 62: Loss = 245.5893, Training Accuracy = 29.84%\n",
      "Epoch 63: Loss = 248.0903, Training Accuracy = 31.49%\n",
      "Epoch 64: Loss = 247.8336, Training Accuracy = 32.76%\n",
      "Epoch 65: Loss = 248.1662, Training Accuracy = 32.38%\n",
      "Epoch 66: Loss = 245.2377, Training Accuracy = 31.62%\n",
      "Epoch 67: Loss = 246.1208, Training Accuracy = 31.33%\n",
      "Epoch 68: Loss = 242.0359, Training Accuracy = 32.48%\n",
      "Epoch 69: Loss = 237.2686, Training Accuracy = 32.21%\n",
      "Epoch 70: Loss = 240.1927, Training Accuracy = 31.88%\n",
      "Epoch 71: Loss = 239.9511, Training Accuracy = 31.71%\n",
      "Epoch 72: Loss = 246.2930, Training Accuracy = 32.28%\n",
      "Epoch 73: Loss = 246.4962, Training Accuracy = 31.57%\n",
      "Epoch 74: Loss = 251.2601, Training Accuracy = 34.95%\n",
      "Epoch 75: Loss = 247.8507, Training Accuracy = 32.18%\n",
      "Epoch 76: Loss = 252.6588, Training Accuracy = 30.47%\n",
      "Epoch 77: Loss = 252.2014, Training Accuracy = 31.84%\n",
      "Epoch 78: Loss = 249.1560, Training Accuracy = 30.52%\n",
      "Epoch 79: Loss = 250.5603, Training Accuracy = 31.67%\n",
      "Epoch 80: Loss = 248.7405, Training Accuracy = 35.82%\n",
      "Epoch 81: Loss = 248.9913, Training Accuracy = 35.70%\n",
      "Epoch 82: Loss = 251.9691, Training Accuracy = 32.28%\n",
      "Epoch 83: Loss = 252.9122, Training Accuracy = 32.07%\n",
      "Epoch 84: Loss = 256.5745, Training Accuracy = 33.16%\n",
      "Epoch 85: Loss = 258.3230, Training Accuracy = 28.73%\n",
      "Epoch 86: Loss = 258.9494, Training Accuracy = 34.04%\n",
      "Epoch 87: Loss = 258.5785, Training Accuracy = 34.85%\n",
      "Epoch 88: Loss = 258.5767, Training Accuracy = 32.91%\n",
      "Epoch 89: Loss = 255.9443, Training Accuracy = 34.83%\n",
      "Epoch 90: Loss = 255.7475, Training Accuracy = 35.23%\n",
      "Epoch 91: Loss = 257.0233, Training Accuracy = 35.36%\n",
      "Epoch 92: Loss = 257.6455, Training Accuracy = 34.66%\n",
      "Epoch 93: Loss = 256.8599, Training Accuracy = 34.53%\n",
      "Epoch 94: Loss = 256.8417, Training Accuracy = 35.27%\n",
      "Epoch 95: Loss = 257.9011, Training Accuracy = 34.65%\n",
      "Epoch 96: Loss = 255.9512, Training Accuracy = 35.32%\n",
      "Epoch 97: Loss = 259.8912, Training Accuracy = 35.76%\n",
      "Epoch 98: Loss = 258.1709, Training Accuracy = 34.55%\n",
      "Epoch 99: Loss = 256.5362, Training Accuracy = 35.32%\n",
      "Epoch 100: Loss = 256.3313, Training Accuracy = 34.86%\n",
      "Epoch 101: Loss = 257.3911, Training Accuracy = 35.44%\n",
      "Epoch 102: Loss = 257.6074, Training Accuracy = 36.14%\n",
      "Epoch 103: Loss = 256.0332, Training Accuracy = 36.54%\n",
      "Epoch 104: Loss = 257.9573, Training Accuracy = 36.32%\n",
      "Epoch 105: Loss = 259.5306, Training Accuracy = 35.72%\n",
      "Epoch 106: Loss = 258.1446, Training Accuracy = 35.70%\n",
      "Epoch 107: Loss = 257.9828, Training Accuracy = 35.16%\n",
      "Epoch 108: Loss = 255.2379, Training Accuracy = 36.00%\n",
      "Epoch 109: Loss = 257.2016, Training Accuracy = 35.89%\n",
      "Epoch 110: Loss = 260.6393, Training Accuracy = 35.26%\n",
      "Epoch 111: Loss = 260.2840, Training Accuracy = 36.49%\n",
      "Epoch 112: Loss = 259.6682, Training Accuracy = 35.28%\n",
      "Epoch 113: Loss = 258.2264, Training Accuracy = 36.53%\n",
      "Epoch 114: Loss = 255.7132, Training Accuracy = 36.04%\n",
      "Epoch 115: Loss = 251.7260, Training Accuracy = 36.90%\n",
      "Epoch 116: Loss = 256.3885, Training Accuracy = 36.39%\n",
      "Epoch 117: Loss = 260.5587, Training Accuracy = 36.76%\n",
      "Epoch 118: Loss = 258.8151, Training Accuracy = 37.04%\n",
      "Epoch 119: Loss = 256.8399, Training Accuracy = 37.04%\n",
      "Epoch 120: Loss = 257.1382, Training Accuracy = 37.35%\n",
      "Epoch 121: Loss = 258.7231, Training Accuracy = 36.96%\n",
      "Epoch 122: Loss = 265.2475, Training Accuracy = 36.47%\n",
      "Epoch 123: Loss = 264.0976, Training Accuracy = 36.32%\n",
      "Epoch 124: Loss = 261.1823, Training Accuracy = 36.84%\n",
      "Epoch 125: Loss = 261.5718, Training Accuracy = 36.14%\n",
      "Epoch 126: Loss = 259.3398, Training Accuracy = 35.81%\n",
      "Epoch 127: Loss = 256.3086, Training Accuracy = 35.33%\n",
      "Epoch 128: Loss = 257.8416, Training Accuracy = 35.84%\n",
      "Epoch 129: Loss = 259.2778, Training Accuracy = 37.45%\n",
      "Epoch 130: Loss = 255.1249, Training Accuracy = 36.99%\n",
      "Epoch 131: Loss = 256.9110, Training Accuracy = 34.56%\n",
      "Epoch 132: Loss = 256.4452, Training Accuracy = 34.28%\n",
      "Epoch 133: Loss = 256.0068, Training Accuracy = 36.00%\n",
      "Epoch 134: Loss = 258.7752, Training Accuracy = 38.69%\n",
      "Epoch 135: Loss = 256.1611, Training Accuracy = 38.78%\n",
      "Epoch 136: Loss = 252.2861, Training Accuracy = 39.02%\n",
      "Epoch 137: Loss = 253.9294, Training Accuracy = 39.56%\n",
      "Epoch 138: Loss = 255.7554, Training Accuracy = 39.12%\n",
      "Epoch 139: Loss = 255.0064, Training Accuracy = 38.57%\n",
      "Epoch 140: Loss = 250.9220, Training Accuracy = 39.93%\n",
      "Epoch 141: Loss = 248.1668, Training Accuracy = 40.72%\n",
      "Epoch 142: Loss = 252.4910, Training Accuracy = 40.37%\n",
      "Epoch 143: Loss = 250.2810, Training Accuracy = 40.68%\n",
      "Epoch 144: Loss = 250.9523, Training Accuracy = 40.83%\n",
      "Epoch 145: Loss = 250.8905, Training Accuracy = 40.64%\n",
      "Epoch 146: Loss = 250.9766, Training Accuracy = 39.93%\n",
      "Epoch 147: Loss = 249.0639, Training Accuracy = 39.88%\n",
      "Epoch 148: Loss = 248.5607, Training Accuracy = 40.44%\n",
      "Epoch 149: Loss = 249.7908, Training Accuracy = 42.09%\n",
      "Epoch 150: Loss = 247.9469, Training Accuracy = 41.74%\n",
      "Epoch 151: Loss = 247.0031, Training Accuracy = 42.24%\n",
      "Epoch 152: Loss = 247.8143, Training Accuracy = 42.43%\n",
      "Epoch 153: Loss = 250.4380, Training Accuracy = 43.07%\n",
      "Epoch 154: Loss = 249.1550, Training Accuracy = 41.33%\n",
      "Epoch 155: Loss = 243.9702, Training Accuracy = 42.80%\n",
      "Epoch 156: Loss = 245.2913, Training Accuracy = 43.06%\n",
      "Epoch 157: Loss = 243.3991, Training Accuracy = 41.83%\n",
      "Epoch 158: Loss = 245.2143, Training Accuracy = 44.16%\n",
      "Epoch 159: Loss = 247.4842, Training Accuracy = 42.19%\n",
      "Epoch 160: Loss = 249.8534, Training Accuracy = 41.58%\n",
      "Epoch 161: Loss = 250.8511, Training Accuracy = 41.99%\n",
      "Epoch 162: Loss = 247.0833, Training Accuracy = 42.61%\n",
      "Epoch 163: Loss = 251.4185, Training Accuracy = 42.63%\n",
      "Epoch 164: Loss = 245.7442, Training Accuracy = 42.79%\n",
      "Epoch 165: Loss = 247.7859, Training Accuracy = 42.41%\n",
      "Epoch 166: Loss = 247.9452, Training Accuracy = 42.78%\n",
      "Epoch 167: Loss = 252.2931, Training Accuracy = 41.90%\n",
      "Epoch 168: Loss = 251.3254, Training Accuracy = 41.33%\n",
      "Epoch 169: Loss = 248.2310, Training Accuracy = 41.84%\n",
      "Epoch 170: Loss = 247.3954, Training Accuracy = 42.65%\n",
      "Epoch 171: Loss = 246.2041, Training Accuracy = 42.46%\n",
      "Epoch 172: Loss = 251.9967, Training Accuracy = 41.57%\n",
      "Epoch 173: Loss = 245.5667, Training Accuracy = 41.46%\n",
      "Epoch 174: Loss = 245.0029, Training Accuracy = 41.18%\n",
      "Epoch 175: Loss = 247.4894, Training Accuracy = 41.50%\n",
      "Epoch 176: Loss = 249.7747, Training Accuracy = 40.92%\n",
      "Epoch 177: Loss = 252.6515, Training Accuracy = 40.50%\n",
      "Epoch 178: Loss = 253.3664, Training Accuracy = 41.84%\n",
      "Epoch 179: Loss = 256.9684, Training Accuracy = 41.00%\n",
      "Epoch 180: Loss = 257.4911, Training Accuracy = 43.34%\n",
      "Epoch 181: Loss = 255.6799, Training Accuracy = 41.55%\n",
      "Epoch 182: Loss = 254.5615, Training Accuracy = 40.26%\n",
      "Epoch 183: Loss = 257.1465, Training Accuracy = 39.51%\n",
      "Epoch 184: Loss = 255.8461, Training Accuracy = 41.91%\n",
      "Epoch 185: Loss = 253.5334, Training Accuracy = 42.42%\n",
      "Epoch 186: Loss = 254.5045, Training Accuracy = 41.43%\n",
      "Epoch 187: Loss = 255.5847, Training Accuracy = 41.60%\n",
      "Epoch 188: Loss = 253.7022, Training Accuracy = 41.14%\n",
      "Epoch 189: Loss = 251.7756, Training Accuracy = 44.71%\n",
      "Epoch 190: Loss = 250.4968, Training Accuracy = 45.01%\n",
      "Epoch 191: Loss = 254.3360, Training Accuracy = 44.35%\n",
      "Epoch 192: Loss = 254.5847, Training Accuracy = 44.08%\n",
      "Epoch 193: Loss = 252.6795, Training Accuracy = 44.02%\n",
      "Epoch 194: Loss = 251.9074, Training Accuracy = 45.88%\n",
      "Epoch 195: Loss = 252.3475, Training Accuracy = 46.05%\n",
      "Epoch 196: Loss = 250.0777, Training Accuracy = 45.13%\n",
      "Epoch 197: Loss = 254.0283, Training Accuracy = 45.01%\n",
      "Epoch 198: Loss = 254.6308, Training Accuracy = 44.93%\n",
      "Epoch 199: Loss = 255.8191, Training Accuracy = 44.11%\n",
      "Epoch 200: Loss = 256.4277, Training Accuracy = 43.50%\n",
      "Epoch 201: Loss = 257.5220, Training Accuracy = 44.11%\n",
      "Epoch 202: Loss = 255.5428, Training Accuracy = 46.09%\n",
      "Epoch 203: Loss = 256.1725, Training Accuracy = 45.13%\n",
      "Epoch 204: Loss = 256.5226, Training Accuracy = 45.05%\n",
      "Epoch 205: Loss = 259.1079, Training Accuracy = 45.84%\n",
      "Epoch 206: Loss = 258.4368, Training Accuracy = 46.76%\n",
      "Epoch 207: Loss = 257.8557, Training Accuracy = 45.72%\n",
      "Epoch 208: Loss = 258.3936, Training Accuracy = 46.88%\n",
      "Epoch 209: Loss = 251.1128, Training Accuracy = 47.73%\n",
      "Epoch 210: Loss = 249.9875, Training Accuracy = 48.06%\n",
      "Epoch 211: Loss = 251.6137, Training Accuracy = 46.95%\n",
      "Epoch 212: Loss = 255.3100, Training Accuracy = 46.56%\n",
      "Epoch 213: Loss = 257.1747, Training Accuracy = 46.28%\n",
      "Epoch 214: Loss = 257.7149, Training Accuracy = 46.86%\n",
      "Epoch 215: Loss = 255.7947, Training Accuracy = 45.82%\n",
      "Epoch 216: Loss = 253.6437, Training Accuracy = 47.61%\n",
      "Epoch 217: Loss = 252.9057, Training Accuracy = 46.88%\n",
      "Epoch 218: Loss = 250.1037, Training Accuracy = 47.95%\n",
      "Epoch 219: Loss = 253.4448, Training Accuracy = 46.39%\n",
      "Epoch 220: Loss = 252.1203, Training Accuracy = 46.81%\n",
      "Epoch 221: Loss = 253.5264, Training Accuracy = 46.79%\n",
      "Epoch 222: Loss = 256.1948, Training Accuracy = 48.05%\n",
      "Epoch 223: Loss = 257.9583, Training Accuracy = 46.48%\n",
      "Epoch 224: Loss = 257.0260, Training Accuracy = 46.44%\n",
      "Epoch 225: Loss = 256.7090, Training Accuracy = 46.63%\n",
      "Epoch 226: Loss = 255.6957, Training Accuracy = 47.44%\n",
      "Epoch 227: Loss = 259.4754, Training Accuracy = 46.70%\n",
      "Epoch 228: Loss = 259.2530, Training Accuracy = 47.39%\n",
      "Epoch 229: Loss = 259.2886, Training Accuracy = 48.24%\n",
      "Epoch 230: Loss = 259.6272, Training Accuracy = 46.54%\n",
      "Epoch 231: Loss = 258.8120, Training Accuracy = 45.69%\n",
      "Epoch 232: Loss = 258.3052, Training Accuracy = 47.48%\n",
      "Epoch 233: Loss = 254.3603, Training Accuracy = 48.16%\n",
      "Epoch 234: Loss = 251.3178, Training Accuracy = 47.94%\n",
      "Epoch 235: Loss = 249.0211, Training Accuracy = 48.18%\n",
      "Epoch 236: Loss = 249.2755, Training Accuracy = 49.38%\n",
      "Epoch 237: Loss = 250.5112, Training Accuracy = 49.31%\n",
      "Epoch 238: Loss = 248.6491, Training Accuracy = 49.96%\n",
      "Epoch 239: Loss = 247.4024, Training Accuracy = 50.02%\n",
      "Epoch 240: Loss = 246.1751, Training Accuracy = 50.22%\n",
      "Epoch 241: Loss = 241.6161, Training Accuracy = 50.95%\n",
      "Epoch 242: Loss = 244.9023, Training Accuracy = 49.54%\n",
      "Epoch 243: Loss = 245.6677, Training Accuracy = 50.18%\n",
      "Epoch 244: Loss = 247.8121, Training Accuracy = 50.83%\n",
      "Epoch 245: Loss = 248.3281, Training Accuracy = 49.27%\n",
      "Epoch 246: Loss = 250.0693, Training Accuracy = 49.45%\n",
      "Epoch 247: Loss = 247.6395, Training Accuracy = 50.29%\n",
      "Epoch 248: Loss = 249.4561, Training Accuracy = 50.18%\n",
      "Epoch 249: Loss = 248.1703, Training Accuracy = 50.27%\n",
      "Epoch 250: Loss = 248.0288, Training Accuracy = 50.37%\n",
      "Epoch 251: Loss = 249.2338, Training Accuracy = 50.77%\n",
      "Epoch 252: Loss = 245.9814, Training Accuracy = 50.89%\n",
      "Epoch 253: Loss = 247.4204, Training Accuracy = 50.45%\n",
      "Epoch 254: Loss = 250.6866, Training Accuracy = 50.52%\n",
      "Epoch 255: Loss = 247.7277, Training Accuracy = 50.40%\n",
      "Epoch 256: Loss = 247.7266, Training Accuracy = 50.54%\n",
      "Epoch 257: Loss = 248.2309, Training Accuracy = 50.49%\n",
      "Epoch 258: Loss = 246.2505, Training Accuracy = 51.08%\n",
      "Epoch 259: Loss = 246.2821, Training Accuracy = 50.88%\n",
      "Epoch 260: Loss = 246.3526, Training Accuracy = 51.12%\n",
      "Epoch 261: Loss = 247.3378, Training Accuracy = 50.62%\n",
      "Epoch 262: Loss = 247.8219, Training Accuracy = 50.77%\n",
      "Epoch 263: Loss = 247.3667, Training Accuracy = 50.61%\n",
      "Epoch 264: Loss = 248.5992, Training Accuracy = 50.75%\n",
      "Epoch 265: Loss = 248.9440, Training Accuracy = 50.59%\n",
      "Epoch 266: Loss = 248.9289, Training Accuracy = 50.58%\n",
      "Epoch 267: Loss = 250.7404, Training Accuracy = 50.80%\n",
      "Epoch 268: Loss = 249.5549, Training Accuracy = 50.83%\n",
      "Epoch 269: Loss = 246.3489, Training Accuracy = 50.90%\n",
      "Epoch 270: Loss = 245.8993, Training Accuracy = 50.82%\n",
      "Epoch 271: Loss = 247.9656, Training Accuracy = 50.45%\n",
      "Epoch 272: Loss = 249.9060, Training Accuracy = 50.49%\n",
      "Epoch 273: Loss = 249.7568, Training Accuracy = 50.71%\n",
      "Epoch 274: Loss = 249.5320, Training Accuracy = 50.34%\n",
      "Epoch 275: Loss = 247.8755, Training Accuracy = 50.80%\n",
      "Epoch 276: Loss = 248.3097, Training Accuracy = 51.16%\n",
      "Epoch 277: Loss = 250.5103, Training Accuracy = 51.49%\n",
      "Epoch 278: Loss = 252.4046, Training Accuracy = 51.05%\n",
      "Epoch 279: Loss = 250.1875, Training Accuracy = 49.63%\n",
      "Epoch 280: Loss = 250.2660, Training Accuracy = 49.55%\n",
      "Epoch 281: Loss = 250.2876, Training Accuracy = 48.69%\n",
      "Epoch 282: Loss = 247.9381, Training Accuracy = 51.31%\n",
      "Epoch 283: Loss = 247.8855, Training Accuracy = 51.04%\n",
      "Epoch 284: Loss = 247.6664, Training Accuracy = 52.39%\n",
      "Epoch 285: Loss = 245.2625, Training Accuracy = 52.63%\n",
      "Epoch 286: Loss = 245.3609, Training Accuracy = 52.24%\n",
      "Epoch 287: Loss = 245.0938, Training Accuracy = 52.40%\n",
      "Epoch 288: Loss = 245.7512, Training Accuracy = 52.00%\n",
      "Epoch 289: Loss = 245.9212, Training Accuracy = 51.55%\n",
      "Epoch 290: Loss = 244.7271, Training Accuracy = 51.80%\n",
      "Epoch 291: Loss = 244.5927, Training Accuracy = 52.25%\n",
      "Epoch 292: Loss = 242.6790, Training Accuracy = 52.17%\n",
      "Epoch 293: Loss = 241.0115, Training Accuracy = 52.63%\n",
      "Epoch 294: Loss = 242.1710, Training Accuracy = 52.16%\n",
      "Epoch 295: Loss = 243.0724, Training Accuracy = 52.42%\n",
      "Epoch 296: Loss = 241.1124, Training Accuracy = 52.18%\n",
      "Epoch 297: Loss = 242.4853, Training Accuracy = 51.85%\n",
      "Epoch 298: Loss = 242.4878, Training Accuracy = 52.47%\n",
      "Epoch 299: Loss = 241.3521, Training Accuracy = 52.08%\n",
      "Epoch 300: Loss = 242.7855, Training Accuracy = 52.28%\n",
      "Epoch 301: Loss = 243.4967, Training Accuracy = 52.18%\n",
      "Epoch 302: Loss = 242.1313, Training Accuracy = 52.02%\n",
      "Epoch 303: Loss = 240.3247, Training Accuracy = 52.23%\n",
      "Epoch 304: Loss = 240.2253, Training Accuracy = 51.98%\n",
      "Epoch 305: Loss = 240.8110, Training Accuracy = 51.71%\n",
      "Epoch 306: Loss = 239.6942, Training Accuracy = 52.16%\n",
      "Epoch 307: Loss = 239.8671, Training Accuracy = 52.47%\n",
      "Epoch 308: Loss = 240.4280, Training Accuracy = 52.65%\n",
      "Epoch 309: Loss = 242.2598, Training Accuracy = 51.77%\n",
      "Epoch 310: Loss = 243.3114, Training Accuracy = 52.28%\n",
      "Epoch 311: Loss = 241.5748, Training Accuracy = 53.09%\n",
      "Epoch 312: Loss = 241.7658, Training Accuracy = 52.41%\n",
      "Epoch 313: Loss = 243.3036, Training Accuracy = 53.31%\n",
      "Epoch 314: Loss = 243.2404, Training Accuracy = 53.21%\n",
      "Epoch 315: Loss = 244.8632, Training Accuracy = 53.53%\n",
      "Epoch 316: Loss = 243.4164, Training Accuracy = 52.74%\n",
      "Epoch 317: Loss = 242.2844, Training Accuracy = 51.83%\n",
      "Epoch 318: Loss = 243.3050, Training Accuracy = 51.73%\n",
      "Epoch 319: Loss = 242.8779, Training Accuracy = 52.15%\n",
      "Epoch 320: Loss = 244.2348, Training Accuracy = 53.86%\n",
      "Epoch 321: Loss = 242.9236, Training Accuracy = 53.25%\n",
      "Epoch 322: Loss = 243.8094, Training Accuracy = 53.33%\n",
      "Epoch 323: Loss = 242.9679, Training Accuracy = 52.96%\n",
      "Epoch 324: Loss = 240.4146, Training Accuracy = 53.24%\n",
      "Epoch 325: Loss = 240.9795, Training Accuracy = 53.39%\n",
      "Epoch 326: Loss = 242.4677, Training Accuracy = 54.55%\n",
      "Epoch 327: Loss = 242.3211, Training Accuracy = 53.29%\n",
      "Epoch 328: Loss = 242.2495, Training Accuracy = 53.37%\n",
      "Epoch 329: Loss = 243.4130, Training Accuracy = 53.41%\n",
      "Epoch 330: Loss = 242.2865, Training Accuracy = 53.96%\n",
      "Epoch 331: Loss = 239.9688, Training Accuracy = 55.04%\n",
      "Epoch 332: Loss = 242.4822, Training Accuracy = 53.88%\n",
      "Epoch 333: Loss = 242.2274, Training Accuracy = 54.19%\n",
      "Epoch 334: Loss = 240.4150, Training Accuracy = 54.86%\n",
      "Epoch 335: Loss = 241.0993, Training Accuracy = 54.70%\n",
      "Epoch 336: Loss = 242.4715, Training Accuracy = 54.52%\n",
      "Epoch 337: Loss = 244.1882, Training Accuracy = 54.17%\n",
      "Epoch 338: Loss = 243.7518, Training Accuracy = 53.66%\n",
      "Epoch 339: Loss = 244.4144, Training Accuracy = 54.06%\n",
      "Epoch 340: Loss = 243.6536, Training Accuracy = 53.78%\n",
      "Epoch 341: Loss = 243.8416, Training Accuracy = 53.65%\n",
      "Epoch 342: Loss = 245.0532, Training Accuracy = 53.80%\n",
      "Epoch 343: Loss = 241.4082, Training Accuracy = 54.73%\n",
      "Epoch 344: Loss = 242.9308, Training Accuracy = 54.57%\n",
      "Epoch 345: Loss = 241.6476, Training Accuracy = 55.04%\n",
      "Epoch 346: Loss = 242.0849, Training Accuracy = 54.98%\n",
      "Epoch 347: Loss = 245.2154, Training Accuracy = 54.25%\n",
      "Epoch 348: Loss = 243.5340, Training Accuracy = 55.41%\n",
      "Epoch 349: Loss = 242.9274, Training Accuracy = 55.20%\n",
      "Epoch 350: Loss = 245.9348, Training Accuracy = 55.03%\n",
      "Epoch 351: Loss = 245.9563, Training Accuracy = 55.31%\n",
      "Epoch 352: Loss = 244.4025, Training Accuracy = 53.97%\n",
      "Epoch 353: Loss = 245.6462, Training Accuracy = 54.70%\n",
      "Epoch 354: Loss = 245.5235, Training Accuracy = 54.90%\n",
      "Epoch 355: Loss = 244.4113, Training Accuracy = 53.36%\n",
      "Epoch 356: Loss = 245.4946, Training Accuracy = 54.36%\n",
      "Epoch 357: Loss = 244.2769, Training Accuracy = 55.31%\n",
      "Epoch 358: Loss = 244.2917, Training Accuracy = 55.14%\n",
      "Epoch 359: Loss = 245.1924, Training Accuracy = 55.92%\n",
      "Epoch 360: Loss = 243.1792, Training Accuracy = 56.40%\n",
      "Epoch 361: Loss = 243.8958, Training Accuracy = 54.91%\n",
      "Epoch 362: Loss = 244.2670, Training Accuracy = 55.67%\n",
      "Epoch 363: Loss = 244.1242, Training Accuracy = 56.70%\n",
      "Epoch 364: Loss = 246.0661, Training Accuracy = 54.04%\n",
      "Epoch 365: Loss = 243.4482, Training Accuracy = 56.43%\n",
      "Epoch 366: Loss = 242.8746, Training Accuracy = 56.42%\n",
      "Epoch 367: Loss = 243.2522, Training Accuracy = 56.43%\n",
      "Epoch 368: Loss = 242.6102, Training Accuracy = 56.93%\n",
      "Epoch 369: Loss = 242.8265, Training Accuracy = 56.93%\n",
      "Epoch 370: Loss = 242.8208, Training Accuracy = 56.69%\n",
      "Epoch 371: Loss = 241.1602, Training Accuracy = 56.39%\n",
      "Epoch 372: Loss = 239.9420, Training Accuracy = 56.78%\n",
      "Epoch 373: Loss = 240.7512, Training Accuracy = 56.76%\n",
      "Epoch 374: Loss = 239.4962, Training Accuracy = 57.26%\n",
      "Epoch 375: Loss = 236.6272, Training Accuracy = 57.18%\n",
      "Epoch 376: Loss = 237.9609, Training Accuracy = 57.46%\n",
      "Epoch 377: Loss = 237.1735, Training Accuracy = 57.20%\n",
      "Epoch 378: Loss = 238.4072, Training Accuracy = 56.74%\n",
      "Epoch 379: Loss = 237.0539, Training Accuracy = 57.61%\n",
      "Epoch 380: Loss = 234.8487, Training Accuracy = 57.95%\n",
      "Epoch 381: Loss = 234.2645, Training Accuracy = 57.46%\n",
      "Epoch 382: Loss = 235.8986, Training Accuracy = 58.08%\n",
      "Epoch 383: Loss = 236.2506, Training Accuracy = 57.69%\n",
      "Epoch 384: Loss = 237.9478, Training Accuracy = 58.02%\n",
      "Epoch 385: Loss = 236.2965, Training Accuracy = 57.32%\n",
      "Epoch 386: Loss = 237.3741, Training Accuracy = 57.73%\n",
      "Epoch 387: Loss = 238.0747, Training Accuracy = 57.80%\n",
      "Epoch 388: Loss = 238.7729, Training Accuracy = 57.62%\n",
      "Epoch 389: Loss = 238.5674, Training Accuracy = 58.06%\n",
      "Epoch 390: Loss = 237.1344, Training Accuracy = 58.49%\n",
      "Epoch 391: Loss = 236.1308, Training Accuracy = 58.57%\n",
      "Epoch 392: Loss = 237.4854, Training Accuracy = 58.58%\n",
      "Epoch 393: Loss = 236.5398, Training Accuracy = 58.60%\n",
      "Epoch 394: Loss = 236.1064, Training Accuracy = 58.49%\n",
      "Epoch 395: Loss = 236.4528, Training Accuracy = 58.49%\n",
      "Epoch 396: Loss = 237.1731, Training Accuracy = 58.54%\n",
      "Epoch 397: Loss = 236.8753, Training Accuracy = 58.69%\n",
      "Epoch 398: Loss = 237.2742, Training Accuracy = 59.06%\n",
      "Epoch 399: Loss = 234.1151, Training Accuracy = 59.63%\n",
      "Epoch 400: Loss = 235.5076, Training Accuracy = 59.44%\n",
      "Epoch 401: Loss = 237.2850, Training Accuracy = 59.41%\n",
      "Epoch 402: Loss = 235.8148, Training Accuracy = 59.23%\n",
      "Epoch 403: Loss = 235.9733, Training Accuracy = 59.21%\n",
      "Epoch 404: Loss = 235.2384, Training Accuracy = 59.43%\n",
      "Epoch 405: Loss = 234.3631, Training Accuracy = 59.58%\n",
      "Epoch 406: Loss = 235.5486, Training Accuracy = 59.69%\n",
      "Epoch 407: Loss = 234.9575, Training Accuracy = 60.22%\n",
      "Epoch 408: Loss = 235.8767, Training Accuracy = 59.78%\n",
      "Epoch 409: Loss = 234.6598, Training Accuracy = 59.93%\n",
      "Epoch 410: Loss = 236.4189, Training Accuracy = 59.43%\n",
      "Epoch 411: Loss = 235.6547, Training Accuracy = 59.61%\n",
      "Epoch 412: Loss = 233.5194, Training Accuracy = 60.16%\n",
      "Epoch 413: Loss = 234.4384, Training Accuracy = 60.20%\n",
      "Epoch 414: Loss = 234.8680, Training Accuracy = 60.03%\n",
      "Epoch 415: Loss = 234.5111, Training Accuracy = 60.17%\n",
      "Epoch 416: Loss = 232.2560, Training Accuracy = 59.95%\n",
      "Epoch 417: Loss = 230.5413, Training Accuracy = 60.18%\n",
      "Epoch 418: Loss = 231.1290, Training Accuracy = 60.24%\n",
      "Epoch 419: Loss = 231.1513, Training Accuracy = 60.65%\n",
      "Epoch 420: Loss = 231.2325, Training Accuracy = 60.19%\n",
      "Epoch 421: Loss = 230.9634, Training Accuracy = 60.19%\n",
      "Epoch 422: Loss = 229.7650, Training Accuracy = 60.06%\n",
      "Epoch 423: Loss = 228.7069, Training Accuracy = 60.46%\n",
      "Epoch 424: Loss = 230.4423, Training Accuracy = 60.25%\n",
      "Epoch 425: Loss = 228.5208, Training Accuracy = 60.11%\n",
      "Epoch 426: Loss = 229.1876, Training Accuracy = 60.67%\n",
      "Epoch 427: Loss = 228.5628, Training Accuracy = 60.74%\n",
      "Epoch 428: Loss = 225.8600, Training Accuracy = 61.00%\n",
      "Epoch 429: Loss = 227.0871, Training Accuracy = 61.00%\n",
      "Epoch 430: Loss = 227.1299, Training Accuracy = 60.94%\n",
      "Epoch 431: Loss = 228.2172, Training Accuracy = 61.34%\n",
      "Epoch 432: Loss = 226.7026, Training Accuracy = 61.86%\n",
      "Epoch 433: Loss = 230.1706, Training Accuracy = 61.10%\n",
      "Epoch 434: Loss = 228.2081, Training Accuracy = 61.45%\n",
      "Epoch 435: Loss = 226.2719, Training Accuracy = 61.58%\n",
      "Epoch 436: Loss = 228.2403, Training Accuracy = 61.58%\n",
      "Epoch 437: Loss = 228.3171, Training Accuracy = 61.47%\n",
      "Epoch 438: Loss = 223.8577, Training Accuracy = 61.76%\n",
      "Epoch 439: Loss = 224.4334, Training Accuracy = 62.04%\n",
      "Epoch 440: Loss = 225.8938, Training Accuracy = 61.25%\n",
      "Epoch 441: Loss = 224.0133, Training Accuracy = 62.40%\n",
      "Epoch 442: Loss = 224.7552, Training Accuracy = 62.31%\n",
      "Epoch 443: Loss = 226.5601, Training Accuracy = 61.25%\n",
      "Epoch 444: Loss = 226.3291, Training Accuracy = 62.16%\n",
      "Epoch 445: Loss = 226.8942, Training Accuracy = 62.24%\n",
      "Epoch 446: Loss = 225.1307, Training Accuracy = 61.84%\n",
      "Epoch 447: Loss = 225.2942, Training Accuracy = 62.49%\n",
      "Epoch 448: Loss = 224.8453, Training Accuracy = 62.44%\n",
      "Epoch 449: Loss = 225.2224, Training Accuracy = 62.60%\n",
      "Epoch 450: Loss = 223.9904, Training Accuracy = 62.35%\n",
      "Epoch 451: Loss = 225.2033, Training Accuracy = 63.35%\n",
      "Epoch 452: Loss = 224.1560, Training Accuracy = 63.18%\n",
      "Epoch 453: Loss = 227.0182, Training Accuracy = 61.88%\n",
      "Epoch 454: Loss = 225.6358, Training Accuracy = 62.70%\n",
      "Epoch 455: Loss = 224.4049, Training Accuracy = 62.60%\n",
      "Epoch 456: Loss = 225.6008, Training Accuracy = 62.16%\n",
      "Epoch 457: Loss = 224.5168, Training Accuracy = 63.26%\n",
      "Epoch 458: Loss = 226.7968, Training Accuracy = 62.91%\n",
      "Epoch 459: Loss = 226.4449, Training Accuracy = 63.67%\n",
      "Epoch 460: Loss = 224.7545, Training Accuracy = 63.28%\n",
      "Epoch 461: Loss = 224.6726, Training Accuracy = 63.53%\n",
      "Epoch 462: Loss = 225.2943, Training Accuracy = 63.19%\n",
      "Epoch 463: Loss = 223.1317, Training Accuracy = 63.31%\n",
      "Epoch 464: Loss = 222.5576, Training Accuracy = 63.34%\n",
      "Epoch 465: Loss = 222.9567, Training Accuracy = 63.38%\n",
      "Epoch 466: Loss = 222.6790, Training Accuracy = 63.64%\n",
      "Epoch 467: Loss = 222.1662, Training Accuracy = 63.62%\n",
      "Epoch 468: Loss = 225.7238, Training Accuracy = 63.01%\n",
      "Epoch 469: Loss = 225.0920, Training Accuracy = 62.98%\n",
      "Epoch 470: Loss = 224.7539, Training Accuracy = 63.34%\n",
      "Epoch 471: Loss = 225.1273, Training Accuracy = 63.46%\n",
      "Epoch 472: Loss = 224.1199, Training Accuracy = 63.57%\n",
      "Epoch 473: Loss = 224.9861, Training Accuracy = 63.65%\n",
      "Epoch 474: Loss = 222.7081, Training Accuracy = 63.33%\n",
      "Epoch 475: Loss = 223.7409, Training Accuracy = 63.82%\n",
      "Epoch 476: Loss = 225.3942, Training Accuracy = 63.11%\n",
      "Epoch 477: Loss = 226.1901, Training Accuracy = 63.01%\n",
      "Epoch 478: Loss = 226.4312, Training Accuracy = 63.22%\n",
      "Epoch 479: Loss = 223.9048, Training Accuracy = 63.32%\n",
      "Epoch 480: Loss = 221.6513, Training Accuracy = 63.58%\n",
      "Epoch 481: Loss = 222.0873, Training Accuracy = 63.30%\n",
      "Epoch 482: Loss = 221.4674, Training Accuracy = 63.50%\n",
      "Epoch 483: Loss = 222.1212, Training Accuracy = 63.80%\n",
      "Epoch 484: Loss = 222.8503, Training Accuracy = 63.67%\n",
      "Epoch 485: Loss = 222.3733, Training Accuracy = 63.52%\n",
      "Epoch 486: Loss = 221.6137, Training Accuracy = 64.05%\n",
      "Epoch 487: Loss = 222.0799, Training Accuracy = 63.87%\n",
      "Epoch 488: Loss = 223.0867, Training Accuracy = 63.59%\n",
      "Epoch 489: Loss = 223.0505, Training Accuracy = 63.52%\n",
      "Epoch 490: Loss = 223.0079, Training Accuracy = 63.92%\n",
      "Epoch 491: Loss = 223.7855, Training Accuracy = 63.16%\n",
      "Epoch 492: Loss = 223.3823, Training Accuracy = 64.60%\n",
      "Epoch 493: Loss = 220.5289, Training Accuracy = 64.69%\n",
      "Epoch 494: Loss = 219.4289, Training Accuracy = 64.87%\n",
      "Epoch 495: Loss = 221.3013, Training Accuracy = 64.74%\n",
      "Epoch 496: Loss = 221.4991, Training Accuracy = 65.07%\n",
      "Epoch 497: Loss = 221.0865, Training Accuracy = 65.36%\n",
      "Epoch 498: Loss = 221.8945, Training Accuracy = 65.52%\n",
      "Epoch 499: Loss = 220.1520, Training Accuracy = 65.30%\n",
      "Epoch 500: Loss = 217.9744, Training Accuracy = 65.45%\n",
      "Epoch 501: Loss = 219.6974, Training Accuracy = 65.21%\n",
      "Epoch 502: Loss = 220.3732, Training Accuracy = 64.63%\n",
      "Epoch 503: Loss = 218.6674, Training Accuracy = 65.80%\n",
      "Epoch 504: Loss = 216.9532, Training Accuracy = 65.85%\n",
      "Epoch 505: Loss = 216.7979, Training Accuracy = 65.86%\n",
      "Epoch 506: Loss = 217.1951, Training Accuracy = 65.41%\n",
      "Epoch 507: Loss = 217.2010, Training Accuracy = 65.55%\n",
      "Epoch 508: Loss = 216.4344, Training Accuracy = 65.61%\n",
      "Epoch 509: Loss = 216.5157, Training Accuracy = 65.88%\n",
      "Epoch 510: Loss = 218.2343, Training Accuracy = 64.88%\n",
      "Epoch 511: Loss = 218.2859, Training Accuracy = 65.83%\n",
      "Epoch 512: Loss = 218.8681, Training Accuracy = 65.63%\n",
      "Epoch 513: Loss = 218.2727, Training Accuracy = 65.74%\n",
      "Epoch 514: Loss = 217.6423, Training Accuracy = 65.60%\n",
      "Epoch 515: Loss = 217.3134, Training Accuracy = 66.10%\n",
      "Epoch 516: Loss = 218.2939, Training Accuracy = 65.80%\n",
      "Epoch 517: Loss = 217.5475, Training Accuracy = 65.86%\n",
      "Epoch 518: Loss = 218.2424, Training Accuracy = 65.15%\n",
      "Epoch 519: Loss = 217.0306, Training Accuracy = 65.72%\n",
      "Epoch 520: Loss = 218.1347, Training Accuracy = 65.25%\n",
      "Epoch 521: Loss = 216.7402, Training Accuracy = 65.77%\n",
      "Epoch 522: Loss = 217.6261, Training Accuracy = 65.47%\n",
      "Epoch 523: Loss = 218.7317, Training Accuracy = 65.36%\n",
      "Epoch 524: Loss = 219.7396, Training Accuracy = 65.05%\n",
      "Epoch 525: Loss = 218.8937, Training Accuracy = 65.30%\n",
      "Epoch 526: Loss = 217.4969, Training Accuracy = 65.13%\n",
      "Epoch 527: Loss = 217.5836, Training Accuracy = 65.20%\n",
      "Epoch 528: Loss = 215.5158, Training Accuracy = 65.90%\n",
      "Epoch 529: Loss = 214.3918, Training Accuracy = 65.87%\n",
      "Epoch 530: Loss = 215.4318, Training Accuracy = 65.82%\n",
      "Epoch 531: Loss = 216.3336, Training Accuracy = 65.68%\n",
      "Epoch 532: Loss = 214.6399, Training Accuracy = 65.91%\n",
      "Epoch 533: Loss = 213.8299, Training Accuracy = 65.69%\n",
      "Epoch 534: Loss = 213.0849, Training Accuracy = 65.88%\n",
      "Epoch 535: Loss = 214.2245, Training Accuracy = 66.62%\n",
      "Epoch 536: Loss = 213.9153, Training Accuracy = 65.64%\n",
      "Epoch 537: Loss = 215.1491, Training Accuracy = 65.71%\n",
      "Epoch 538: Loss = 215.5804, Training Accuracy = 65.69%\n",
      "Epoch 539: Loss = 216.5061, Training Accuracy = 66.09%\n",
      "Epoch 540: Loss = 216.3063, Training Accuracy = 66.67%\n",
      "Epoch 541: Loss = 214.6551, Training Accuracy = 65.86%\n",
      "Epoch 542: Loss = 212.4778, Training Accuracy = 66.24%\n",
      "Epoch 543: Loss = 214.0158, Training Accuracy = 66.19%\n",
      "Epoch 544: Loss = 215.4113, Training Accuracy = 66.24%\n",
      "Epoch 545: Loss = 215.2788, Training Accuracy = 66.33%\n",
      "Epoch 546: Loss = 216.0863, Training Accuracy = 65.60%\n",
      "Epoch 547: Loss = 217.2475, Training Accuracy = 65.56%\n",
      "Epoch 548: Loss = 215.9132, Training Accuracy = 66.25%\n",
      "Epoch 549: Loss = 215.0300, Training Accuracy = 66.12%\n",
      "Epoch 550: Loss = 215.8386, Training Accuracy = 66.00%\n",
      "Epoch 551: Loss = 212.6568, Training Accuracy = 66.43%\n",
      "Epoch 552: Loss = 212.8551, Training Accuracy = 66.15%\n",
      "Epoch 553: Loss = 214.0822, Training Accuracy = 66.21%\n",
      "Epoch 554: Loss = 211.3342, Training Accuracy = 66.51%\n",
      "Epoch 555: Loss = 210.7020, Training Accuracy = 66.72%\n",
      "Epoch 556: Loss = 210.3968, Training Accuracy = 67.03%\n",
      "Epoch 557: Loss = 210.5916, Training Accuracy = 67.02%\n",
      "Epoch 558: Loss = 210.7197, Training Accuracy = 66.59%\n",
      "Epoch 559: Loss = 210.3972, Training Accuracy = 66.81%\n",
      "Epoch 560: Loss = 210.9535, Training Accuracy = 66.87%\n",
      "Epoch 561: Loss = 209.3669, Training Accuracy = 66.93%\n",
      "Epoch 562: Loss = 210.7523, Training Accuracy = 66.54%\n",
      "Epoch 563: Loss = 210.3376, Training Accuracy = 66.48%\n",
      "Epoch 564: Loss = 208.5742, Training Accuracy = 66.92%\n",
      "Epoch 565: Loss = 210.6800, Training Accuracy = 66.74%\n",
      "Epoch 566: Loss = 211.1637, Training Accuracy = 66.62%\n",
      "Epoch 567: Loss = 212.0428, Training Accuracy = 66.38%\n",
      "Epoch 568: Loss = 210.5392, Training Accuracy = 66.58%\n",
      "Epoch 569: Loss = 211.7027, Training Accuracy = 66.39%\n",
      "Epoch 570: Loss = 211.7079, Training Accuracy = 66.53%\n",
      "Epoch 571: Loss = 211.6638, Training Accuracy = 66.37%\n",
      "Epoch 572: Loss = 210.1730, Training Accuracy = 66.54%\n",
      "Epoch 573: Loss = 211.0514, Training Accuracy = 66.25%\n",
      "Epoch 574: Loss = 212.2065, Training Accuracy = 66.47%\n",
      "Epoch 575: Loss = 211.9489, Training Accuracy = 66.37%\n",
      "Epoch 576: Loss = 209.5192, Training Accuracy = 66.95%\n",
      "Epoch 577: Loss = 210.7136, Training Accuracy = 66.64%\n",
      "Epoch 578: Loss = 208.7870, Training Accuracy = 66.86%\n",
      "Epoch 579: Loss = 207.0368, Training Accuracy = 67.10%\n",
      "Epoch 580: Loss = 205.3869, Training Accuracy = 67.25%\n",
      "Epoch 581: Loss = 206.5206, Training Accuracy = 67.14%\n",
      "Epoch 582: Loss = 206.3135, Training Accuracy = 66.94%\n",
      "Epoch 583: Loss = 207.2331, Training Accuracy = 66.95%\n",
      "Epoch 584: Loss = 207.8832, Training Accuracy = 66.88%\n",
      "Epoch 585: Loss = 208.6425, Training Accuracy = 66.68%\n",
      "Epoch 586: Loss = 207.5527, Training Accuracy = 66.95%\n",
      "Epoch 587: Loss = 207.9249, Training Accuracy = 66.85%\n",
      "Epoch 588: Loss = 209.3861, Training Accuracy = 66.75%\n",
      "Epoch 589: Loss = 209.4663, Training Accuracy = 66.45%\n",
      "Epoch 590: Loss = 208.6777, Training Accuracy = 66.58%\n",
      "Epoch 591: Loss = 208.8056, Training Accuracy = 66.31%\n",
      "Epoch 592: Loss = 209.0358, Training Accuracy = 66.19%\n",
      "Epoch 593: Loss = 210.1444, Training Accuracy = 66.02%\n",
      "Epoch 594: Loss = 210.7420, Training Accuracy = 65.80%\n",
      "Epoch 595: Loss = 210.6302, Training Accuracy = 66.47%\n",
      "Epoch 596: Loss = 210.0144, Training Accuracy = 66.07%\n",
      "Epoch 597: Loss = 210.1036, Training Accuracy = 67.00%\n",
      "Epoch 598: Loss = 210.4312, Training Accuracy = 66.92%\n",
      "Epoch 599: Loss = 210.7171, Training Accuracy = 67.05%\n",
      "Epoch 600: Loss = 210.6380, Training Accuracy = 67.17%\n",
      "Epoch 601: Loss = 210.3278, Training Accuracy = 67.31%\n",
      "Epoch 602: Loss = 209.9777, Training Accuracy = 67.23%\n",
      "Epoch 603: Loss = 208.7334, Training Accuracy = 67.33%\n",
      "Epoch 604: Loss = 209.0554, Training Accuracy = 67.29%\n",
      "Epoch 605: Loss = 209.5910, Training Accuracy = 67.23%\n",
      "Epoch 606: Loss = 208.0992, Training Accuracy = 67.30%\n",
      "Epoch 607: Loss = 208.9618, Training Accuracy = 67.23%\n",
      "Epoch 608: Loss = 209.0469, Training Accuracy = 67.28%\n",
      "Epoch 609: Loss = 207.9945, Training Accuracy = 67.37%\n",
      "Epoch 610: Loss = 208.4626, Training Accuracy = 67.34%\n",
      "Epoch 611: Loss = 208.9126, Training Accuracy = 67.21%\n",
      "Epoch 612: Loss = 208.2325, Training Accuracy = 67.12%\n",
      "Epoch 613: Loss = 207.6987, Training Accuracy = 67.56%\n",
      "Epoch 614: Loss = 206.9524, Training Accuracy = 67.81%\n",
      "Epoch 615: Loss = 208.2401, Training Accuracy = 67.02%\n",
      "Epoch 616: Loss = 208.0656, Training Accuracy = 67.48%\n",
      "Epoch 617: Loss = 207.7193, Training Accuracy = 67.34%\n",
      "Epoch 618: Loss = 208.5435, Training Accuracy = 67.25%\n",
      "Epoch 619: Loss = 208.7463, Training Accuracy = 67.44%\n",
      "Epoch 620: Loss = 209.2341, Training Accuracy = 67.23%\n",
      "Epoch 621: Loss = 208.9516, Training Accuracy = 67.03%\n",
      "Epoch 622: Loss = 208.7547, Training Accuracy = 67.18%\n",
      "Epoch 623: Loss = 207.7308, Training Accuracy = 67.15%\n",
      "Epoch 624: Loss = 207.1289, Training Accuracy = 67.35%\n",
      "Epoch 625: Loss = 208.8563, Training Accuracy = 67.12%\n",
      "Epoch 626: Loss = 207.8975, Training Accuracy = 66.72%\n",
      "Epoch 627: Loss = 208.1401, Training Accuracy = 66.78%\n",
      "Epoch 628: Loss = 206.6960, Training Accuracy = 66.94%\n",
      "Epoch 629: Loss = 206.8272, Training Accuracy = 67.17%\n",
      "Epoch 630: Loss = 208.0423, Training Accuracy = 66.68%\n",
      "Epoch 631: Loss = 207.4878, Training Accuracy = 67.25%\n",
      "Epoch 632: Loss = 207.6932, Training Accuracy = 66.58%\n",
      "Epoch 633: Loss = 209.0819, Training Accuracy = 66.39%\n",
      "Epoch 634: Loss = 208.9648, Training Accuracy = 66.36%\n",
      "Epoch 635: Loss = 208.2949, Training Accuracy = 67.83%\n",
      "Epoch 636: Loss = 209.1172, Training Accuracy = 66.62%\n",
      "Epoch 637: Loss = 208.0124, Training Accuracy = 66.74%\n",
      "Epoch 638: Loss = 207.6067, Training Accuracy = 67.56%\n",
      "Epoch 639: Loss = 207.8898, Training Accuracy = 67.73%\n",
      "Epoch 640: Loss = 207.3014, Training Accuracy = 67.43%\n",
      "Epoch 641: Loss = 207.1125, Training Accuracy = 66.98%\n",
      "Epoch 642: Loss = 207.6921, Training Accuracy = 66.57%\n",
      "Epoch 643: Loss = 208.9850, Training Accuracy = 67.13%\n",
      "Epoch 644: Loss = 208.3764, Training Accuracy = 67.09%\n",
      "Epoch 645: Loss = 209.1528, Training Accuracy = 67.07%\n",
      "Epoch 646: Loss = 210.0034, Training Accuracy = 67.03%\n",
      "Epoch 647: Loss = 210.3173, Training Accuracy = 66.99%\n",
      "Epoch 648: Loss = 210.7668, Training Accuracy = 66.74%\n",
      "Epoch 649: Loss = 210.1543, Training Accuracy = 66.92%\n",
      "Epoch 650: Loss = 210.5096, Training Accuracy = 66.74%\n",
      "Epoch 651: Loss = 210.3271, Training Accuracy = 66.78%\n",
      "Epoch 652: Loss = 210.0182, Training Accuracy = 66.83%\n",
      "Epoch 653: Loss = 210.2462, Training Accuracy = 66.87%\n",
      "Epoch 654: Loss = 209.4108, Training Accuracy = 67.05%\n",
      "Epoch 655: Loss = 210.2196, Training Accuracy = 67.04%\n",
      "Epoch 656: Loss = 210.4893, Training Accuracy = 66.64%\n",
      "Epoch 657: Loss = 210.8897, Training Accuracy = 66.72%\n",
      "Epoch 658: Loss = 210.5482, Training Accuracy = 66.40%\n",
      "Epoch 659: Loss = 211.3956, Training Accuracy = 66.77%\n",
      "Epoch 660: Loss = 210.5021, Training Accuracy = 66.07%\n",
      "Epoch 661: Loss = 209.2383, Training Accuracy = 66.40%\n",
      "Epoch 662: Loss = 209.4204, Training Accuracy = 66.20%\n",
      "Epoch 663: Loss = 210.5306, Training Accuracy = 66.49%\n",
      "Epoch 664: Loss = 210.7999, Training Accuracy = 67.52%\n",
      "Epoch 665: Loss = 210.6005, Training Accuracy = 66.50%\n",
      "Epoch 666: Loss = 208.4239, Training Accuracy = 66.75%\n",
      "Epoch 667: Loss = 209.3959, Training Accuracy = 66.66%\n",
      "Epoch 668: Loss = 209.3592, Training Accuracy = 66.66%\n",
      "Epoch 669: Loss = 209.5541, Training Accuracy = 67.52%\n",
      "Epoch 670: Loss = 209.6365, Training Accuracy = 67.34%\n",
      "Epoch 671: Loss = 209.9469, Training Accuracy = 67.41%\n",
      "Epoch 672: Loss = 210.1919, Training Accuracy = 67.47%\n",
      "Epoch 673: Loss = 209.2986, Training Accuracy = 67.47%\n",
      "Epoch 674: Loss = 207.2571, Training Accuracy = 68.00%\n",
      "Epoch 675: Loss = 207.5620, Training Accuracy = 67.89%\n",
      "Epoch 676: Loss = 207.9093, Training Accuracy = 67.78%\n",
      "Epoch 677: Loss = 207.1539, Training Accuracy = 67.69%\n",
      "Epoch 678: Loss = 207.7029, Training Accuracy = 67.59%\n",
      "Epoch 679: Loss = 207.4929, Training Accuracy = 67.60%\n",
      "Epoch 680: Loss = 207.9458, Training Accuracy = 67.71%\n",
      "Epoch 681: Loss = 208.8996, Training Accuracy = 68.15%\n",
      "Epoch 682: Loss = 209.4168, Training Accuracy = 67.59%\n",
      "Epoch 683: Loss = 209.0677, Training Accuracy = 67.99%\n",
      "Epoch 684: Loss = 210.2486, Training Accuracy = 67.86%\n",
      "Epoch 685: Loss = 208.4993, Training Accuracy = 68.27%\n",
      "Epoch 686: Loss = 208.8927, Training Accuracy = 68.09%\n",
      "Epoch 687: Loss = 209.5197, Training Accuracy = 68.27%\n",
      "Epoch 688: Loss = 209.4392, Training Accuracy = 68.49%\n",
      "Epoch 689: Loss = 208.8091, Training Accuracy = 68.52%\n",
      "Epoch 690: Loss = 209.3223, Training Accuracy = 68.72%\n",
      "Epoch 691: Loss = 208.4539, Training Accuracy = 68.73%\n",
      "Epoch 692: Loss = 207.4743, Training Accuracy = 69.30%\n",
      "Epoch 693: Loss = 208.4238, Training Accuracy = 68.73%\n",
      "Epoch 694: Loss = 207.2845, Training Accuracy = 68.76%\n",
      "Epoch 695: Loss = 207.1787, Training Accuracy = 68.77%\n",
      "Epoch 696: Loss = 207.8441, Training Accuracy = 68.66%\n",
      "Epoch 697: Loss = 208.6945, Training Accuracy = 68.55%\n",
      "Epoch 698: Loss = 208.6850, Training Accuracy = 68.62%\n",
      "Epoch 699: Loss = 208.0542, Training Accuracy = 68.43%\n",
      "Epoch 700: Loss = 207.6064, Training Accuracy = 68.75%\n",
      "Epoch 701: Loss = 208.6463, Training Accuracy = 68.94%\n",
      "Epoch 702: Loss = 206.8005, Training Accuracy = 69.25%\n",
      "Epoch 703: Loss = 208.5542, Training Accuracy = 68.97%\n",
      "Epoch 704: Loss = 207.0428, Training Accuracy = 69.19%\n",
      "Epoch 705: Loss = 208.6493, Training Accuracy = 68.79%\n",
      "Epoch 706: Loss = 209.7084, Training Accuracy = 68.34%\n",
      "Epoch 707: Loss = 209.3047, Training Accuracy = 68.92%\n",
      "Epoch 708: Loss = 208.6635, Training Accuracy = 68.45%\n",
      "Epoch 709: Loss = 208.4483, Training Accuracy = 69.20%\n",
      "Epoch 710: Loss = 207.7564, Training Accuracy = 68.19%\n",
      "Epoch 711: Loss = 207.6795, Training Accuracy = 68.22%\n",
      "Epoch 712: Loss = 208.4682, Training Accuracy = 68.21%\n",
      "Epoch 713: Loss = 209.1373, Training Accuracy = 67.80%\n",
      "Epoch 714: Loss = 207.4300, Training Accuracy = 68.23%\n",
      "Epoch 715: Loss = 208.2358, Training Accuracy = 67.87%\n",
      "Epoch 716: Loss = 208.6825, Training Accuracy = 68.58%\n",
      "Epoch 717: Loss = 207.5875, Training Accuracy = 68.69%\n",
      "Epoch 718: Loss = 207.5234, Training Accuracy = 68.99%\n",
      "Epoch 719: Loss = 208.7293, Training Accuracy = 68.95%\n",
      "Epoch 720: Loss = 208.6110, Training Accuracy = 68.49%\n",
      "Epoch 721: Loss = 208.9673, Training Accuracy = 68.75%\n",
      "Epoch 722: Loss = 209.1338, Training Accuracy = 69.08%\n",
      "Epoch 723: Loss = 208.2627, Training Accuracy = 68.54%\n",
      "Epoch 724: Loss = 207.2995, Training Accuracy = 68.99%\n",
      "Epoch 725: Loss = 206.8721, Training Accuracy = 69.08%\n",
      "Epoch 726: Loss = 208.3117, Training Accuracy = 69.23%\n",
      "Epoch 727: Loss = 207.5870, Training Accuracy = 69.29%\n",
      "Epoch 728: Loss = 206.2437, Training Accuracy = 69.43%\n",
      "Epoch 729: Loss = 207.1087, Training Accuracy = 69.19%\n",
      "Epoch 730: Loss = 207.2379, Training Accuracy = 69.41%\n",
      "Epoch 731: Loss = 206.4498, Training Accuracy = 69.43%\n",
      "Epoch 732: Loss = 206.7398, Training Accuracy = 69.63%\n",
      "Epoch 733: Loss = 208.0220, Training Accuracy = 69.23%\n",
      "Epoch 734: Loss = 206.8831, Training Accuracy = 69.43%\n",
      "Epoch 735: Loss = 207.5451, Training Accuracy = 69.21%\n",
      "Epoch 736: Loss = 207.6136, Training Accuracy = 69.32%\n",
      "Epoch 737: Loss = 207.8122, Training Accuracy = 69.16%\n",
      "Epoch 738: Loss = 208.5313, Training Accuracy = 69.24%\n",
      "Epoch 739: Loss = 207.5930, Training Accuracy = 69.13%\n",
      "Epoch 740: Loss = 208.1153, Training Accuracy = 69.12%\n",
      "Epoch 741: Loss = 208.2567, Training Accuracy = 69.54%\n",
      "Epoch 742: Loss = 207.8558, Training Accuracy = 69.18%\n",
      "Epoch 743: Loss = 207.9841, Training Accuracy = 69.32%\n",
      "Epoch 744: Loss = 207.6121, Training Accuracy = 68.59%\n",
      "Epoch 745: Loss = 207.9717, Training Accuracy = 69.51%\n",
      "Epoch 746: Loss = 208.1953, Training Accuracy = 69.45%\n",
      "Epoch 747: Loss = 208.7614, Training Accuracy = 69.37%\n",
      "Epoch 748: Loss = 208.5018, Training Accuracy = 69.42%\n",
      "Epoch 749: Loss = 207.8537, Training Accuracy = 69.21%\n",
      "Epoch 750: Loss = 207.8049, Training Accuracy = 69.29%\n",
      "Epoch 751: Loss = 208.0734, Training Accuracy = 69.40%\n",
      "Epoch 752: Loss = 208.8237, Training Accuracy = 69.09%\n",
      "Epoch 753: Loss = 208.9175, Training Accuracy = 68.92%\n",
      "Epoch 754: Loss = 208.2248, Training Accuracy = 69.36%\n",
      "Epoch 755: Loss = 207.3678, Training Accuracy = 69.38%\n",
      "Epoch 756: Loss = 209.3708, Training Accuracy = 68.93%\n",
      "Epoch 757: Loss = 209.2623, Training Accuracy = 69.19%\n",
      "Epoch 758: Loss = 209.1331, Training Accuracy = 69.21%\n",
      "Epoch 759: Loss = 208.1107, Training Accuracy = 69.51%\n",
      "Epoch 760: Loss = 207.1849, Training Accuracy = 69.42%\n",
      "Epoch 761: Loss = 209.0298, Training Accuracy = 69.44%\n",
      "Epoch 762: Loss = 208.4420, Training Accuracy = 69.33%\n",
      "Epoch 763: Loss = 209.2862, Training Accuracy = 69.22%\n",
      "Epoch 764: Loss = 208.9960, Training Accuracy = 69.17%\n",
      "Epoch 765: Loss = 208.7419, Training Accuracy = 69.48%\n",
      "Epoch 766: Loss = 208.9101, Training Accuracy = 69.34%\n",
      "Epoch 767: Loss = 209.4815, Training Accuracy = 69.35%\n",
      "Epoch 768: Loss = 209.0959, Training Accuracy = 69.37%\n",
      "Epoch 769: Loss = 208.7736, Training Accuracy = 69.49%\n",
      "Epoch 770: Loss = 208.6202, Training Accuracy = 69.41%\n",
      "Epoch 771: Loss = 208.7425, Training Accuracy = 69.48%\n",
      "Epoch 772: Loss = 208.7532, Training Accuracy = 69.59%\n",
      "Epoch 773: Loss = 207.7007, Training Accuracy = 69.52%\n",
      "Epoch 774: Loss = 208.2244, Training Accuracy = 69.69%\n",
      "Epoch 775: Loss = 209.2617, Training Accuracy = 69.69%\n",
      "Epoch 776: Loss = 208.4844, Training Accuracy = 69.53%\n",
      "Epoch 777: Loss = 208.4153, Training Accuracy = 69.86%\n",
      "Epoch 778: Loss = 209.2157, Training Accuracy = 70.03%\n",
      "Epoch 779: Loss = 209.3402, Training Accuracy = 69.81%\n",
      "Epoch 780: Loss = 209.2093, Training Accuracy = 69.07%\n",
      "Epoch 781: Loss = 208.7827, Training Accuracy = 69.73%\n",
      "Epoch 782: Loss = 207.4863, Training Accuracy = 69.97%\n",
      "Epoch 783: Loss = 207.8802, Training Accuracy = 69.97%\n",
      "Epoch 784: Loss = 207.3739, Training Accuracy = 69.88%\n",
      "Epoch 785: Loss = 207.2668, Training Accuracy = 69.77%\n",
      "Epoch 786: Loss = 206.7324, Training Accuracy = 69.81%\n",
      "Epoch 787: Loss = 207.3530, Training Accuracy = 69.83%\n",
      "Epoch 788: Loss = 207.0857, Training Accuracy = 69.71%\n",
      "Epoch 789: Loss = 207.4609, Training Accuracy = 69.73%\n",
      "Epoch 790: Loss = 207.5460, Training Accuracy = 69.92%\n",
      "Epoch 791: Loss = 207.7716, Training Accuracy = 69.88%\n",
      "Epoch 792: Loss = 206.7085, Training Accuracy = 70.25%\n",
      "Epoch 793: Loss = 206.9005, Training Accuracy = 70.02%\n",
      "Epoch 794: Loss = 207.6802, Training Accuracy = 69.45%\n",
      "Epoch 795: Loss = 208.0301, Training Accuracy = 69.41%\n",
      "Epoch 796: Loss = 208.5772, Training Accuracy = 69.45%\n",
      "Epoch 797: Loss = 209.2435, Training Accuracy = 69.49%\n",
      "Epoch 798: Loss = 209.1513, Training Accuracy = 69.20%\n",
      "Epoch 799: Loss = 209.1977, Training Accuracy = 69.35%\n",
      "Epoch 800: Loss = 208.8935, Training Accuracy = 69.62%\n",
      "Epoch 801: Loss = 208.6906, Training Accuracy = 69.48%\n",
      "Epoch 802: Loss = 209.1845, Training Accuracy = 69.51%\n",
      "Epoch 803: Loss = 209.1570, Training Accuracy = 69.49%\n",
      "Epoch 804: Loss = 208.4019, Training Accuracy = 69.83%\n",
      "Epoch 805: Loss = 209.1751, Training Accuracy = 69.71%\n",
      "Epoch 806: Loss = 208.6027, Training Accuracy = 69.89%\n",
      "Epoch 807: Loss = 208.8913, Training Accuracy = 69.87%\n",
      "Epoch 808: Loss = 208.0163, Training Accuracy = 69.67%\n",
      "Epoch 809: Loss = 208.1553, Training Accuracy = 69.78%\n",
      "Epoch 810: Loss = 208.9115, Training Accuracy = 69.37%\n",
      "Epoch 811: Loss = 208.3508, Training Accuracy = 69.63%\n",
      "Epoch 812: Loss = 209.4956, Training Accuracy = 70.64%\n",
      "Epoch 813: Loss = 208.5782, Training Accuracy = 70.71%\n",
      "Epoch 814: Loss = 210.1814, Training Accuracy = 69.41%\n",
      "Epoch 815: Loss = 209.8211, Training Accuracy = 69.66%\n",
      "Epoch 816: Loss = 210.3942, Training Accuracy = 69.74%\n",
      "Epoch 817: Loss = 210.0337, Training Accuracy = 69.77%\n",
      "Epoch 818: Loss = 210.5175, Training Accuracy = 69.77%\n",
      "Epoch 819: Loss = 209.2609, Training Accuracy = 70.52%\n",
      "Epoch 820: Loss = 208.9161, Training Accuracy = 70.80%\n",
      "Epoch 821: Loss = 209.0640, Training Accuracy = 70.91%\n",
      "Epoch 822: Loss = 210.8208, Training Accuracy = 70.55%\n",
      "Epoch 823: Loss = 209.6417, Training Accuracy = 69.99%\n",
      "Epoch 824: Loss = 210.3575, Training Accuracy = 70.13%\n",
      "Epoch 825: Loss = 209.8348, Training Accuracy = 70.42%\n",
      "Epoch 826: Loss = 209.5367, Training Accuracy = 70.48%\n",
      "Epoch 827: Loss = 209.1938, Training Accuracy = 70.31%\n",
      "Epoch 828: Loss = 208.2861, Training Accuracy = 70.24%\n",
      "Epoch 829: Loss = 209.6640, Training Accuracy = 70.28%\n",
      "Epoch 830: Loss = 209.0873, Training Accuracy = 69.60%\n",
      "Epoch 831: Loss = 210.6682, Training Accuracy = 70.14%\n",
      "Epoch 832: Loss = 211.1405, Training Accuracy = 70.06%\n",
      "Epoch 833: Loss = 210.0516, Training Accuracy = 70.26%\n",
      "Epoch 834: Loss = 209.8003, Training Accuracy = 69.72%\n",
      "Epoch 835: Loss = 210.2843, Training Accuracy = 69.80%\n",
      "Epoch 836: Loss = 209.3509, Training Accuracy = 70.57%\n",
      "Epoch 837: Loss = 208.2166, Training Accuracy = 70.71%\n",
      "Epoch 838: Loss = 207.8684, Training Accuracy = 70.75%\n",
      "Epoch 839: Loss = 207.5319, Training Accuracy = 71.11%\n",
      "Epoch 840: Loss = 206.4536, Training Accuracy = 71.22%\n",
      "Epoch 841: Loss = 206.7137, Training Accuracy = 71.19%\n",
      "Epoch 842: Loss = 207.3443, Training Accuracy = 70.98%\n",
      "Epoch 843: Loss = 207.8065, Training Accuracy = 71.31%\n",
      "Epoch 844: Loss = 208.8702, Training Accuracy = 71.06%\n",
      "Epoch 845: Loss = 207.9502, Training Accuracy = 71.22%\n",
      "Epoch 846: Loss = 206.4602, Training Accuracy = 71.59%\n",
      "Epoch 847: Loss = 206.1986, Training Accuracy = 71.53%\n",
      "Epoch 848: Loss = 205.6833, Training Accuracy = 71.63%\n",
      "Epoch 849: Loss = 207.7621, Training Accuracy = 71.58%\n",
      "Epoch 850: Loss = 206.7961, Training Accuracy = 71.48%\n",
      "Epoch 851: Loss = 205.8353, Training Accuracy = 71.65%\n",
      "Epoch 852: Loss = 207.4745, Training Accuracy = 71.26%\n",
      "Epoch 853: Loss = 206.4326, Training Accuracy = 70.78%\n",
      "Epoch 854: Loss = 207.0064, Training Accuracy = 70.81%\n",
      "Epoch 855: Loss = 207.0570, Training Accuracy = 70.85%\n",
      "Epoch 856: Loss = 207.2681, Training Accuracy = 70.58%\n",
      "Epoch 857: Loss = 206.8888, Training Accuracy = 71.40%\n",
      "Epoch 858: Loss = 208.2122, Training Accuracy = 71.63%\n",
      "Epoch 859: Loss = 207.6396, Training Accuracy = 70.80%\n",
      "Epoch 860: Loss = 207.5495, Training Accuracy = 71.82%\n",
      "Epoch 861: Loss = 207.3061, Training Accuracy = 71.11%\n",
      "Epoch 862: Loss = 207.5676, Training Accuracy = 70.75%\n",
      "Epoch 863: Loss = 207.4679, Training Accuracy = 70.96%\n",
      "Epoch 864: Loss = 205.9055, Training Accuracy = 71.64%\n",
      "Epoch 865: Loss = 208.0088, Training Accuracy = 71.65%\n",
      "Epoch 866: Loss = 206.7797, Training Accuracy = 71.78%\n",
      "Epoch 867: Loss = 206.1057, Training Accuracy = 71.80%\n",
      "Epoch 868: Loss = 206.5440, Training Accuracy = 71.40%\n",
      "Epoch 869: Loss = 205.8169, Training Accuracy = 71.68%\n",
      "Epoch 870: Loss = 206.5644, Training Accuracy = 71.40%\n",
      "Epoch 871: Loss = 206.3723, Training Accuracy = 71.59%\n",
      "Epoch 872: Loss = 206.7609, Training Accuracy = 71.82%\n",
      "Epoch 873: Loss = 206.8123, Training Accuracy = 71.53%\n",
      "Epoch 874: Loss = 205.8235, Training Accuracy = 71.26%\n",
      "Epoch 875: Loss = 205.8018, Training Accuracy = 71.72%\n",
      "Epoch 876: Loss = 204.5229, Training Accuracy = 71.81%\n",
      "Epoch 877: Loss = 206.4473, Training Accuracy = 71.75%\n",
      "Epoch 878: Loss = 206.1016, Training Accuracy = 71.89%\n",
      "Epoch 879: Loss = 205.0330, Training Accuracy = 71.86%\n",
      "Epoch 880: Loss = 204.9247, Training Accuracy = 71.76%\n",
      "Epoch 881: Loss = 204.4796, Training Accuracy = 71.68%\n",
      "Epoch 882: Loss = 204.6210, Training Accuracy = 71.68%\n",
      "Epoch 883: Loss = 205.5764, Training Accuracy = 71.56%\n",
      "Epoch 884: Loss = 206.0649, Training Accuracy = 71.64%\n",
      "Epoch 885: Loss = 206.0262, Training Accuracy = 71.91%\n",
      "Epoch 886: Loss = 206.5327, Training Accuracy = 71.75%\n",
      "Epoch 887: Loss = 206.1376, Training Accuracy = 71.81%\n",
      "Epoch 888: Loss = 205.6607, Training Accuracy = 71.94%\n",
      "Epoch 889: Loss = 205.6633, Training Accuracy = 71.69%\n",
      "Epoch 890: Loss = 205.5740, Training Accuracy = 71.94%\n",
      "Epoch 891: Loss = 204.3687, Training Accuracy = 71.64%\n",
      "Epoch 892: Loss = 204.1615, Training Accuracy = 71.49%\n",
      "Epoch 893: Loss = 203.7211, Training Accuracy = 71.72%\n",
      "Epoch 894: Loss = 203.6790, Training Accuracy = 71.39%\n",
      "Epoch 895: Loss = 202.4048, Training Accuracy = 72.08%\n",
      "Epoch 896: Loss = 203.1884, Training Accuracy = 71.43%\n",
      "Epoch 897: Loss = 202.3846, Training Accuracy = 71.66%\n",
      "Epoch 898: Loss = 201.6908, Training Accuracy = 71.70%\n",
      "Epoch 899: Loss = 201.2861, Training Accuracy = 71.78%\n",
      "Epoch 900: Loss = 201.3080, Training Accuracy = 72.21%\n",
      "Epoch 901: Loss = 201.0520, Training Accuracy = 72.17%\n",
      "Epoch 902: Loss = 202.2584, Training Accuracy = 72.10%\n",
      "Epoch 903: Loss = 201.6760, Training Accuracy = 71.98%\n",
      "Epoch 904: Loss = 201.2546, Training Accuracy = 72.18%\n",
      "Epoch 905: Loss = 202.7646, Training Accuracy = 71.91%\n",
      "Epoch 906: Loss = 202.3640, Training Accuracy = 72.05%\n",
      "Epoch 907: Loss = 202.4080, Training Accuracy = 72.03%\n",
      "Epoch 908: Loss = 201.7641, Training Accuracy = 72.17%\n",
      "Epoch 909: Loss = 201.6128, Training Accuracy = 71.99%\n",
      "Epoch 910: Loss = 201.8995, Training Accuracy = 72.22%\n",
      "Epoch 911: Loss = 201.7443, Training Accuracy = 72.19%\n",
      "Epoch 912: Loss = 200.8364, Training Accuracy = 72.27%\n",
      "Epoch 913: Loss = 202.0965, Training Accuracy = 72.30%\n",
      "Epoch 914: Loss = 202.5633, Training Accuracy = 72.02%\n",
      "Epoch 915: Loss = 202.3074, Training Accuracy = 72.08%\n",
      "Epoch 916: Loss = 202.4049, Training Accuracy = 72.24%\n",
      "Epoch 917: Loss = 202.9256, Training Accuracy = 72.19%\n",
      "Epoch 918: Loss = 201.9191, Training Accuracy = 72.33%\n",
      "Epoch 919: Loss = 201.7557, Training Accuracy = 72.25%\n",
      "Epoch 920: Loss = 202.4107, Training Accuracy = 72.35%\n",
      "Epoch 921: Loss = 201.7676, Training Accuracy = 72.25%\n",
      "Epoch 922: Loss = 202.0331, Training Accuracy = 72.09%\n",
      "Epoch 923: Loss = 202.1261, Training Accuracy = 72.58%\n",
      "Epoch 924: Loss = 202.0956, Training Accuracy = 72.67%\n",
      "Epoch 925: Loss = 202.1657, Training Accuracy = 72.38%\n",
      "Epoch 926: Loss = 202.0352, Training Accuracy = 72.42%\n",
      "Epoch 927: Loss = 202.2050, Training Accuracy = 72.96%\n",
      "Epoch 928: Loss = 202.0159, Training Accuracy = 72.40%\n",
      "Epoch 929: Loss = 202.0303, Training Accuracy = 72.33%\n",
      "Epoch 930: Loss = 202.2709, Training Accuracy = 72.56%\n",
      "Epoch 931: Loss = 203.1882, Training Accuracy = 72.00%\n",
      "Epoch 932: Loss = 202.4440, Training Accuracy = 72.96%\n",
      "Epoch 933: Loss = 202.7182, Training Accuracy = 72.89%\n",
      "Epoch 934: Loss = 202.7685, Training Accuracy = 72.80%\n",
      "Epoch 935: Loss = 203.6144, Training Accuracy = 71.65%\n",
      "Epoch 936: Loss = 202.1844, Training Accuracy = 71.79%\n",
      "Epoch 937: Loss = 202.6800, Training Accuracy = 71.77%\n",
      "Epoch 938: Loss = 203.6006, Training Accuracy = 71.81%\n",
      "Epoch 939: Loss = 203.7115, Training Accuracy = 71.74%\n",
      "Epoch 940: Loss = 203.2847, Training Accuracy = 71.72%\n",
      "Epoch 941: Loss = 203.2176, Training Accuracy = 72.40%\n",
      "Epoch 942: Loss = 202.3629, Training Accuracy = 72.08%\n",
      "Epoch 943: Loss = 203.1963, Training Accuracy = 72.00%\n",
      "Epoch 944: Loss = 203.1720, Training Accuracy = 72.18%\n",
      "Epoch 945: Loss = 203.2475, Training Accuracy = 72.50%\n",
      "Epoch 946: Loss = 204.1239, Training Accuracy = 72.13%\n",
      "Epoch 947: Loss = 203.2016, Training Accuracy = 72.14%\n",
      "Epoch 948: Loss = 203.3965, Training Accuracy = 72.10%\n",
      "Epoch 949: Loss = 202.6856, Training Accuracy = 72.94%\n",
      "Epoch 950: Loss = 203.3770, Training Accuracy = 72.80%\n",
      "Epoch 951: Loss = 203.3775, Training Accuracy = 73.04%\n",
      "Epoch 952: Loss = 203.9566, Training Accuracy = 72.70%\n",
      "Epoch 953: Loss = 203.2971, Training Accuracy = 72.19%\n",
      "Epoch 954: Loss = 202.8627, Training Accuracy = 72.97%\n",
      "Epoch 955: Loss = 203.5183, Training Accuracy = 72.90%\n",
      "Epoch 956: Loss = 203.3779, Training Accuracy = 72.91%\n",
      "Epoch 957: Loss = 202.2763, Training Accuracy = 72.84%\n",
      "Epoch 958: Loss = 201.6833, Training Accuracy = 72.97%\n",
      "Epoch 959: Loss = 201.2577, Training Accuracy = 73.10%\n",
      "Epoch 960: Loss = 201.5771, Training Accuracy = 73.14%\n",
      "Epoch 961: Loss = 202.0188, Training Accuracy = 73.09%\n",
      "Epoch 962: Loss = 202.3827, Training Accuracy = 72.85%\n",
      "Epoch 963: Loss = 202.1290, Training Accuracy = 72.42%\n",
      "Epoch 964: Loss = 201.3478, Training Accuracy = 72.46%\n",
      "Epoch 965: Loss = 200.7991, Training Accuracy = 72.54%\n",
      "Epoch 966: Loss = 201.4866, Training Accuracy = 72.46%\n",
      "Epoch 967: Loss = 202.6144, Training Accuracy = 72.33%\n",
      "Epoch 968: Loss = 203.1335, Training Accuracy = 72.20%\n",
      "Epoch 969: Loss = 202.7267, Training Accuracy = 72.14%\n",
      "Epoch 970: Loss = 201.1912, Training Accuracy = 73.37%\n",
      "Epoch 971: Loss = 201.3061, Training Accuracy = 73.29%\n",
      "Epoch 972: Loss = 202.2172, Training Accuracy = 73.28%\n",
      "Epoch 973: Loss = 202.0740, Training Accuracy = 73.27%\n",
      "Epoch 974: Loss = 203.7573, Training Accuracy = 73.02%\n",
      "Epoch 975: Loss = 203.9298, Training Accuracy = 72.93%\n",
      "Epoch 976: Loss = 202.3267, Training Accuracy = 73.08%\n",
      "Epoch 977: Loss = 201.3988, Training Accuracy = 73.15%\n",
      "Epoch 978: Loss = 201.6954, Training Accuracy = 73.20%\n",
      "Epoch 979: Loss = 201.7551, Training Accuracy = 73.04%\n",
      "Epoch 980: Loss = 201.0544, Training Accuracy = 73.04%\n",
      "Epoch 981: Loss = 201.3152, Training Accuracy = 73.10%\n",
      "Epoch 982: Loss = 201.8202, Training Accuracy = 73.07%\n",
      "Epoch 983: Loss = 201.5968, Training Accuracy = 73.15%\n",
      "Epoch 984: Loss = 202.5112, Training Accuracy = 73.14%\n",
      "Epoch 985: Loss = 202.5503, Training Accuracy = 73.17%\n",
      "Epoch 986: Loss = 201.9574, Training Accuracy = 72.83%\n",
      "Epoch 987: Loss = 202.9533, Training Accuracy = 72.91%\n",
      "Epoch 988: Loss = 202.7795, Training Accuracy = 72.97%\n",
      "Epoch 989: Loss = 201.8474, Training Accuracy = 73.29%\n",
      "Epoch 990: Loss = 201.5253, Training Accuracy = 73.36%\n",
      "Epoch 991: Loss = 202.0617, Training Accuracy = 73.28%\n",
      "Epoch 992: Loss = 201.3308, Training Accuracy = 72.98%\n",
      "Epoch 993: Loss = 201.8319, Training Accuracy = 73.07%\n",
      "Epoch 994: Loss = 202.2375, Training Accuracy = 73.01%\n",
      "Epoch 995: Loss = 200.9041, Training Accuracy = 73.13%\n",
      "Epoch 996: Loss = 201.5271, Training Accuracy = 73.10%\n",
      "Epoch 997: Loss = 202.1177, Training Accuracy = 72.98%\n",
      "Epoch 998: Loss = 201.9103, Training Accuracy = 72.99%\n",
      "Epoch 999: Loss = 201.6806, Training Accuracy = 73.10%\n",
      "Epoch 1000: Loss = 202.1297, Training Accuracy = 73.32%\n",
      "Epoch 1001: Loss = 202.8486, Training Accuracy = 73.03%\n",
      "Epoch 1002: Loss = 202.7867, Training Accuracy = 73.05%\n",
      "Epoch 1003: Loss = 202.7088, Training Accuracy = 72.87%\n",
      "Epoch 1004: Loss = 201.8925, Training Accuracy = 72.83%\n",
      "Epoch 1005: Loss = 202.5633, Training Accuracy = 72.84%\n",
      "Epoch 1006: Loss = 202.2993, Training Accuracy = 72.82%\n",
      "Epoch 1007: Loss = 201.3405, Training Accuracy = 72.90%\n",
      "Epoch 1008: Loss = 202.5982, Training Accuracy = 72.82%\n",
      "Epoch 1009: Loss = 202.0401, Training Accuracy = 72.81%\n",
      "Epoch 1010: Loss = 201.6160, Training Accuracy = 73.28%\n",
      "Epoch 1011: Loss = 201.4492, Training Accuracy = 72.47%\n",
      "Epoch 1012: Loss = 200.9017, Training Accuracy = 72.52%\n",
      "Epoch 1013: Loss = 202.4992, Training Accuracy = 72.61%\n",
      "Epoch 1014: Loss = 202.2526, Training Accuracy = 72.71%\n",
      "Epoch 1015: Loss = 202.2381, Training Accuracy = 73.00%\n",
      "Epoch 1016: Loss = 202.2131, Training Accuracy = 73.00%\n",
      "Epoch 1017: Loss = 202.5368, Training Accuracy = 72.93%\n",
      "Epoch 1018: Loss = 201.8520, Training Accuracy = 72.95%\n",
      "Epoch 1019: Loss = 202.4652, Training Accuracy = 72.65%\n",
      "Epoch 1020: Loss = 202.4160, Training Accuracy = 73.06%\n",
      "Epoch 1021: Loss = 202.1022, Training Accuracy = 73.20%\n",
      "Epoch 1022: Loss = 201.4464, Training Accuracy = 73.18%\n",
      "Epoch 1023: Loss = 200.5281, Training Accuracy = 73.10%\n",
      "Epoch 1024: Loss = 200.5393, Training Accuracy = 73.07%\n",
      "Epoch 1025: Loss = 200.6899, Training Accuracy = 73.23%\n",
      "Epoch 1026: Loss = 201.0845, Training Accuracy = 73.31%\n",
      "Epoch 1027: Loss = 201.2284, Training Accuracy = 73.27%\n",
      "Epoch 1028: Loss = 201.5445, Training Accuracy = 72.90%\n",
      "Epoch 1029: Loss = 201.6641, Training Accuracy = 73.57%\n",
      "Epoch 1030: Loss = 201.7357, Training Accuracy = 73.09%\n",
      "Epoch 1031: Loss = 202.1267, Training Accuracy = 72.77%\n",
      "Epoch 1032: Loss = 202.3860, Training Accuracy = 72.77%\n",
      "Epoch 1033: Loss = 202.2348, Training Accuracy = 72.76%\n",
      "Epoch 1034: Loss = 201.7815, Training Accuracy = 73.30%\n",
      "Epoch 1035: Loss = 201.9234, Training Accuracy = 73.31%\n",
      "Epoch 1036: Loss = 202.2299, Training Accuracy = 73.43%\n",
      "Epoch 1037: Loss = 201.7874, Training Accuracy = 73.36%\n",
      "Epoch 1038: Loss = 201.9928, Training Accuracy = 73.34%\n",
      "Epoch 1039: Loss = 202.7143, Training Accuracy = 73.55%\n",
      "Epoch 1040: Loss = 202.4405, Training Accuracy = 73.12%\n",
      "Epoch 1041: Loss = 202.4112, Training Accuracy = 73.16%\n",
      "Epoch 1042: Loss = 202.9158, Training Accuracy = 73.63%\n",
      "Epoch 1043: Loss = 201.3114, Training Accuracy = 73.73%\n",
      "Epoch 1044: Loss = 202.9866, Training Accuracy = 72.90%\n",
      "Epoch 1045: Loss = 203.1398, Training Accuracy = 73.10%\n",
      "Epoch 1046: Loss = 203.3063, Training Accuracy = 73.21%\n",
      "Epoch 1047: Loss = 203.9655, Training Accuracy = 73.26%\n",
      "Epoch 1048: Loss = 203.8199, Training Accuracy = 73.35%\n",
      "Epoch 1049: Loss = 203.1249, Training Accuracy = 73.46%\n",
      "Epoch 1050: Loss = 203.1351, Training Accuracy = 73.44%\n",
      "Epoch 1051: Loss = 204.1730, Training Accuracy = 73.48%\n",
      "Epoch 1052: Loss = 203.8084, Training Accuracy = 73.40%\n",
      "Epoch 1053: Loss = 204.0688, Training Accuracy = 73.58%\n",
      "Epoch 1054: Loss = 204.1708, Training Accuracy = 73.54%\n",
      "Epoch 1055: Loss = 204.0239, Training Accuracy = 73.41%\n",
      "Epoch 1056: Loss = 202.6726, Training Accuracy = 73.38%\n",
      "Epoch 1057: Loss = 203.9014, Training Accuracy = 73.67%\n",
      "Epoch 1058: Loss = 204.0217, Training Accuracy = 73.53%\n",
      "Epoch 1059: Loss = 203.7598, Training Accuracy = 73.45%\n",
      "Epoch 1060: Loss = 203.1287, Training Accuracy = 73.50%\n",
      "Epoch 1061: Loss = 203.4730, Training Accuracy = 73.48%\n",
      "Epoch 1062: Loss = 203.6545, Training Accuracy = 73.37%\n",
      "Epoch 1063: Loss = 203.7141, Training Accuracy = 73.26%\n",
      "Epoch 1064: Loss = 204.0639, Training Accuracy = 73.20%\n",
      "Epoch 1065: Loss = 204.1286, Training Accuracy = 73.31%\n",
      "Epoch 1066: Loss = 203.7621, Training Accuracy = 73.52%\n",
      "Epoch 1067: Loss = 204.0970, Training Accuracy = 73.21%\n",
      "Epoch 1068: Loss = 204.5057, Training Accuracy = 73.27%\n",
      "Epoch 1069: Loss = 203.9230, Training Accuracy = 73.23%\n",
      "Epoch 1070: Loss = 203.5973, Training Accuracy = 73.72%\n",
      "Epoch 1071: Loss = 203.3072, Training Accuracy = 73.00%\n",
      "Epoch 1072: Loss = 202.4545, Training Accuracy = 73.69%\n",
      "Epoch 1073: Loss = 202.2004, Training Accuracy = 73.54%\n",
      "Epoch 1074: Loss = 201.5187, Training Accuracy = 73.63%\n",
      "Epoch 1075: Loss = 202.6627, Training Accuracy = 73.94%\n",
      "Epoch 1076: Loss = 203.2811, Training Accuracy = 73.65%\n",
      "Epoch 1077: Loss = 203.1034, Training Accuracy = 73.66%\n",
      "Epoch 1078: Loss = 200.9126, Training Accuracy = 73.76%\n",
      "Epoch 1079: Loss = 200.5534, Training Accuracy = 73.82%\n",
      "Epoch 1080: Loss = 200.9004, Training Accuracy = 74.25%\n",
      "Epoch 1081: Loss = 200.0963, Training Accuracy = 74.23%\n",
      "Epoch 1082: Loss = 201.3911, Training Accuracy = 73.68%\n",
      "Epoch 1083: Loss = 201.7101, Training Accuracy = 73.73%\n",
      "Epoch 1084: Loss = 200.8498, Training Accuracy = 73.84%\n",
      "Epoch 1085: Loss = 201.0971, Training Accuracy = 74.03%\n",
      "Epoch 1086: Loss = 201.9554, Training Accuracy = 73.89%\n",
      "Epoch 1087: Loss = 201.9362, Training Accuracy = 73.68%\n",
      "Epoch 1088: Loss = 201.7307, Training Accuracy = 73.71%\n",
      "Epoch 1089: Loss = 201.4314, Training Accuracy = 73.77%\n",
      "Epoch 1090: Loss = 201.6382, Training Accuracy = 73.55%\n",
      "Epoch 1091: Loss = 201.4998, Training Accuracy = 73.53%\n",
      "Epoch 1092: Loss = 201.6704, Training Accuracy = 73.65%\n",
      "Epoch 1093: Loss = 201.8360, Training Accuracy = 73.93%\n",
      "Epoch 1094: Loss = 201.2941, Training Accuracy = 73.90%\n",
      "Epoch 1095: Loss = 201.9686, Training Accuracy = 73.84%\n",
      "Epoch 1096: Loss = 201.7803, Training Accuracy = 73.93%\n",
      "Epoch 1097: Loss = 201.3158, Training Accuracy = 73.90%\n",
      "Epoch 1098: Loss = 200.4763, Training Accuracy = 73.66%\n",
      "Epoch 1099: Loss = 201.2259, Training Accuracy = 73.75%\n",
      "Epoch 1100: Loss = 201.9998, Training Accuracy = 73.80%\n",
      "Epoch 1101: Loss = 201.5087, Training Accuracy = 73.79%\n",
      "Epoch 1102: Loss = 202.1976, Training Accuracy = 73.94%\n",
      "Epoch 1103: Loss = 201.7617, Training Accuracy = 73.61%\n",
      "Epoch 1104: Loss = 201.1833, Training Accuracy = 73.70%\n",
      "Epoch 1105: Loss = 201.5387, Training Accuracy = 73.62%\n",
      "Epoch 1106: Loss = 201.7238, Training Accuracy = 73.70%\n",
      "Epoch 1107: Loss = 201.7257, Training Accuracy = 73.78%\n",
      "Epoch 1108: Loss = 201.4689, Training Accuracy = 73.81%\n",
      "Epoch 1109: Loss = 201.4645, Training Accuracy = 73.37%\n",
      "Epoch 1110: Loss = 201.4382, Training Accuracy = 73.70%\n",
      "Epoch 1111: Loss = 202.1622, Training Accuracy = 73.25%\n",
      "Epoch 1112: Loss = 201.5946, Training Accuracy = 73.87%\n",
      "Epoch 1113: Loss = 201.6850, Training Accuracy = 73.68%\n",
      "Epoch 1114: Loss = 202.0316, Training Accuracy = 73.86%\n",
      "Epoch 1115: Loss = 201.9188, Training Accuracy = 73.91%\n",
      "Epoch 1116: Loss = 201.8693, Training Accuracy = 73.99%\n",
      "Epoch 1117: Loss = 201.5436, Training Accuracy = 74.16%\n",
      "Epoch 1118: Loss = 201.8915, Training Accuracy = 73.80%\n",
      "Epoch 1119: Loss = 201.9022, Training Accuracy = 72.79%\n",
      "Epoch 1120: Loss = 202.1322, Training Accuracy = 73.91%\n",
      "Epoch 1121: Loss = 200.8061, Training Accuracy = 73.34%\n",
      "Epoch 1122: Loss = 201.4221, Training Accuracy = 73.32%\n",
      "Epoch 1123: Loss = 200.7652, Training Accuracy = 73.16%\n",
      "Epoch 1124: Loss = 201.2848, Training Accuracy = 73.53%\n",
      "Epoch 1125: Loss = 201.3676, Training Accuracy = 74.05%\n",
      "Epoch 1126: Loss = 202.0941, Training Accuracy = 74.04%\n",
      "Epoch 1127: Loss = 202.6834, Training Accuracy = 74.07%\n",
      "Epoch 1128: Loss = 202.5543, Training Accuracy = 74.04%\n",
      "Epoch 1129: Loss = 202.2389, Training Accuracy = 73.76%\n",
      "Epoch 1130: Loss = 200.9185, Training Accuracy = 73.92%\n",
      "Epoch 1131: Loss = 200.8481, Training Accuracy = 73.97%\n",
      "Epoch 1132: Loss = 202.0063, Training Accuracy = 73.79%\n",
      "Epoch 1133: Loss = 201.7743, Training Accuracy = 73.83%\n",
      "Epoch 1134: Loss = 201.4655, Training Accuracy = 73.79%\n",
      "Epoch 1135: Loss = 202.2265, Training Accuracy = 73.80%\n",
      "Epoch 1136: Loss = 203.2548, Training Accuracy = 74.06%\n",
      "Epoch 1137: Loss = 203.0843, Training Accuracy = 73.99%\n",
      "Epoch 1138: Loss = 202.5476, Training Accuracy = 73.68%\n",
      "Epoch 1139: Loss = 202.4359, Training Accuracy = 74.06%\n",
      "Epoch 1140: Loss = 202.5012, Training Accuracy = 73.75%\n",
      "Epoch 1141: Loss = 202.1378, Training Accuracy = 73.77%\n",
      "Epoch 1142: Loss = 202.9994, Training Accuracy = 74.05%\n",
      "Epoch 1143: Loss = 202.5977, Training Accuracy = 73.72%\n",
      "Epoch 1144: Loss = 202.2980, Training Accuracy = 74.09%\n",
      "Epoch 1145: Loss = 202.5508, Training Accuracy = 73.84%\n",
      "Epoch 1146: Loss = 203.0300, Training Accuracy = 73.91%\n",
      "Epoch 1147: Loss = 202.2720, Training Accuracy = 73.76%\n",
      "Epoch 1148: Loss = 202.3841, Training Accuracy = 73.84%\n",
      "Epoch 1149: Loss = 202.9273, Training Accuracy = 73.77%\n",
      "Epoch 1150: Loss = 202.9857, Training Accuracy = 73.79%\n",
      "Epoch 1151: Loss = 202.2013, Training Accuracy = 73.77%\n",
      "Epoch 1152: Loss = 201.7353, Training Accuracy = 73.93%\n",
      "Epoch 1153: Loss = 201.1577, Training Accuracy = 73.79%\n",
      "Epoch 1154: Loss = 201.0958, Training Accuracy = 73.70%\n",
      "Epoch 1155: Loss = 201.1407, Training Accuracy = 73.70%\n",
      "Epoch 1156: Loss = 201.3614, Training Accuracy = 73.60%\n",
      "Epoch 1157: Loss = 201.0645, Training Accuracy = 73.60%\n",
      "Epoch 1158: Loss = 202.1806, Training Accuracy = 73.47%\n",
      "Epoch 1159: Loss = 201.9877, Training Accuracy = 73.84%\n",
      "Epoch 1160: Loss = 202.2858, Training Accuracy = 73.30%\n",
      "Epoch 1161: Loss = 201.9335, Training Accuracy = 74.03%\n",
      "Epoch 1162: Loss = 202.2858, Training Accuracy = 73.04%\n",
      "Epoch 1163: Loss = 201.7363, Training Accuracy = 73.34%\n",
      "Epoch 1164: Loss = 201.5792, Training Accuracy = 73.27%\n",
      "Epoch 1165: Loss = 202.5313, Training Accuracy = 73.79%\n",
      "Epoch 1166: Loss = 202.7334, Training Accuracy = 73.71%\n",
      "Epoch 1167: Loss = 202.7334, Training Accuracy = 73.72%\n",
      "Epoch 1168: Loss = 202.1971, Training Accuracy = 73.80%\n",
      "Epoch 1169: Loss = 202.2739, Training Accuracy = 73.80%\n",
      "Epoch 1170: Loss = 201.9726, Training Accuracy = 74.00%\n",
      "Epoch 1171: Loss = 203.0503, Training Accuracy = 74.18%\n",
      "Epoch 1172: Loss = 202.2051, Training Accuracy = 73.47%\n",
      "Epoch 1173: Loss = 202.9951, Training Accuracy = 74.25%\n",
      "Epoch 1174: Loss = 203.3145, Training Accuracy = 74.43%\n",
      "Epoch 1175: Loss = 203.0553, Training Accuracy = 74.07%\n",
      "Epoch 1176: Loss = 203.1635, Training Accuracy = 73.94%\n",
      "Epoch 1177: Loss = 203.4740, Training Accuracy = 74.54%\n",
      "Epoch 1178: Loss = 203.8492, Training Accuracy = 74.57%\n",
      "Epoch 1179: Loss = 204.1835, Training Accuracy = 73.87%\n",
      "Epoch 1180: Loss = 203.1607, Training Accuracy = 73.91%\n",
      "Epoch 1181: Loss = 203.7416, Training Accuracy = 73.95%\n",
      "Epoch 1182: Loss = 203.6140, Training Accuracy = 74.27%\n",
      "Epoch 1183: Loss = 204.0676, Training Accuracy = 74.37%\n",
      "Epoch 1184: Loss = 204.0665, Training Accuracy = 73.84%\n",
      "Epoch 1185: Loss = 203.7749, Training Accuracy = 74.22%\n",
      "Epoch 1186: Loss = 203.9821, Training Accuracy = 74.12%\n",
      "Epoch 1187: Loss = 203.8131, Training Accuracy = 73.89%\n",
      "Epoch 1188: Loss = 202.8087, Training Accuracy = 74.30%\n",
      "Epoch 1189: Loss = 202.5305, Training Accuracy = 74.29%\n",
      "Epoch 1190: Loss = 202.8752, Training Accuracy = 74.26%\n",
      "Epoch 1191: Loss = 201.4785, Training Accuracy = 74.38%\n",
      "Epoch 1192: Loss = 201.2718, Training Accuracy = 74.51%\n",
      "Epoch 1193: Loss = 200.9521, Training Accuracy = 74.65%\n",
      "Epoch 1194: Loss = 202.5726, Training Accuracy = 74.30%\n",
      "Epoch 1195: Loss = 203.0033, Training Accuracy = 74.22%\n",
      "Epoch 1196: Loss = 203.4917, Training Accuracy = 74.55%\n",
      "Epoch 1197: Loss = 203.6064, Training Accuracy = 73.80%\n",
      "Epoch 1198: Loss = 202.4024, Training Accuracy = 74.12%\n",
      "Epoch 1199: Loss = 203.1871, Training Accuracy = 74.02%\n",
      "Epoch 1200: Loss = 203.2408, Training Accuracy = 74.30%\n",
      "Epoch 1201: Loss = 203.0373, Training Accuracy = 74.25%\n",
      "Epoch 1202: Loss = 202.6313, Training Accuracy = 73.88%\n",
      "Epoch 1203: Loss = 202.3584, Training Accuracy = 74.33%\n",
      "Epoch 1204: Loss = 203.0524, Training Accuracy = 73.81%\n",
      "Epoch 1205: Loss = 203.4558, Training Accuracy = 74.22%\n",
      "Epoch 1206: Loss = 203.4021, Training Accuracy = 74.02%\n",
      "Epoch 1207: Loss = 203.0865, Training Accuracy = 73.87%\n",
      "Epoch 1208: Loss = 203.3336, Training Accuracy = 73.79%\n",
      "Epoch 1209: Loss = 203.7176, Training Accuracy = 74.61%\n",
      "Epoch 1210: Loss = 203.1772, Training Accuracy = 74.38%\n",
      "Epoch 1211: Loss = 202.2520, Training Accuracy = 73.94%\n",
      "Epoch 1212: Loss = 202.8293, Training Accuracy = 73.84%\n",
      "Epoch 1213: Loss = 203.1421, Training Accuracy = 73.90%\n",
      "Epoch 1214: Loss = 203.7045, Training Accuracy = 73.79%\n",
      "Epoch 1215: Loss = 203.3554, Training Accuracy = 73.78%\n",
      "Epoch 1216: Loss = 203.0824, Training Accuracy = 73.94%\n",
      "Epoch 1217: Loss = 203.0266, Training Accuracy = 74.08%\n",
      "Epoch 1218: Loss = 202.9501, Training Accuracy = 74.03%\n",
      "Epoch 1219: Loss = 203.1199, Training Accuracy = 74.08%\n",
      "Epoch 1220: Loss = 202.7716, Training Accuracy = 73.94%\n",
      "Epoch 1221: Loss = 202.7273, Training Accuracy = 73.97%\n",
      "Epoch 1222: Loss = 202.7787, Training Accuracy = 74.20%\n",
      "Epoch 1223: Loss = 202.2135, Training Accuracy = 74.36%\n",
      "Epoch 1224: Loss = 203.0668, Training Accuracy = 74.23%\n",
      "Epoch 1225: Loss = 202.3614, Training Accuracy = 74.10%\n",
      "Epoch 1226: Loss = 203.0136, Training Accuracy = 74.14%\n",
      "Epoch 1227: Loss = 202.1470, Training Accuracy = 74.23%\n",
      "Epoch 1228: Loss = 203.2897, Training Accuracy = 73.45%\n",
      "Epoch 1229: Loss = 201.9064, Training Accuracy = 73.82%\n",
      "Epoch 1230: Loss = 202.7640, Training Accuracy = 74.06%\n",
      "Epoch 1231: Loss = 202.4044, Training Accuracy = 74.05%\n",
      "Epoch 1232: Loss = 202.0552, Training Accuracy = 74.07%\n",
      "Epoch 1233: Loss = 201.5711, Training Accuracy = 73.98%\n",
      "Epoch 1234: Loss = 201.5674, Training Accuracy = 74.39%\n",
      "Epoch 1235: Loss = 201.8182, Training Accuracy = 74.43%\n",
      "Epoch 1236: Loss = 202.1710, Training Accuracy = 74.62%\n",
      "Epoch 1237: Loss = 202.0374, Training Accuracy = 74.64%\n",
      "Epoch 1238: Loss = 200.0891, Training Accuracy = 74.79%\n",
      "Epoch 1239: Loss = 201.5101, Training Accuracy = 74.70%\n",
      "Epoch 1240: Loss = 201.0573, Training Accuracy = 74.29%\n",
      "Epoch 1241: Loss = 202.1019, Training Accuracy = 74.20%\n",
      "Epoch 1242: Loss = 201.3148, Training Accuracy = 74.10%\n",
      "Epoch 1243: Loss = 201.6488, Training Accuracy = 74.10%\n",
      "Epoch 1244: Loss = 200.9803, Training Accuracy = 74.03%\n",
      "Epoch 1245: Loss = 201.4082, Training Accuracy = 74.05%\n",
      "Epoch 1246: Loss = 201.3851, Training Accuracy = 74.85%\n",
      "Epoch 1247: Loss = 202.3421, Training Accuracy = 74.54%\n",
      "Epoch 1248: Loss = 201.4594, Training Accuracy = 73.91%\n",
      "Epoch 1249: Loss = 201.1534, Training Accuracy = 74.01%\n",
      "Epoch 1250: Loss = 201.7209, Training Accuracy = 73.88%\n",
      "Epoch 1251: Loss = 202.1588, Training Accuracy = 74.32%\n",
      "Epoch 1252: Loss = 202.2843, Training Accuracy = 73.72%\n",
      "Epoch 1253: Loss = 201.9177, Training Accuracy = 73.50%\n",
      "Epoch 1254: Loss = 202.8126, Training Accuracy = 73.63%\n",
      "Epoch 1255: Loss = 202.4214, Training Accuracy = 73.80%\n",
      "Epoch 1256: Loss = 202.7778, Training Accuracy = 73.55%\n",
      "Epoch 1257: Loss = 203.2379, Training Accuracy = 73.51%\n",
      "Epoch 1258: Loss = 202.4375, Training Accuracy = 74.62%\n",
      "Epoch 1259: Loss = 202.4244, Training Accuracy = 74.63%\n",
      "Epoch 1260: Loss = 202.9230, Training Accuracy = 73.80%\n",
      "Epoch 1261: Loss = 203.9680, Training Accuracy = 74.51%\n",
      "Epoch 1262: Loss = 203.4723, Training Accuracy = 73.91%\n",
      "Epoch 1263: Loss = 202.7120, Training Accuracy = 73.82%\n",
      "Epoch 1264: Loss = 203.0770, Training Accuracy = 73.70%\n",
      "Epoch 1265: Loss = 202.6676, Training Accuracy = 73.85%\n",
      "Epoch 1266: Loss = 203.0238, Training Accuracy = 73.79%\n",
      "Epoch 1267: Loss = 201.7329, Training Accuracy = 74.01%\n",
      "Epoch 1268: Loss = 201.9290, Training Accuracy = 73.96%\n",
      "Epoch 1269: Loss = 203.1982, Training Accuracy = 74.19%\n",
      "Epoch 1270: Loss = 203.1254, Training Accuracy = 73.71%\n",
      "Epoch 1271: Loss = 203.0668, Training Accuracy = 74.22%\n",
      "Epoch 1272: Loss = 201.6587, Training Accuracy = 73.95%\n",
      "Epoch 1273: Loss = 201.1224, Training Accuracy = 73.98%\n",
      "Epoch 1274: Loss = 201.5052, Training Accuracy = 73.93%\n",
      "Epoch 1275: Loss = 201.5544, Training Accuracy = 73.81%\n",
      "Epoch 1276: Loss = 202.1609, Training Accuracy = 73.92%\n",
      "Epoch 1277: Loss = 201.9409, Training Accuracy = 73.91%\n",
      "Epoch 1278: Loss = 202.6902, Training Accuracy = 73.74%\n",
      "Epoch 1279: Loss = 202.2418, Training Accuracy = 73.83%\n",
      "Epoch 1280: Loss = 202.7826, Training Accuracy = 73.90%\n",
      "Epoch 1281: Loss = 202.3250, Training Accuracy = 74.13%\n",
      "Epoch 1282: Loss = 201.8303, Training Accuracy = 73.93%\n",
      "Epoch 1283: Loss = 201.6689, Training Accuracy = 73.98%\n",
      "Epoch 1284: Loss = 202.1071, Training Accuracy = 74.19%\n",
      "Epoch 1285: Loss = 201.9987, Training Accuracy = 73.55%\n",
      "Epoch 1286: Loss = 201.4294, Training Accuracy = 73.63%\n",
      "Epoch 1287: Loss = 201.7302, Training Accuracy = 73.82%\n",
      "Epoch 1288: Loss = 201.6142, Training Accuracy = 73.66%\n",
      "Epoch 1289: Loss = 202.5075, Training Accuracy = 73.50%\n",
      "Epoch 1290: Loss = 201.6802, Training Accuracy = 73.84%\n",
      "Epoch 1291: Loss = 202.7832, Training Accuracy = 73.72%\n",
      "Epoch 1292: Loss = 202.7377, Training Accuracy = 74.69%\n",
      "Epoch 1293: Loss = 202.7658, Training Accuracy = 74.13%\n",
      "Epoch 1294: Loss = 202.3567, Training Accuracy = 74.54%\n",
      "Epoch 1295: Loss = 202.6519, Training Accuracy = 74.51%\n",
      "Epoch 1296: Loss = 202.3327, Training Accuracy = 74.39%\n",
      "Epoch 1297: Loss = 202.7280, Training Accuracy = 73.89%\n",
      "Epoch 1298: Loss = 202.3034, Training Accuracy = 74.27%\n",
      "Epoch 1299: Loss = 201.8454, Training Accuracy = 73.67%\n",
      "Epoch 1300: Loss = 201.0107, Training Accuracy = 74.11%\n",
      "Epoch 1301: Loss = 200.7743, Training Accuracy = 74.18%\n",
      "Epoch 1302: Loss = 201.2222, Training Accuracy = 74.74%\n",
      "Epoch 1303: Loss = 201.5543, Training Accuracy = 74.55%\n",
      "Epoch 1304: Loss = 201.8676, Training Accuracy = 74.55%\n",
      "Epoch 1305: Loss = 201.6526, Training Accuracy = 74.59%\n",
      "Epoch 1306: Loss = 202.2927, Training Accuracy = 74.51%\n",
      "Epoch 1307: Loss = 201.4628, Training Accuracy = 74.73%\n",
      "Epoch 1308: Loss = 201.9231, Training Accuracy = 74.77%\n",
      "Epoch 1309: Loss = 201.7514, Training Accuracy = 74.29%\n",
      "Epoch 1310: Loss = 202.0887, Training Accuracy = 74.95%\n",
      "Epoch 1311: Loss = 201.6266, Training Accuracy = 75.19%\n",
      "Epoch 1312: Loss = 201.9573, Training Accuracy = 74.42%\n",
      "Epoch 1313: Loss = 201.7198, Training Accuracy = 74.56%\n",
      "Epoch 1314: Loss = 201.8953, Training Accuracy = 74.52%\n",
      "Epoch 1315: Loss = 201.5319, Training Accuracy = 74.60%\n",
      "Epoch 1316: Loss = 200.3797, Training Accuracy = 74.57%\n",
      "Epoch 1317: Loss = 201.1286, Training Accuracy = 74.45%\n",
      "Epoch 1318: Loss = 200.8027, Training Accuracy = 74.55%\n",
      "Epoch 1319: Loss = 202.5216, Training Accuracy = 74.16%\n",
      "Epoch 1320: Loss = 202.0508, Training Accuracy = 74.87%\n",
      "Epoch 1321: Loss = 201.7234, Training Accuracy = 75.05%\n",
      "Epoch 1322: Loss = 200.9514, Training Accuracy = 75.18%\n",
      "Epoch 1323: Loss = 201.0898, Training Accuracy = 74.99%\n",
      "Epoch 1324: Loss = 199.4987, Training Accuracy = 75.26%\n",
      "Epoch 1325: Loss = 201.1501, Training Accuracy = 74.90%\n",
      "Epoch 1326: Loss = 201.4211, Training Accuracy = 74.80%\n",
      "Epoch 1327: Loss = 201.2358, Training Accuracy = 74.97%\n",
      "Epoch 1328: Loss = 200.8037, Training Accuracy = 75.08%\n",
      "Epoch 1329: Loss = 201.1567, Training Accuracy = 75.11%\n",
      "Epoch 1330: Loss = 200.8788, Training Accuracy = 75.17%\n",
      "Epoch 1331: Loss = 200.9859, Training Accuracy = 75.09%\n",
      "Epoch 1332: Loss = 200.5295, Training Accuracy = 75.09%\n",
      "Epoch 1333: Loss = 200.3586, Training Accuracy = 75.34%\n",
      "Epoch 1334: Loss = 199.9411, Training Accuracy = 75.35%\n",
      "Epoch 1335: Loss = 200.0316, Training Accuracy = 75.30%\n",
      "Epoch 1336: Loss = 200.3369, Training Accuracy = 75.28%\n",
      "Epoch 1337: Loss = 199.5799, Training Accuracy = 75.33%\n",
      "Epoch 1338: Loss = 199.8945, Training Accuracy = 75.42%\n",
      "Epoch 1339: Loss = 199.4512, Training Accuracy = 75.33%\n",
      "Epoch 1340: Loss = 200.0269, Training Accuracy = 75.23%\n",
      "Epoch 1341: Loss = 201.1272, Training Accuracy = 75.11%\n",
      "Epoch 1342: Loss = 201.7227, Training Accuracy = 75.20%\n",
      "Epoch 1343: Loss = 201.7117, Training Accuracy = 75.22%\n",
      "Epoch 1344: Loss = 201.6311, Training Accuracy = 75.35%\n",
      "Epoch 1345: Loss = 201.4042, Training Accuracy = 75.07%\n",
      "Epoch 1346: Loss = 201.5670, Training Accuracy = 74.85%\n",
      "Epoch 1347: Loss = 201.3884, Training Accuracy = 75.36%\n",
      "Epoch 1348: Loss = 201.5148, Training Accuracy = 75.38%\n",
      "Epoch 1349: Loss = 201.1949, Training Accuracy = 75.31%\n",
      "Epoch 1350: Loss = 200.7064, Training Accuracy = 75.21%\n",
      "Epoch 1351: Loss = 200.6881, Training Accuracy = 75.23%\n",
      "Epoch 1352: Loss = 200.4124, Training Accuracy = 75.39%\n",
      "Epoch 1353: Loss = 200.2129, Training Accuracy = 75.46%\n",
      "Epoch 1354: Loss = 199.8460, Training Accuracy = 75.44%\n",
      "Epoch 1355: Loss = 199.6008, Training Accuracy = 75.42%\n",
      "Epoch 1356: Loss = 199.9030, Training Accuracy = 75.31%\n",
      "Epoch 1357: Loss = 199.8363, Training Accuracy = 75.30%\n",
      "Epoch 1358: Loss = 199.4124, Training Accuracy = 75.34%\n",
      "Epoch 1359: Loss = 199.1580, Training Accuracy = 75.45%\n",
      "Epoch 1360: Loss = 199.6138, Training Accuracy = 75.30%\n",
      "Epoch 1361: Loss = 199.4570, Training Accuracy = 75.38%\n",
      "Epoch 1362: Loss = 200.6396, Training Accuracy = 75.39%\n",
      "Epoch 1363: Loss = 200.6060, Training Accuracy = 75.53%\n",
      "Epoch 1364: Loss = 200.3600, Training Accuracy = 75.63%\n",
      "Epoch 1365: Loss = 200.8332, Training Accuracy = 75.51%\n",
      "Epoch 1366: Loss = 200.7481, Training Accuracy = 75.53%\n",
      "Epoch 1367: Loss = 199.8337, Training Accuracy = 75.51%\n",
      "Epoch 1368: Loss = 199.5118, Training Accuracy = 75.67%\n",
      "Epoch 1369: Loss = 199.3927, Training Accuracy = 75.69%\n",
      "Epoch 1370: Loss = 199.5560, Training Accuracy = 75.66%\n",
      "Epoch 1371: Loss = 199.3862, Training Accuracy = 75.66%\n",
      "Epoch 1372: Loss = 199.4127, Training Accuracy = 75.69%\n",
      "Epoch 1373: Loss = 199.6642, Training Accuracy = 75.75%\n",
      "Epoch 1374: Loss = 199.9324, Training Accuracy = 75.74%\n",
      "Epoch 1375: Loss = 200.0047, Training Accuracy = 75.74%\n",
      "Epoch 1376: Loss = 200.1076, Training Accuracy = 75.56%\n",
      "Epoch 1377: Loss = 199.9971, Training Accuracy = 75.76%\n",
      "Epoch 1378: Loss = 199.5976, Training Accuracy = 75.59%\n",
      "Epoch 1379: Loss = 199.4615, Training Accuracy = 75.58%\n",
      "Epoch 1380: Loss = 199.0225, Training Accuracy = 75.97%\n",
      "Epoch 1381: Loss = 199.3754, Training Accuracy = 76.05%\n",
      "Epoch 1382: Loss = 199.8907, Training Accuracy = 75.57%\n",
      "Epoch 1383: Loss = 199.3384, Training Accuracy = 75.60%\n",
      "Epoch 1384: Loss = 199.2056, Training Accuracy = 75.71%\n",
      "Epoch 1385: Loss = 199.5185, Training Accuracy = 75.64%\n",
      "Epoch 1386: Loss = 199.7285, Training Accuracy = 75.62%\n",
      "Epoch 1387: Loss = 199.5601, Training Accuracy = 75.65%\n",
      "Epoch 1388: Loss = 199.5385, Training Accuracy = 75.85%\n",
      "Epoch 1389: Loss = 200.2084, Training Accuracy = 75.66%\n",
      "Epoch 1390: Loss = 199.9265, Training Accuracy = 75.71%\n",
      "Epoch 1391: Loss = 200.3544, Training Accuracy = 75.61%\n",
      "Epoch 1392: Loss = 200.0636, Training Accuracy = 75.74%\n",
      "Epoch 1393: Loss = 200.5554, Training Accuracy = 75.70%\n",
      "Epoch 1394: Loss = 199.8400, Training Accuracy = 75.85%\n",
      "Epoch 1395: Loss = 199.5428, Training Accuracy = 75.78%\n",
      "Epoch 1396: Loss = 199.5926, Training Accuracy = 75.96%\n",
      "Epoch 1397: Loss = 199.3454, Training Accuracy = 75.91%\n",
      "Epoch 1398: Loss = 198.9451, Training Accuracy = 75.87%\n",
      "Epoch 1399: Loss = 199.5871, Training Accuracy = 75.66%\n",
      "Epoch 1400: Loss = 199.5778, Training Accuracy = 75.64%\n",
      "Epoch 1401: Loss = 198.9674, Training Accuracy = 75.66%\n",
      "Epoch 1402: Loss = 198.2018, Training Accuracy = 75.69%\n",
      "Epoch 1403: Loss = 197.8555, Training Accuracy = 75.65%\n",
      "Epoch 1404: Loss = 197.9864, Training Accuracy = 75.74%\n",
      "Epoch 1405: Loss = 198.2877, Training Accuracy = 75.79%\n",
      "Epoch 1406: Loss = 198.3231, Training Accuracy = 75.91%\n",
      "Epoch 1407: Loss = 199.3002, Training Accuracy = 75.85%\n",
      "Epoch 1408: Loss = 198.8931, Training Accuracy = 75.62%\n",
      "Epoch 1409: Loss = 199.4070, Training Accuracy = 75.61%\n",
      "Epoch 1410: Loss = 199.1393, Training Accuracy = 75.53%\n",
      "Epoch 1411: Loss = 198.5933, Training Accuracy = 75.87%\n",
      "Epoch 1412: Loss = 198.5349, Training Accuracy = 75.71%\n",
      "Epoch 1413: Loss = 198.2425, Training Accuracy = 75.84%\n",
      "Epoch 1414: Loss = 198.4661, Training Accuracy = 75.99%\n",
      "Epoch 1415: Loss = 199.3951, Training Accuracy = 75.84%\n",
      "Epoch 1416: Loss = 198.8234, Training Accuracy = 75.99%\n",
      "Epoch 1417: Loss = 199.5182, Training Accuracy = 75.76%\n",
      "Epoch 1418: Loss = 199.7497, Training Accuracy = 75.71%\n",
      "Epoch 1419: Loss = 199.3641, Training Accuracy = 76.10%\n",
      "Epoch 1420: Loss = 198.5461, Training Accuracy = 75.94%\n",
      "Epoch 1421: Loss = 198.5502, Training Accuracy = 75.92%\n",
      "Epoch 1422: Loss = 199.2879, Training Accuracy = 76.09%\n",
      "Epoch 1423: Loss = 199.3413, Training Accuracy = 76.16%\n",
      "Epoch 1424: Loss = 199.0009, Training Accuracy = 76.13%\n",
      "Epoch 1425: Loss = 198.7855, Training Accuracy = 75.76%\n",
      "Epoch 1426: Loss = 199.4327, Training Accuracy = 75.66%\n",
      "Epoch 1427: Loss = 199.1104, Training Accuracy = 75.63%\n",
      "Epoch 1428: Loss = 200.0061, Training Accuracy = 76.15%\n",
      "Epoch 1429: Loss = 199.7112, Training Accuracy = 76.06%\n",
      "Epoch 1430: Loss = 199.5709, Training Accuracy = 76.19%\n",
      "Epoch 1431: Loss = 199.9120, Training Accuracy = 76.07%\n",
      "Epoch 1432: Loss = 199.1511, Training Accuracy = 76.09%\n",
      "Epoch 1433: Loss = 199.1222, Training Accuracy = 76.05%\n",
      "Epoch 1434: Loss = 199.5292, Training Accuracy = 76.12%\n",
      "Epoch 1435: Loss = 199.7757, Training Accuracy = 76.07%\n",
      "Epoch 1436: Loss = 199.7881, Training Accuracy = 76.07%\n",
      "Epoch 1437: Loss = 200.2340, Training Accuracy = 75.94%\n",
      "Epoch 1438: Loss = 199.8325, Training Accuracy = 76.03%\n",
      "Epoch 1439: Loss = 199.4819, Training Accuracy = 76.23%\n",
      "Epoch 1440: Loss = 198.9498, Training Accuracy = 76.00%\n",
      "Epoch 1441: Loss = 199.5825, Training Accuracy = 75.88%\n",
      "Epoch 1442: Loss = 198.8215, Training Accuracy = 76.02%\n",
      "Epoch 1443: Loss = 199.7868, Training Accuracy = 75.98%\n",
      "Epoch 1444: Loss = 199.1898, Training Accuracy = 76.03%\n",
      "Epoch 1445: Loss = 200.2768, Training Accuracy = 76.07%\n",
      "Epoch 1446: Loss = 200.2057, Training Accuracy = 75.89%\n",
      "Epoch 1447: Loss = 200.2885, Training Accuracy = 76.04%\n",
      "Epoch 1448: Loss = 200.8015, Training Accuracy = 75.73%\n",
      "Epoch 1449: Loss = 199.9424, Training Accuracy = 76.23%\n",
      "Epoch 1450: Loss = 199.1121, Training Accuracy = 76.29%\n",
      "Epoch 1451: Loss = 198.7972, Training Accuracy = 76.33%\n",
      "Epoch 1452: Loss = 199.0729, Training Accuracy = 76.43%\n",
      "Epoch 1453: Loss = 199.3455, Training Accuracy = 76.16%\n",
      "Epoch 1454: Loss = 198.4642, Training Accuracy = 76.38%\n",
      "Epoch 1455: Loss = 198.3405, Training Accuracy = 76.47%\n",
      "Epoch 1456: Loss = 199.2970, Training Accuracy = 76.56%\n",
      "Epoch 1457: Loss = 200.0683, Training Accuracy = 75.99%\n",
      "Epoch 1458: Loss = 200.4719, Training Accuracy = 76.10%\n",
      "Epoch 1459: Loss = 200.1779, Training Accuracy = 76.24%\n",
      "Epoch 1460: Loss = 200.0580, Training Accuracy = 75.94%\n",
      "Epoch 1461: Loss = 200.6495, Training Accuracy = 76.06%\n",
      "Epoch 1462: Loss = 199.9058, Training Accuracy = 76.06%\n",
      "Epoch 1463: Loss = 200.6916, Training Accuracy = 76.38%\n",
      "Epoch 1464: Loss = 199.9327, Training Accuracy = 76.49%\n",
      "Epoch 1465: Loss = 200.4834, Training Accuracy = 76.27%\n",
      "Epoch 1466: Loss = 200.6233, Training Accuracy = 76.23%\n",
      "Epoch 1467: Loss = 200.3625, Training Accuracy = 76.32%\n",
      "Epoch 1468: Loss = 199.8358, Training Accuracy = 76.33%\n",
      "Epoch 1469: Loss = 199.8935, Training Accuracy = 76.35%\n",
      "Epoch 1470: Loss = 200.3445, Training Accuracy = 76.32%\n",
      "Epoch 1471: Loss = 200.7050, Training Accuracy = 76.30%\n",
      "Epoch 1472: Loss = 199.6443, Training Accuracy = 76.25%\n",
      "Epoch 1473: Loss = 199.9901, Training Accuracy = 76.20%\n",
      "Epoch 1474: Loss = 199.8596, Training Accuracy = 76.22%\n",
      "Epoch 1475: Loss = 199.3418, Training Accuracy = 76.27%\n",
      "Epoch 1476: Loss = 199.5451, Training Accuracy = 76.32%\n",
      "Epoch 1477: Loss = 200.3430, Training Accuracy = 76.31%\n",
      "Epoch 1478: Loss = 199.8413, Training Accuracy = 76.31%\n",
      "Epoch 1479: Loss = 201.2440, Training Accuracy = 76.23%\n",
      "Epoch 1480: Loss = 200.3722, Training Accuracy = 75.92%\n",
      "Epoch 1481: Loss = 200.4297, Training Accuracy = 76.08%\n",
      "Epoch 1482: Loss = 199.6225, Training Accuracy = 75.79%\n",
      "Epoch 1483: Loss = 200.1670, Training Accuracy = 76.03%\n",
      "Epoch 1484: Loss = 200.1924, Training Accuracy = 75.70%\n",
      "Epoch 1485: Loss = 200.2300, Training Accuracy = 75.98%\n",
      "Epoch 1486: Loss = 200.0617, Training Accuracy = 76.02%\n",
      "Epoch 1487: Loss = 200.7984, Training Accuracy = 75.95%\n",
      "Epoch 1488: Loss = 201.0380, Training Accuracy = 75.81%\n",
      "Epoch 1489: Loss = 200.6247, Training Accuracy = 75.87%\n",
      "Epoch 1490: Loss = 200.8505, Training Accuracy = 75.84%\n",
      "Epoch 1491: Loss = 200.8668, Training Accuracy = 75.81%\n",
      "Epoch 1492: Loss = 201.0517, Training Accuracy = 75.87%\n",
      "Epoch 1493: Loss = 200.8749, Training Accuracy = 75.99%\n",
      "Epoch 1494: Loss = 200.7167, Training Accuracy = 75.81%\n",
      "Epoch 1495: Loss = 200.2707, Training Accuracy = 76.27%\n",
      "Epoch 1496: Loss = 200.8365, Training Accuracy = 76.01%\n",
      "Epoch 1497: Loss = 200.7210, Training Accuracy = 75.94%\n",
      "Epoch 1498: Loss = 200.9503, Training Accuracy = 75.97%\n",
      "Epoch 1499: Loss = 201.4257, Training Accuracy = 75.96%\n",
      "Epoch 1500: Loss = 201.1547, Training Accuracy = 75.86%\n",
      "Epoch 1501: Loss = 200.7097, Training Accuracy = 75.81%\n",
      "Epoch 1502: Loss = 200.5228, Training Accuracy = 75.81%\n",
      "Epoch 1503: Loss = 200.3750, Training Accuracy = 75.86%\n",
      "Epoch 1504: Loss = 200.6859, Training Accuracy = 75.85%\n",
      "Epoch 1505: Loss = 200.7349, Training Accuracy = 75.75%\n",
      "Epoch 1506: Loss = 200.7457, Training Accuracy = 76.08%\n",
      "Epoch 1507: Loss = 200.7496, Training Accuracy = 75.86%\n",
      "Epoch 1508: Loss = 200.9583, Training Accuracy = 75.81%\n",
      "Epoch 1509: Loss = 201.6089, Training Accuracy = 75.87%\n",
      "Epoch 1510: Loss = 200.2566, Training Accuracy = 76.08%\n",
      "Epoch 1511: Loss = 200.0096, Training Accuracy = 76.29%\n",
      "Epoch 1512: Loss = 200.4096, Training Accuracy = 76.23%\n",
      "Epoch 1513: Loss = 200.5557, Training Accuracy = 75.65%\n",
      "Epoch 1514: Loss = 201.3756, Training Accuracy = 75.82%\n",
      "Epoch 1515: Loss = 200.9497, Training Accuracy = 75.84%\n",
      "Epoch 1516: Loss = 200.6385, Training Accuracy = 75.88%\n",
      "Epoch 1517: Loss = 200.9847, Training Accuracy = 76.00%\n",
      "Epoch 1518: Loss = 201.0817, Training Accuracy = 76.21%\n",
      "Epoch 1519: Loss = 200.8602, Training Accuracy = 76.05%\n",
      "Epoch 1520: Loss = 200.8385, Training Accuracy = 76.22%\n",
      "Epoch 1521: Loss = 201.1264, Training Accuracy = 76.40%\n",
      "Epoch 1522: Loss = 201.2446, Training Accuracy = 76.49%\n",
      "Epoch 1523: Loss = 201.9433, Training Accuracy = 76.53%\n",
      "Epoch 1524: Loss = 201.4815, Training Accuracy = 76.43%\n",
      "Epoch 1525: Loss = 201.2352, Training Accuracy = 76.00%\n",
      "Epoch 1526: Loss = 201.1194, Training Accuracy = 76.04%\n",
      "Epoch 1527: Loss = 201.7795, Training Accuracy = 75.93%\n",
      "Epoch 1528: Loss = 201.4277, Training Accuracy = 76.19%\n",
      "Epoch 1529: Loss = 201.4541, Training Accuracy = 76.24%\n",
      "Epoch 1530: Loss = 201.1475, Training Accuracy = 76.31%\n",
      "Epoch 1531: Loss = 200.4389, Training Accuracy = 76.38%\n",
      "Epoch 1532: Loss = 200.5827, Training Accuracy = 76.30%\n",
      "Epoch 1533: Loss = 200.5498, Training Accuracy = 76.24%\n",
      "Epoch 1534: Loss = 199.7172, Training Accuracy = 76.29%\n",
      "Epoch 1535: Loss = 200.0517, Training Accuracy = 76.31%\n",
      "Epoch 1536: Loss = 200.5365, Training Accuracy = 76.24%\n",
      "Epoch 1537: Loss = 200.6996, Training Accuracy = 76.09%\n",
      "Epoch 1538: Loss = 201.2307, Training Accuracy = 76.11%\n",
      "Epoch 1539: Loss = 201.0295, Training Accuracy = 76.30%\n",
      "Epoch 1540: Loss = 201.6238, Training Accuracy = 76.19%\n",
      "Epoch 1541: Loss = 200.1485, Training Accuracy = 76.23%\n",
      "Epoch 1542: Loss = 201.2778, Training Accuracy = 76.12%\n",
      "Epoch 1543: Loss = 201.9359, Training Accuracy = 76.27%\n",
      "Epoch 1544: Loss = 201.4672, Training Accuracy = 76.17%\n",
      "Epoch 1545: Loss = 202.0193, Training Accuracy = 76.22%\n",
      "Epoch 1546: Loss = 202.0016, Training Accuracy = 76.08%\n",
      "Epoch 1547: Loss = 201.4865, Training Accuracy = 76.13%\n",
      "Epoch 1548: Loss = 201.9507, Training Accuracy = 76.22%\n",
      "Epoch 1549: Loss = 200.7935, Training Accuracy = 76.03%\n",
      "Epoch 1550: Loss = 201.1461, Training Accuracy = 76.24%\n",
      "Epoch 1551: Loss = 201.2679, Training Accuracy = 76.21%\n",
      "Epoch 1552: Loss = 200.7510, Training Accuracy = 76.21%\n",
      "Epoch 1553: Loss = 200.8340, Training Accuracy = 76.10%\n",
      "Epoch 1554: Loss = 200.4242, Training Accuracy = 76.31%\n",
      "Epoch 1555: Loss = 200.4106, Training Accuracy = 76.43%\n",
      "Epoch 1556: Loss = 199.4349, Training Accuracy = 76.21%\n",
      "Epoch 1557: Loss = 200.7640, Training Accuracy = 76.25%\n",
      "Epoch 1558: Loss = 200.1783, Training Accuracy = 76.17%\n",
      "Epoch 1559: Loss = 200.5029, Training Accuracy = 76.29%\n",
      "Epoch 1560: Loss = 200.4249, Training Accuracy = 76.30%\n",
      "Epoch 1561: Loss = 200.7556, Training Accuracy = 76.64%\n",
      "Epoch 1562: Loss = 200.7477, Training Accuracy = 76.50%\n",
      "Epoch 1563: Loss = 200.4625, Training Accuracy = 76.81%\n",
      "Epoch 1564: Loss = 201.1294, Training Accuracy = 76.77%\n",
      "Epoch 1565: Loss = 201.0496, Training Accuracy = 76.24%\n",
      "Epoch 1566: Loss = 201.2815, Training Accuracy = 76.34%\n",
      "Epoch 1567: Loss = 201.3367, Training Accuracy = 76.40%\n",
      "Epoch 1568: Loss = 201.3072, Training Accuracy = 76.38%\n",
      "Epoch 1569: Loss = 201.3936, Training Accuracy = 76.44%\n",
      "Epoch 1570: Loss = 200.1643, Training Accuracy = 76.64%\n",
      "Epoch 1571: Loss = 202.3428, Training Accuracy = 76.23%\n",
      "Epoch 1572: Loss = 201.5374, Training Accuracy = 76.36%\n",
      "Epoch 1573: Loss = 201.8228, Training Accuracy = 76.42%\n",
      "Epoch 1574: Loss = 202.0224, Training Accuracy = 76.38%\n",
      "Epoch 1575: Loss = 201.8659, Training Accuracy = 76.03%\n",
      "Epoch 1576: Loss = 200.6139, Training Accuracy = 76.20%\n",
      "Epoch 1577: Loss = 200.6185, Training Accuracy = 76.32%\n",
      "Epoch 1578: Loss = 200.6325, Training Accuracy = 76.15%\n",
      "Epoch 1579: Loss = 200.5425, Training Accuracy = 76.23%\n",
      "Epoch 1580: Loss = 200.5712, Training Accuracy = 76.24%\n",
      "Epoch 1581: Loss = 200.3527, Training Accuracy = 76.33%\n",
      "Epoch 1582: Loss = 200.3516, Training Accuracy = 76.49%\n",
      "Epoch 1583: Loss = 200.3403, Training Accuracy = 76.48%\n",
      "Epoch 1584: Loss = 200.6382, Training Accuracy = 76.46%\n",
      "Epoch 1585: Loss = 200.1006, Training Accuracy = 76.64%\n",
      "Epoch 1586: Loss = 200.2843, Training Accuracy = 76.71%\n",
      "Epoch 1587: Loss = 199.7926, Training Accuracy = 76.58%\n",
      "Epoch 1588: Loss = 199.9301, Training Accuracy = 76.59%\n",
      "Epoch 1589: Loss = 199.6076, Training Accuracy = 76.50%\n",
      "Epoch 1590: Loss = 199.1183, Training Accuracy = 76.40%\n",
      "Epoch 1591: Loss = 198.3813, Training Accuracy = 76.59%\n",
      "Epoch 1592: Loss = 197.6847, Training Accuracy = 76.60%\n",
      "Epoch 1593: Loss = 197.4991, Training Accuracy = 76.57%\n",
      "Epoch 1594: Loss = 197.0278, Training Accuracy = 76.69%\n",
      "Epoch 1595: Loss = 196.6898, Training Accuracy = 76.71%\n",
      "Epoch 1596: Loss = 196.9692, Training Accuracy = 76.67%\n",
      "Epoch 1597: Loss = 197.5174, Training Accuracy = 76.56%\n",
      "Epoch 1598: Loss = 197.7296, Training Accuracy = 76.65%\n",
      "Epoch 1599: Loss = 196.8243, Training Accuracy = 76.59%\n",
      "Epoch 1600: Loss = 197.7712, Training Accuracy = 76.78%\n",
      "Epoch 1601: Loss = 198.0744, Training Accuracy = 76.72%\n",
      "Epoch 1602: Loss = 198.3125, Training Accuracy = 76.74%\n",
      "Epoch 1603: Loss = 198.3428, Training Accuracy = 76.65%\n",
      "Epoch 1604: Loss = 197.9633, Training Accuracy = 76.43%\n",
      "Epoch 1605: Loss = 197.9982, Training Accuracy = 76.86%\n",
      "Epoch 1606: Loss = 197.9826, Training Accuracy = 76.74%\n",
      "Epoch 1607: Loss = 198.3212, Training Accuracy = 76.86%\n",
      "Epoch 1608: Loss = 198.2331, Training Accuracy = 76.70%\n",
      "Epoch 1609: Loss = 198.6163, Training Accuracy = 76.66%\n",
      "Epoch 1610: Loss = 198.1674, Training Accuracy = 76.45%\n",
      "Epoch 1611: Loss = 196.9071, Training Accuracy = 76.59%\n",
      "Epoch 1612: Loss = 197.2706, Training Accuracy = 76.42%\n",
      "Epoch 1613: Loss = 196.6669, Training Accuracy = 76.49%\n",
      "Epoch 1614: Loss = 198.7109, Training Accuracy = 76.11%\n",
      "Epoch 1615: Loss = 198.5026, Training Accuracy = 76.60%\n",
      "Epoch 1616: Loss = 198.3461, Training Accuracy = 76.68%\n",
      "Epoch 1617: Loss = 198.1888, Training Accuracy = 76.40%\n",
      "Epoch 1618: Loss = 197.2021, Training Accuracy = 76.50%\n",
      "Epoch 1619: Loss = 198.2235, Training Accuracy = 76.35%\n",
      "Epoch 1620: Loss = 197.9618, Training Accuracy = 76.49%\n",
      "Epoch 1621: Loss = 198.1295, Training Accuracy = 76.46%\n",
      "Epoch 1622: Loss = 197.9507, Training Accuracy = 76.43%\n",
      "Epoch 1623: Loss = 197.8669, Training Accuracy = 76.46%\n",
      "Epoch 1624: Loss = 198.0844, Training Accuracy = 76.45%\n",
      "Epoch 1625: Loss = 197.8732, Training Accuracy = 76.45%\n",
      "Epoch 1626: Loss = 198.1307, Training Accuracy = 76.32%\n",
      "Epoch 1627: Loss = 198.1978, Training Accuracy = 76.75%\n",
      "Epoch 1628: Loss = 198.0900, Training Accuracy = 76.36%\n",
      "Epoch 1629: Loss = 198.5327, Training Accuracy = 76.58%\n",
      "Epoch 1630: Loss = 198.2903, Training Accuracy = 76.67%\n",
      "Epoch 1631: Loss = 198.2149, Training Accuracy = 76.70%\n",
      "Epoch 1632: Loss = 197.8542, Training Accuracy = 76.75%\n",
      "Epoch 1633: Loss = 197.9963, Training Accuracy = 76.78%\n",
      "Epoch 1634: Loss = 198.0990, Training Accuracy = 76.88%\n",
      "Epoch 1635: Loss = 198.6768, Training Accuracy = 76.78%\n",
      "Epoch 1636: Loss = 199.0086, Training Accuracy = 76.84%\n",
      "Epoch 1637: Loss = 198.8688, Training Accuracy = 76.39%\n",
      "Epoch 1638: Loss = 198.9886, Training Accuracy = 76.72%\n",
      "Epoch 1639: Loss = 198.8256, Training Accuracy = 76.74%\n",
      "Epoch 1640: Loss = 198.5289, Training Accuracy = 76.70%\n",
      "Epoch 1641: Loss = 198.6449, Training Accuracy = 76.56%\n",
      "Epoch 1642: Loss = 198.6334, Training Accuracy = 76.81%\n",
      "Epoch 1643: Loss = 197.9277, Training Accuracy = 76.64%\n",
      "Epoch 1644: Loss = 199.2826, Training Accuracy = 76.47%\n",
      "Epoch 1645: Loss = 199.3168, Training Accuracy = 76.60%\n",
      "Epoch 1646: Loss = 199.0777, Training Accuracy = 76.63%\n",
      "Epoch 1647: Loss = 198.3154, Training Accuracy = 76.81%\n",
      "Epoch 1648: Loss = 199.6278, Training Accuracy = 76.61%\n",
      "Epoch 1649: Loss = 200.0371, Training Accuracy = 76.62%\n",
      "Epoch 1650: Loss = 199.0682, Training Accuracy = 76.85%\n",
      "Epoch 1651: Loss = 199.6240, Training Accuracy = 76.85%\n",
      "Epoch 1652: Loss = 199.7765, Training Accuracy = 76.75%\n",
      "Epoch 1653: Loss = 199.6794, Training Accuracy = 76.74%\n",
      "Epoch 1654: Loss = 199.4539, Training Accuracy = 76.63%\n",
      "Epoch 1655: Loss = 199.0471, Training Accuracy = 76.96%\n",
      "Epoch 1656: Loss = 199.5526, Training Accuracy = 76.89%\n",
      "Epoch 1657: Loss = 199.7617, Training Accuracy = 76.85%\n",
      "Epoch 1658: Loss = 199.5289, Training Accuracy = 76.93%\n",
      "Epoch 1659: Loss = 200.0059, Training Accuracy = 76.86%\n",
      "Epoch 1660: Loss = 199.4167, Training Accuracy = 76.99%\n",
      "Epoch 1661: Loss = 198.9186, Training Accuracy = 77.07%\n",
      "Epoch 1662: Loss = 199.2243, Training Accuracy = 76.84%\n",
      "Epoch 1663: Loss = 199.3158, Training Accuracy = 76.92%\n",
      "Epoch 1664: Loss = 198.4788, Training Accuracy = 76.98%\n",
      "Epoch 1665: Loss = 198.7852, Training Accuracy = 76.96%\n",
      "Epoch 1666: Loss = 199.2026, Training Accuracy = 76.98%\n",
      "Epoch 1667: Loss = 199.3136, Training Accuracy = 76.99%\n",
      "Epoch 1668: Loss = 199.4782, Training Accuracy = 76.96%\n",
      "Epoch 1669: Loss = 199.1666, Training Accuracy = 76.97%\n",
      "Epoch 1670: Loss = 199.3419, Training Accuracy = 77.04%\n",
      "Epoch 1671: Loss = 199.0681, Training Accuracy = 77.04%\n",
      "Epoch 1672: Loss = 198.4486, Training Accuracy = 77.07%\n",
      "Epoch 1673: Loss = 197.7159, Training Accuracy = 77.19%\n",
      "Epoch 1674: Loss = 198.7826, Training Accuracy = 77.23%\n",
      "Epoch 1675: Loss = 198.4124, Training Accuracy = 77.17%\n",
      "Epoch 1676: Loss = 198.0004, Training Accuracy = 77.13%\n",
      "Epoch 1677: Loss = 197.4867, Training Accuracy = 77.06%\n",
      "Epoch 1678: Loss = 197.7292, Training Accuracy = 77.04%\n",
      "Epoch 1679: Loss = 197.2428, Training Accuracy = 77.17%\n",
      "Epoch 1680: Loss = 197.8685, Training Accuracy = 77.10%\n",
      "Epoch 1681: Loss = 198.0822, Training Accuracy = 77.35%\n",
      "Epoch 1682: Loss = 198.0977, Training Accuracy = 77.32%\n",
      "Epoch 1683: Loss = 197.9998, Training Accuracy = 77.37%\n",
      "Epoch 1684: Loss = 199.0342, Training Accuracy = 77.42%\n",
      "Epoch 1685: Loss = 198.5979, Training Accuracy = 77.28%\n",
      "Epoch 1686: Loss = 198.7444, Training Accuracy = 77.24%\n",
      "Epoch 1687: Loss = 198.5262, Training Accuracy = 77.29%\n",
      "Epoch 1688: Loss = 198.0703, Training Accuracy = 77.35%\n",
      "Epoch 1689: Loss = 198.5658, Training Accuracy = 77.17%\n",
      "Epoch 1690: Loss = 198.4498, Training Accuracy = 77.38%\n",
      "Epoch 1691: Loss = 198.1592, Training Accuracy = 77.43%\n",
      "Epoch 1692: Loss = 198.3706, Training Accuracy = 77.13%\n",
      "Epoch 1693: Loss = 198.3531, Training Accuracy = 77.09%\n",
      "Epoch 1694: Loss = 198.3948, Training Accuracy = 77.10%\n",
      "Epoch 1695: Loss = 197.6755, Training Accuracy = 77.30%\n",
      "Epoch 1696: Loss = 198.0932, Training Accuracy = 77.36%\n",
      "Epoch 1697: Loss = 197.6580, Training Accuracy = 77.61%\n",
      "Epoch 1698: Loss = 197.2299, Training Accuracy = 77.71%\n",
      "Epoch 1699: Loss = 196.9444, Training Accuracy = 77.65%\n",
      "Epoch 1700: Loss = 195.6680, Training Accuracy = 77.76%\n",
      "Epoch 1701: Loss = 196.9055, Training Accuracy = 77.55%\n",
      "Epoch 1702: Loss = 196.8320, Training Accuracy = 77.53%\n",
      "Epoch 1703: Loss = 197.8248, Training Accuracy = 77.60%\n",
      "Epoch 1704: Loss = 197.4312, Training Accuracy = 77.53%\n",
      "Epoch 1705: Loss = 197.2333, Training Accuracy = 77.73%\n",
      "Epoch 1706: Loss = 196.7489, Training Accuracy = 77.75%\n",
      "Epoch 1707: Loss = 196.1637, Training Accuracy = 77.78%\n",
      "Epoch 1708: Loss = 196.5711, Training Accuracy = 77.83%\n",
      "Epoch 1709: Loss = 196.5495, Training Accuracy = 77.75%\n",
      "Epoch 1710: Loss = 196.7351, Training Accuracy = 77.71%\n",
      "Epoch 1711: Loss = 196.2084, Training Accuracy = 77.94%\n",
      "Epoch 1712: Loss = 196.3041, Training Accuracy = 77.89%\n",
      "Epoch 1713: Loss = 196.5829, Training Accuracy = 77.87%\n",
      "Epoch 1714: Loss = 195.9385, Training Accuracy = 77.79%\n",
      "Epoch 1715: Loss = 195.5876, Training Accuracy = 77.73%\n",
      "Epoch 1716: Loss = 196.3954, Training Accuracy = 77.64%\n",
      "Epoch 1717: Loss = 196.5573, Training Accuracy = 77.74%\n",
      "Epoch 1718: Loss = 195.8841, Training Accuracy = 77.84%\n",
      "Epoch 1719: Loss = 196.0989, Training Accuracy = 77.68%\n",
      "Epoch 1720: Loss = 196.4839, Training Accuracy = 77.99%\n",
      "Epoch 1721: Loss = 196.6039, Training Accuracy = 77.91%\n",
      "Epoch 1722: Loss = 195.7496, Training Accuracy = 77.93%\n",
      "Epoch 1723: Loss = 196.1309, Training Accuracy = 77.90%\n",
      "Epoch 1724: Loss = 196.5011, Training Accuracy = 77.93%\n",
      "Epoch 1725: Loss = 195.6169, Training Accuracy = 78.02%\n",
      "Epoch 1726: Loss = 195.4293, Training Accuracy = 78.04%\n",
      "Epoch 1727: Loss = 195.9019, Training Accuracy = 77.79%\n",
      "Epoch 1728: Loss = 195.7436, Training Accuracy = 77.80%\n",
      "Epoch 1729: Loss = 195.6766, Training Accuracy = 77.83%\n",
      "Epoch 1730: Loss = 195.6209, Training Accuracy = 77.77%\n",
      "Epoch 1731: Loss = 195.2752, Training Accuracy = 78.06%\n",
      "Epoch 1732: Loss = 195.8537, Training Accuracy = 78.03%\n",
      "Epoch 1733: Loss = 195.4690, Training Accuracy = 77.83%\n",
      "Epoch 1734: Loss = 194.9087, Training Accuracy = 77.86%\n",
      "Epoch 1735: Loss = 194.7864, Training Accuracy = 77.97%\n",
      "Epoch 1736: Loss = 195.0534, Training Accuracy = 77.87%\n",
      "Epoch 1737: Loss = 194.9589, Training Accuracy = 77.88%\n",
      "Epoch 1738: Loss = 195.2099, Training Accuracy = 77.81%\n",
      "Epoch 1739: Loss = 194.0848, Training Accuracy = 77.94%\n",
      "Epoch 1740: Loss = 193.7645, Training Accuracy = 78.00%\n",
      "Epoch 1741: Loss = 193.9730, Training Accuracy = 77.86%\n",
      "Epoch 1742: Loss = 194.0801, Training Accuracy = 77.83%\n",
      "Epoch 1743: Loss = 193.8916, Training Accuracy = 77.79%\n",
      "Epoch 1744: Loss = 194.0814, Training Accuracy = 77.84%\n",
      "Epoch 1745: Loss = 193.8528, Training Accuracy = 77.84%\n",
      "Epoch 1746: Loss = 194.3497, Training Accuracy = 77.84%\n",
      "Epoch 1747: Loss = 194.5544, Training Accuracy = 77.64%\n",
      "Epoch 1748: Loss = 194.6577, Training Accuracy = 77.62%\n",
      "Epoch 1749: Loss = 194.2471, Training Accuracy = 77.70%\n",
      "Epoch 1750: Loss = 194.2930, Training Accuracy = 77.69%\n",
      "Epoch 1751: Loss = 194.0889, Training Accuracy = 77.76%\n",
      "Epoch 1752: Loss = 194.5136, Training Accuracy = 77.70%\n",
      "Epoch 1753: Loss = 194.3317, Training Accuracy = 78.05%\n",
      "Epoch 1754: Loss = 194.0900, Training Accuracy = 78.15%\n",
      "Epoch 1755: Loss = 194.4123, Training Accuracy = 78.11%\n",
      "Epoch 1756: Loss = 194.1203, Training Accuracy = 78.08%\n",
      "Epoch 1757: Loss = 194.5909, Training Accuracy = 77.96%\n",
      "Epoch 1758: Loss = 194.6991, Training Accuracy = 77.94%\n",
      "Epoch 1759: Loss = 194.9001, Training Accuracy = 77.88%\n",
      "Epoch 1760: Loss = 194.4447, Training Accuracy = 77.99%\n",
      "Epoch 1761: Loss = 194.5464, Training Accuracy = 78.03%\n",
      "Epoch 1762: Loss = 194.4881, Training Accuracy = 78.03%\n",
      "Epoch 1763: Loss = 194.9613, Training Accuracy = 78.00%\n",
      "Epoch 1764: Loss = 194.9347, Training Accuracy = 77.82%\n",
      "Epoch 1765: Loss = 195.3036, Training Accuracy = 77.89%\n",
      "Epoch 1766: Loss = 194.8674, Training Accuracy = 77.80%\n",
      "Epoch 1767: Loss = 194.8876, Training Accuracy = 77.75%\n",
      "Epoch 1768: Loss = 195.1575, Training Accuracy = 77.75%\n",
      "Epoch 1769: Loss = 195.6217, Training Accuracy = 77.74%\n",
      "Epoch 1770: Loss = 195.5510, Training Accuracy = 77.84%\n",
      "Epoch 1771: Loss = 195.8339, Training Accuracy = 77.77%\n",
      "Epoch 1772: Loss = 195.9850, Training Accuracy = 77.72%\n",
      "Epoch 1773: Loss = 195.9881, Training Accuracy = 77.91%\n",
      "Epoch 1774: Loss = 195.5911, Training Accuracy = 77.88%\n",
      "Epoch 1775: Loss = 195.5114, Training Accuracy = 77.66%\n",
      "Epoch 1776: Loss = 196.2033, Training Accuracy = 78.04%\n",
      "Epoch 1777: Loss = 195.9588, Training Accuracy = 77.97%\n",
      "Epoch 1778: Loss = 195.8392, Training Accuracy = 77.88%\n",
      "Epoch 1779: Loss = 196.4335, Training Accuracy = 77.79%\n",
      "Epoch 1780: Loss = 196.5985, Training Accuracy = 77.79%\n",
      "Epoch 1781: Loss = 196.3310, Training Accuracy = 77.87%\n",
      "Epoch 1782: Loss = 196.1682, Training Accuracy = 77.92%\n",
      "Epoch 1783: Loss = 197.2313, Training Accuracy = 77.86%\n",
      "Epoch 1784: Loss = 197.5341, Training Accuracy = 77.92%\n",
      "Epoch 1785: Loss = 197.0055, Training Accuracy = 77.81%\n",
      "Epoch 1786: Loss = 197.4623, Training Accuracy = 77.65%\n",
      "Epoch 1787: Loss = 197.6302, Training Accuracy = 77.63%\n",
      "Epoch 1788: Loss = 197.6463, Training Accuracy = 77.68%\n",
      "Epoch 1789: Loss = 196.6568, Training Accuracy = 77.65%\n",
      "Epoch 1790: Loss = 196.4985, Training Accuracy = 77.51%\n",
      "Epoch 1791: Loss = 196.5405, Training Accuracy = 77.61%\n",
      "Epoch 1792: Loss = 196.0872, Training Accuracy = 77.83%\n",
      "Epoch 1793: Loss = 195.7206, Training Accuracy = 78.03%\n",
      "Epoch 1794: Loss = 197.7575, Training Accuracy = 77.70%\n",
      "Epoch 1795: Loss = 196.8541, Training Accuracy = 77.83%\n",
      "Epoch 1796: Loss = 197.0277, Training Accuracy = 77.77%\n",
      "Epoch 1797: Loss = 196.1169, Training Accuracy = 77.92%\n",
      "Epoch 1798: Loss = 196.7495, Training Accuracy = 77.94%\n",
      "Epoch 1799: Loss = 197.0286, Training Accuracy = 77.51%\n",
      "Epoch 1800: Loss = 196.6423, Training Accuracy = 77.92%\n",
      "Epoch 1801: Loss = 196.9629, Training Accuracy = 77.84%\n",
      "Epoch 1802: Loss = 196.7934, Training Accuracy = 77.94%\n",
      "Epoch 1803: Loss = 197.1111, Training Accuracy = 77.80%\n",
      "Epoch 1804: Loss = 196.7512, Training Accuracy = 78.09%\n",
      "Epoch 1805: Loss = 196.5669, Training Accuracy = 78.07%\n",
      "Epoch 1806: Loss = 195.6952, Training Accuracy = 78.25%\n",
      "Epoch 1807: Loss = 195.7750, Training Accuracy = 78.19%\n",
      "Epoch 1808: Loss = 196.1174, Training Accuracy = 78.18%\n",
      "Epoch 1809: Loss = 195.9205, Training Accuracy = 78.26%\n",
      "Epoch 1810: Loss = 195.8660, Training Accuracy = 78.15%\n",
      "Epoch 1811: Loss = 195.9577, Training Accuracy = 78.11%\n",
      "Epoch 1812: Loss = 195.6278, Training Accuracy = 78.24%\n",
      "Epoch 1813: Loss = 195.5123, Training Accuracy = 78.22%\n",
      "Epoch 1814: Loss = 196.0132, Training Accuracy = 78.09%\n",
      "Epoch 1815: Loss = 195.7479, Training Accuracy = 78.08%\n",
      "Epoch 1816: Loss = 196.4209, Training Accuracy = 78.02%\n",
      "Epoch 1817: Loss = 195.4247, Training Accuracy = 78.00%\n",
      "Epoch 1818: Loss = 195.4399, Training Accuracy = 78.16%\n",
      "Epoch 1819: Loss = 195.2950, Training Accuracy = 78.21%\n",
      "Epoch 1820: Loss = 195.0143, Training Accuracy = 78.29%\n",
      "Epoch 1821: Loss = 195.4599, Training Accuracy = 78.19%\n",
      "Epoch 1822: Loss = 195.2776, Training Accuracy = 78.25%\n",
      "Epoch 1823: Loss = 194.4023, Training Accuracy = 78.17%\n",
      "Epoch 1824: Loss = 194.1856, Training Accuracy = 78.23%\n",
      "Epoch 1825: Loss = 194.2380, Training Accuracy = 78.22%\n",
      "Epoch 1826: Loss = 194.5500, Training Accuracy = 78.06%\n",
      "Epoch 1827: Loss = 194.7944, Training Accuracy = 78.07%\n",
      "Epoch 1828: Loss = 194.2732, Training Accuracy = 78.41%\n",
      "Epoch 1829: Loss = 194.0385, Training Accuracy = 78.32%\n",
      "Epoch 1830: Loss = 193.9382, Training Accuracy = 78.29%\n",
      "Epoch 1831: Loss = 193.9273, Training Accuracy = 78.29%\n",
      "Epoch 1832: Loss = 194.1623, Training Accuracy = 78.33%\n",
      "Epoch 1833: Loss = 195.2378, Training Accuracy = 78.04%\n",
      "Epoch 1834: Loss = 195.0593, Training Accuracy = 78.04%\n",
      "Epoch 1835: Loss = 195.6023, Training Accuracy = 77.95%\n",
      "Epoch 1836: Loss = 195.4960, Training Accuracy = 78.06%\n",
      "Epoch 1837: Loss = 195.5206, Training Accuracy = 77.92%\n",
      "Epoch 1838: Loss = 195.1515, Training Accuracy = 78.09%\n",
      "Epoch 1839: Loss = 195.2502, Training Accuracy = 78.05%\n",
      "Epoch 1840: Loss = 195.7144, Training Accuracy = 77.93%\n",
      "Epoch 1841: Loss = 196.2020, Training Accuracy = 78.04%\n",
      "Epoch 1842: Loss = 195.5252, Training Accuracy = 78.06%\n",
      "Epoch 1843: Loss = 195.4806, Training Accuracy = 77.89%\n",
      "Epoch 1844: Loss = 194.9655, Training Accuracy = 77.97%\n",
      "Epoch 1845: Loss = 195.1926, Training Accuracy = 78.00%\n",
      "Epoch 1846: Loss = 196.0088, Training Accuracy = 77.94%\n",
      "Epoch 1847: Loss = 195.2688, Training Accuracy = 77.94%\n",
      "Epoch 1848: Loss = 195.4602, Training Accuracy = 77.66%\n",
      "Epoch 1849: Loss = 195.1211, Training Accuracy = 77.89%\n",
      "Epoch 1850: Loss = 195.4075, Training Accuracy = 77.92%\n",
      "Epoch 1851: Loss = 195.7760, Training Accuracy = 77.84%\n",
      "Epoch 1852: Loss = 195.1457, Training Accuracy = 77.94%\n",
      "Epoch 1853: Loss = 195.1376, Training Accuracy = 78.01%\n",
      "Epoch 1854: Loss = 195.4133, Training Accuracy = 77.96%\n",
      "Epoch 1855: Loss = 194.9740, Training Accuracy = 77.82%\n",
      "Epoch 1856: Loss = 195.9024, Training Accuracy = 77.87%\n",
      "Epoch 1857: Loss = 195.8272, Training Accuracy = 77.84%\n",
      "Epoch 1858: Loss = 195.8384, Training Accuracy = 77.69%\n",
      "Epoch 1859: Loss = 194.8804, Training Accuracy = 77.75%\n",
      "Epoch 1860: Loss = 195.7232, Training Accuracy = 77.79%\n",
      "Epoch 1861: Loss = 196.0069, Training Accuracy = 77.75%\n",
      "Epoch 1862: Loss = 196.7681, Training Accuracy = 77.74%\n",
      "Epoch 1863: Loss = 196.5998, Training Accuracy = 77.87%\n",
      "Epoch 1864: Loss = 196.3421, Training Accuracy = 77.94%\n",
      "Epoch 1865: Loss = 196.8657, Training Accuracy = 77.94%\n",
      "Epoch 1866: Loss = 196.0715, Training Accuracy = 77.93%\n",
      "Epoch 1867: Loss = 196.0563, Training Accuracy = 77.96%\n",
      "Epoch 1868: Loss = 196.5339, Training Accuracy = 77.75%\n",
      "Epoch 1869: Loss = 196.4959, Training Accuracy = 77.88%\n",
      "Epoch 1870: Loss = 196.2613, Training Accuracy = 77.90%\n",
      "Epoch 1871: Loss = 196.1401, Training Accuracy = 77.74%\n",
      "Epoch 1872: Loss = 195.5044, Training Accuracy = 77.88%\n",
      "Epoch 1873: Loss = 195.4789, Training Accuracy = 78.00%\n",
      "Epoch 1874: Loss = 195.4386, Training Accuracy = 77.87%\n",
      "Epoch 1875: Loss = 195.6878, Training Accuracy = 77.89%\n",
      "Epoch 1876: Loss = 195.6094, Training Accuracy = 77.90%\n",
      "Epoch 1877: Loss = 194.9767, Training Accuracy = 77.91%\n",
      "Epoch 1878: Loss = 195.1022, Training Accuracy = 77.92%\n",
      "Epoch 1879: Loss = 195.4300, Training Accuracy = 77.80%\n",
      "Epoch 1880: Loss = 195.7498, Training Accuracy = 78.11%\n",
      "Epoch 1881: Loss = 195.1005, Training Accuracy = 78.02%\n",
      "Epoch 1882: Loss = 195.2542, Training Accuracy = 78.00%\n",
      "Epoch 1883: Loss = 194.4703, Training Accuracy = 78.13%\n",
      "Epoch 1884: Loss = 193.8021, Training Accuracy = 78.08%\n",
      "Epoch 1885: Loss = 194.0447, Training Accuracy = 78.06%\n",
      "Epoch 1886: Loss = 195.0715, Training Accuracy = 78.05%\n",
      "Epoch 1887: Loss = 195.2123, Training Accuracy = 77.99%\n",
      "Epoch 1888: Loss = 195.5327, Training Accuracy = 77.96%\n",
      "Epoch 1889: Loss = 195.1198, Training Accuracy = 78.16%\n",
      "Epoch 1890: Loss = 194.6759, Training Accuracy = 78.25%\n",
      "Epoch 1891: Loss = 194.7362, Training Accuracy = 78.29%\n",
      "Epoch 1892: Loss = 194.8723, Training Accuracy = 78.00%\n",
      "Epoch 1893: Loss = 194.9154, Training Accuracy = 78.11%\n",
      "Epoch 1894: Loss = 194.3725, Training Accuracy = 78.27%\n",
      "Epoch 1895: Loss = 193.5941, Training Accuracy = 78.25%\n",
      "Epoch 1896: Loss = 193.7798, Training Accuracy = 78.25%\n",
      "Epoch 1897: Loss = 193.5623, Training Accuracy = 78.19%\n",
      "Epoch 1898: Loss = 193.3422, Training Accuracy = 78.17%\n",
      "Epoch 1899: Loss = 193.1288, Training Accuracy = 78.01%\n",
      "Epoch 1900: Loss = 192.3798, Training Accuracy = 78.18%\n",
      "Epoch 1901: Loss = 191.7280, Training Accuracy = 78.31%\n",
      "Epoch 1902: Loss = 191.8248, Training Accuracy = 78.18%\n",
      "Epoch 1903: Loss = 191.9487, Training Accuracy = 78.36%\n",
      "Epoch 1904: Loss = 192.8752, Training Accuracy = 78.26%\n",
      "Epoch 1905: Loss = 192.4153, Training Accuracy = 78.30%\n",
      "Epoch 1906: Loss = 192.4961, Training Accuracy = 78.27%\n",
      "Epoch 1907: Loss = 192.2307, Training Accuracy = 78.26%\n",
      "Epoch 1908: Loss = 192.4308, Training Accuracy = 78.16%\n",
      "Epoch 1909: Loss = 192.6923, Training Accuracy = 78.28%\n",
      "Epoch 1910: Loss = 192.6819, Training Accuracy = 78.43%\n",
      "Epoch 1911: Loss = 192.2833, Training Accuracy = 78.21%\n",
      "Epoch 1912: Loss = 192.3232, Training Accuracy = 78.36%\n",
      "Epoch 1913: Loss = 192.4058, Training Accuracy = 78.13%\n",
      "Epoch 1914: Loss = 192.4911, Training Accuracy = 78.02%\n",
      "Epoch 1915: Loss = 192.2377, Training Accuracy = 78.31%\n",
      "Epoch 1916: Loss = 192.6039, Training Accuracy = 78.25%\n",
      "Epoch 1917: Loss = 192.2363, Training Accuracy = 78.25%\n",
      "Epoch 1918: Loss = 193.1497, Training Accuracy = 78.16%\n",
      "Epoch 1919: Loss = 193.6586, Training Accuracy = 78.24%\n",
      "Epoch 1920: Loss = 193.6582, Training Accuracy = 78.15%\n",
      "Epoch 1921: Loss = 192.8882, Training Accuracy = 78.16%\n",
      "Epoch 1922: Loss = 193.1806, Training Accuracy = 78.16%\n",
      "Epoch 1923: Loss = 192.8268, Training Accuracy = 78.41%\n",
      "Epoch 1924: Loss = 193.4597, Training Accuracy = 78.22%\n",
      "Epoch 1925: Loss = 193.6028, Training Accuracy = 78.11%\n",
      "Epoch 1926: Loss = 194.1392, Training Accuracy = 78.35%\n",
      "Epoch 1927: Loss = 193.8850, Training Accuracy = 78.18%\n",
      "Epoch 1928: Loss = 194.2345, Training Accuracy = 78.12%\n",
      "Epoch 1929: Loss = 194.1143, Training Accuracy = 78.26%\n",
      "Epoch 1930: Loss = 194.1063, Training Accuracy = 78.29%\n",
      "Epoch 1931: Loss = 193.8900, Training Accuracy = 78.24%\n",
      "Epoch 1932: Loss = 194.4699, Training Accuracy = 78.18%\n",
      "Epoch 1933: Loss = 194.5178, Training Accuracy = 78.18%\n",
      "Epoch 1934: Loss = 194.7587, Training Accuracy = 78.05%\n",
      "Epoch 1935: Loss = 193.7350, Training Accuracy = 78.27%\n",
      "Epoch 1936: Loss = 193.5637, Training Accuracy = 78.27%\n",
      "Epoch 1937: Loss = 193.6300, Training Accuracy = 78.15%\n",
      "Epoch 1938: Loss = 194.0854, Training Accuracy = 78.16%\n",
      "Epoch 1939: Loss = 194.2797, Training Accuracy = 78.38%\n",
      "Epoch 1940: Loss = 193.7567, Training Accuracy = 78.43%\n",
      "Epoch 1941: Loss = 194.3786, Training Accuracy = 78.27%\n",
      "Epoch 1942: Loss = 194.6284, Training Accuracy = 78.25%\n",
      "Epoch 1943: Loss = 195.2206, Training Accuracy = 78.30%\n",
      "Epoch 1944: Loss = 194.9094, Training Accuracy = 78.41%\n",
      "Epoch 1945: Loss = 194.0751, Training Accuracy = 78.29%\n",
      "Epoch 1946: Loss = 194.0389, Training Accuracy = 78.61%\n",
      "Epoch 1947: Loss = 194.4695, Training Accuracy = 78.55%\n",
      "Epoch 1948: Loss = 194.9132, Training Accuracy = 78.29%\n",
      "Epoch 1949: Loss = 195.2054, Training Accuracy = 78.27%\n",
      "Epoch 1950: Loss = 194.9989, Training Accuracy = 78.03%\n",
      "Epoch 1951: Loss = 195.2545, Training Accuracy = 78.22%\n",
      "Epoch 1952: Loss = 194.4208, Training Accuracy = 78.30%\n",
      "Epoch 1953: Loss = 194.0796, Training Accuracy = 78.22%\n",
      "Epoch 1954: Loss = 194.9964, Training Accuracy = 78.30%\n",
      "Epoch 1955: Loss = 194.9924, Training Accuracy = 78.25%\n",
      "Epoch 1956: Loss = 195.0878, Training Accuracy = 78.26%\n",
      "Epoch 1957: Loss = 195.4079, Training Accuracy = 78.37%\n",
      "Epoch 1958: Loss = 195.5907, Training Accuracy = 78.09%\n",
      "Epoch 1959: Loss = 195.3495, Training Accuracy = 78.33%\n",
      "Epoch 1960: Loss = 195.0034, Training Accuracy = 78.46%\n",
      "Epoch 1961: Loss = 195.6095, Training Accuracy = 78.53%\n",
      "Epoch 1962: Loss = 194.8941, Training Accuracy = 78.62%\n",
      "Epoch 1963: Loss = 194.2024, Training Accuracy = 78.60%\n",
      "Epoch 1964: Loss = 194.7912, Training Accuracy = 78.56%\n",
      "Epoch 1965: Loss = 194.3696, Training Accuracy = 78.61%\n",
      "Epoch 1966: Loss = 195.1998, Training Accuracy = 78.61%\n",
      "Epoch 1967: Loss = 195.6004, Training Accuracy = 78.58%\n",
      "Epoch 1968: Loss = 195.2928, Training Accuracy = 78.58%\n",
      "Epoch 1969: Loss = 195.1927, Training Accuracy = 78.53%\n",
      "Epoch 1970: Loss = 194.7819, Training Accuracy = 78.49%\n",
      "Epoch 1971: Loss = 195.1896, Training Accuracy = 78.28%\n",
      "Epoch 1972: Loss = 195.0939, Training Accuracy = 78.57%\n",
      "Epoch 1973: Loss = 194.9801, Training Accuracy = 78.67%\n",
      "Epoch 1974: Loss = 195.1291, Training Accuracy = 78.58%\n",
      "Epoch 1975: Loss = 195.1373, Training Accuracy = 78.65%\n",
      "Epoch 1976: Loss = 194.9238, Training Accuracy = 78.76%\n",
      "Epoch 1977: Loss = 194.5476, Training Accuracy = 78.91%\n",
      "Epoch 1978: Loss = 194.9594, Training Accuracy = 78.93%\n",
      "Epoch 1979: Loss = 195.0972, Training Accuracy = 78.82%\n",
      "Epoch 1980: Loss = 195.1331, Training Accuracy = 78.87%\n",
      "Epoch 1981: Loss = 194.8139, Training Accuracy = 78.78%\n",
      "Epoch 1982: Loss = 194.8360, Training Accuracy = 78.88%\n",
      "Epoch 1983: Loss = 195.0211, Training Accuracy = 78.86%\n",
      "Epoch 1984: Loss = 194.3486, Training Accuracy = 78.95%\n",
      "Epoch 1985: Loss = 193.9622, Training Accuracy = 78.97%\n",
      "Epoch 1986: Loss = 193.7130, Training Accuracy = 78.80%\n",
      "Epoch 1987: Loss = 193.7598, Training Accuracy = 78.83%\n",
      "Epoch 1988: Loss = 194.3015, Training Accuracy = 79.08%\n",
      "Epoch 1989: Loss = 194.1830, Training Accuracy = 78.71%\n",
      "Epoch 1990: Loss = 194.0126, Training Accuracy = 78.79%\n",
      "Epoch 1991: Loss = 194.2764, Training Accuracy = 78.93%\n",
      "Epoch 1992: Loss = 194.5258, Training Accuracy = 78.72%\n",
      "Epoch 1993: Loss = 194.0419, Training Accuracy = 78.86%\n",
      "Epoch 1994: Loss = 194.4943, Training Accuracy = 78.69%\n",
      "Epoch 1995: Loss = 193.8409, Training Accuracy = 78.93%\n",
      "Epoch 1996: Loss = 194.0803, Training Accuracy = 78.97%\n",
      "Epoch 1997: Loss = 194.7132, Training Accuracy = 78.80%\n",
      "Epoch 1998: Loss = 194.3013, Training Accuracy = 78.99%\n",
      "Epoch 1999: Loss = 194.2700, Training Accuracy = 79.10%\n",
      "Epoch 2000: Loss = 194.7262, Training Accuracy = 78.84%\n",
      "Epoch 2001: Loss = 195.0972, Training Accuracy = 79.11%\n",
      "Epoch 2002: Loss = 194.7193, Training Accuracy = 78.84%\n",
      "Epoch 2003: Loss = 194.1860, Training Accuracy = 79.11%\n",
      "Epoch 2004: Loss = 194.1626, Training Accuracy = 79.14%\n",
      "Epoch 2005: Loss = 194.4841, Training Accuracy = 78.68%\n",
      "Epoch 2006: Loss = 194.7043, Training Accuracy = 78.69%\n",
      "Epoch 2007: Loss = 194.4992, Training Accuracy = 78.81%\n",
      "Epoch 2008: Loss = 194.0914, Training Accuracy = 78.84%\n",
      "Epoch 2009: Loss = 194.5762, Training Accuracy = 78.91%\n",
      "Epoch 2010: Loss = 194.8929, Training Accuracy = 79.19%\n",
      "Epoch 2011: Loss = 193.9301, Training Accuracy = 79.33%\n",
      "Epoch 2012: Loss = 194.6642, Training Accuracy = 79.19%\n",
      "Epoch 2013: Loss = 194.4739, Training Accuracy = 79.31%\n",
      "Epoch 2014: Loss = 194.5699, Training Accuracy = 79.28%\n",
      "Epoch 2015: Loss = 194.2092, Training Accuracy = 79.34%\n",
      "Epoch 2016: Loss = 194.4856, Training Accuracy = 79.22%\n",
      "Epoch 2017: Loss = 194.3714, Training Accuracy = 79.31%\n",
      "Epoch 2018: Loss = 195.0138, Training Accuracy = 79.25%\n",
      "Epoch 2019: Loss = 194.8419, Training Accuracy = 79.04%\n",
      "Epoch 2020: Loss = 195.2194, Training Accuracy = 79.23%\n",
      "Epoch 2021: Loss = 195.8020, Training Accuracy = 79.02%\n",
      "Epoch 2022: Loss = 195.6196, Training Accuracy = 79.17%\n",
      "Epoch 2023: Loss = 194.8054, Training Accuracy = 79.15%\n",
      "Epoch 2024: Loss = 194.6427, Training Accuracy = 79.14%\n",
      "Epoch 2025: Loss = 194.8316, Training Accuracy = 79.22%\n",
      "Epoch 2026: Loss = 195.0648, Training Accuracy = 79.32%\n",
      "Epoch 2027: Loss = 195.4521, Training Accuracy = 79.05%\n",
      "Epoch 2028: Loss = 196.0960, Training Accuracy = 79.11%\n",
      "Epoch 2029: Loss = 196.2481, Training Accuracy = 79.04%\n",
      "Epoch 2030: Loss = 195.9931, Training Accuracy = 79.23%\n",
      "Epoch 2031: Loss = 195.9872, Training Accuracy = 79.19%\n",
      "Epoch 2032: Loss = 195.3517, Training Accuracy = 78.86%\n",
      "Epoch 2033: Loss = 195.4540, Training Accuracy = 79.04%\n",
      "Epoch 2034: Loss = 195.4458, Training Accuracy = 79.08%\n",
      "Epoch 2035: Loss = 195.2777, Training Accuracy = 78.88%\n",
      "Epoch 2036: Loss = 195.3499, Training Accuracy = 78.84%\n",
      "Epoch 2037: Loss = 195.1894, Training Accuracy = 78.93%\n",
      "Epoch 2038: Loss = 195.3917, Training Accuracy = 78.88%\n",
      "Epoch 2039: Loss = 195.2405, Training Accuracy = 79.05%\n",
      "Epoch 2040: Loss = 195.2452, Training Accuracy = 78.96%\n",
      "Epoch 2041: Loss = 195.4891, Training Accuracy = 79.01%\n",
      "Epoch 2042: Loss = 195.9516, Training Accuracy = 78.86%\n",
      "Epoch 2043: Loss = 195.7109, Training Accuracy = 78.97%\n",
      "Epoch 2044: Loss = 195.9507, Training Accuracy = 79.16%\n",
      "Epoch 2045: Loss = 195.7655, Training Accuracy = 79.29%\n",
      "Epoch 2046: Loss = 195.0856, Training Accuracy = 79.32%\n",
      "Epoch 2047: Loss = 195.4768, Training Accuracy = 79.25%\n",
      "Epoch 2048: Loss = 196.0229, Training Accuracy = 79.06%\n",
      "Epoch 2049: Loss = 195.8689, Training Accuracy = 79.20%\n",
      "Epoch 2050: Loss = 195.4813, Training Accuracy = 79.22%\n",
      "Epoch 2051: Loss = 196.1354, Training Accuracy = 78.88%\n",
      "Epoch 2052: Loss = 195.8753, Training Accuracy = 79.24%\n",
      "Epoch 2053: Loss = 195.3629, Training Accuracy = 79.27%\n",
      "Epoch 2054: Loss = 195.8575, Training Accuracy = 79.10%\n",
      "Epoch 2055: Loss = 195.7584, Training Accuracy = 79.14%\n",
      "Epoch 2056: Loss = 195.7604, Training Accuracy = 79.28%\n",
      "Epoch 2057: Loss = 195.2468, Training Accuracy = 79.20%\n",
      "Epoch 2058: Loss = 195.6109, Training Accuracy = 79.31%\n",
      "Epoch 2059: Loss = 195.8052, Training Accuracy = 79.11%\n",
      "Epoch 2060: Loss = 195.8248, Training Accuracy = 79.34%\n",
      "Epoch 2061: Loss = 195.7631, Training Accuracy = 79.32%\n",
      "Epoch 2062: Loss = 195.4653, Training Accuracy = 79.41%\n",
      "Epoch 2063: Loss = 195.7511, Training Accuracy = 79.39%\n",
      "Epoch 2064: Loss = 194.8484, Training Accuracy = 79.52%\n",
      "Epoch 2065: Loss = 194.2878, Training Accuracy = 79.61%\n",
      "Epoch 2066: Loss = 194.4900, Training Accuracy = 79.62%\n",
      "Epoch 2067: Loss = 193.9898, Training Accuracy = 79.47%\n",
      "Epoch 2068: Loss = 193.8679, Training Accuracy = 79.52%\n",
      "Epoch 2069: Loss = 193.5314, Training Accuracy = 79.58%\n",
      "Epoch 2070: Loss = 193.7437, Training Accuracy = 79.57%\n",
      "Epoch 2071: Loss = 193.5431, Training Accuracy = 79.77%\n",
      "Epoch 2072: Loss = 194.3330, Training Accuracy = 79.34%\n",
      "Epoch 2073: Loss = 193.7838, Training Accuracy = 79.67%\n",
      "Epoch 2074: Loss = 193.9644, Training Accuracy = 79.56%\n",
      "Epoch 2075: Loss = 194.2254, Training Accuracy = 79.54%\n",
      "Epoch 2076: Loss = 194.1425, Training Accuracy = 79.53%\n",
      "Epoch 2077: Loss = 194.1227, Training Accuracy = 79.37%\n",
      "Epoch 2078: Loss = 193.9818, Training Accuracy = 79.43%\n",
      "Epoch 2079: Loss = 193.8849, Training Accuracy = 79.36%\n",
      "Epoch 2080: Loss = 193.6617, Training Accuracy = 79.28%\n",
      "Epoch 2081: Loss = 193.8761, Training Accuracy = 79.46%\n",
      "Epoch 2082: Loss = 193.9622, Training Accuracy = 79.41%\n",
      "Epoch 2083: Loss = 193.7548, Training Accuracy = 79.47%\n",
      "Epoch 2084: Loss = 193.4547, Training Accuracy = 79.64%\n",
      "Epoch 2085: Loss = 193.5469, Training Accuracy = 79.64%\n",
      "Epoch 2086: Loss = 194.3163, Training Accuracy = 79.59%\n",
      "Epoch 2087: Loss = 194.0855, Training Accuracy = 79.54%\n",
      "Epoch 2088: Loss = 193.6611, Training Accuracy = 79.63%\n",
      "Epoch 2089: Loss = 194.5922, Training Accuracy = 79.56%\n",
      "Epoch 2090: Loss = 194.8245, Training Accuracy = 79.56%\n",
      "Epoch 2091: Loss = 194.4576, Training Accuracy = 79.19%\n",
      "Epoch 2092: Loss = 194.8430, Training Accuracy = 79.28%\n",
      "Epoch 2093: Loss = 195.0406, Training Accuracy = 79.36%\n",
      "Epoch 2094: Loss = 195.1305, Training Accuracy = 79.26%\n",
      "Epoch 2095: Loss = 195.2431, Training Accuracy = 79.37%\n",
      "Epoch 2096: Loss = 195.1112, Training Accuracy = 79.51%\n",
      "Epoch 2097: Loss = 195.9999, Training Accuracy = 79.06%\n",
      "Epoch 2098: Loss = 196.0505, Training Accuracy = 79.12%\n",
      "Epoch 2099: Loss = 195.5691, Training Accuracy = 79.50%\n",
      "Epoch 2100: Loss = 195.8308, Training Accuracy = 79.38%\n",
      "Epoch 2101: Loss = 195.9789, Training Accuracy = 79.42%\n",
      "Epoch 2102: Loss = 195.6937, Training Accuracy = 79.23%\n",
      "Epoch 2103: Loss = 196.0047, Training Accuracy = 79.19%\n",
      "Epoch 2104: Loss = 195.9048, Training Accuracy = 79.21%\n",
      "Epoch 2105: Loss = 196.1733, Training Accuracy = 79.15%\n",
      "Epoch 2106: Loss = 195.7260, Training Accuracy = 79.14%\n",
      "Epoch 2107: Loss = 196.3635, Training Accuracy = 79.30%\n",
      "Epoch 2108: Loss = 196.4012, Training Accuracy = 79.08%\n",
      "Epoch 2109: Loss = 196.3992, Training Accuracy = 79.23%\n",
      "Epoch 2110: Loss = 196.3415, Training Accuracy = 79.16%\n",
      "Epoch 2111: Loss = 196.2861, Training Accuracy = 79.24%\n",
      "Epoch 2112: Loss = 196.0504, Training Accuracy = 79.03%\n",
      "Epoch 2113: Loss = 196.0735, Training Accuracy = 79.28%\n",
      "Epoch 2114: Loss = 195.2294, Training Accuracy = 79.20%\n",
      "Epoch 2115: Loss = 195.7310, Training Accuracy = 79.23%\n",
      "Epoch 2116: Loss = 195.3674, Training Accuracy = 79.30%\n",
      "Epoch 2117: Loss = 195.9465, Training Accuracy = 78.99%\n",
      "Epoch 2118: Loss = 196.0773, Training Accuracy = 79.21%\n",
      "Epoch 2119: Loss = 196.2165, Training Accuracy = 78.89%\n",
      "Epoch 2120: Loss = 195.6678, Training Accuracy = 79.26%\n",
      "Epoch 2121: Loss = 195.4837, Training Accuracy = 79.44%\n",
      "Epoch 2122: Loss = 195.2360, Training Accuracy = 79.34%\n",
      "Epoch 2123: Loss = 195.3734, Training Accuracy = 79.35%\n",
      "Epoch 2124: Loss = 196.1687, Training Accuracy = 79.21%\n",
      "Epoch 2125: Loss = 195.4553, Training Accuracy = 79.19%\n",
      "Epoch 2126: Loss = 194.6750, Training Accuracy = 79.40%\n",
      "Epoch 2127: Loss = 195.1180, Training Accuracy = 79.36%\n",
      "Epoch 2128: Loss = 195.0606, Training Accuracy = 79.41%\n",
      "Epoch 2129: Loss = 195.4223, Training Accuracy = 79.19%\n",
      "Epoch 2130: Loss = 195.4659, Training Accuracy = 79.16%\n",
      "Epoch 2131: Loss = 195.1778, Training Accuracy = 79.38%\n",
      "Epoch 2132: Loss = 195.5777, Training Accuracy = 79.44%\n",
      "Epoch 2133: Loss = 195.5603, Training Accuracy = 79.12%\n",
      "Epoch 2134: Loss = 195.8555, Training Accuracy = 79.06%\n",
      "Epoch 2135: Loss = 195.7213, Training Accuracy = 79.32%\n",
      "Epoch 2136: Loss = 195.4186, Training Accuracy = 79.13%\n",
      "Epoch 2137: Loss = 195.0083, Training Accuracy = 79.32%\n",
      "Epoch 2138: Loss = 195.3278, Training Accuracy = 79.33%\n",
      "Epoch 2139: Loss = 195.7460, Training Accuracy = 79.26%\n",
      "Epoch 2140: Loss = 196.2117, Training Accuracy = 79.16%\n",
      "Epoch 2141: Loss = 196.2504, Training Accuracy = 79.03%\n",
      "Epoch 2142: Loss = 196.1450, Training Accuracy = 79.15%\n",
      "Epoch 2143: Loss = 196.0920, Training Accuracy = 79.07%\n",
      "Epoch 2144: Loss = 195.9007, Training Accuracy = 79.27%\n",
      "Epoch 2145: Loss = 195.9142, Training Accuracy = 79.25%\n",
      "Epoch 2146: Loss = 195.9985, Training Accuracy = 79.01%\n",
      "Epoch 2147: Loss = 196.2530, Training Accuracy = 79.23%\n",
      "Epoch 2148: Loss = 196.2605, Training Accuracy = 79.07%\n",
      "Epoch 2149: Loss = 196.1750, Training Accuracy = 78.97%\n",
      "Epoch 2150: Loss = 196.1928, Training Accuracy = 79.01%\n",
      "Epoch 2151: Loss = 195.6085, Training Accuracy = 79.09%\n",
      "Epoch 2152: Loss = 195.1563, Training Accuracy = 79.10%\n",
      "Epoch 2153: Loss = 195.4400, Training Accuracy = 79.29%\n",
      "Epoch 2154: Loss = 195.1085, Training Accuracy = 79.27%\n",
      "Epoch 2155: Loss = 195.5383, Training Accuracy = 79.32%\n",
      "Epoch 2156: Loss = 195.5997, Training Accuracy = 79.31%\n",
      "Epoch 2157: Loss = 195.7376, Training Accuracy = 79.37%\n",
      "Epoch 2158: Loss = 195.4199, Training Accuracy = 79.33%\n",
      "Epoch 2159: Loss = 195.7414, Training Accuracy = 79.06%\n",
      "Epoch 2160: Loss = 196.2976, Training Accuracy = 78.98%\n",
      "Epoch 2161: Loss = 196.1270, Training Accuracy = 78.99%\n",
      "Epoch 2162: Loss = 196.1421, Training Accuracy = 79.18%\n",
      "Epoch 2163: Loss = 196.0121, Training Accuracy = 79.13%\n",
      "Epoch 2164: Loss = 195.9832, Training Accuracy = 79.22%\n",
      "Epoch 2165: Loss = 196.1434, Training Accuracy = 79.04%\n",
      "Epoch 2166: Loss = 195.2767, Training Accuracy = 79.11%\n",
      "Epoch 2167: Loss = 195.7034, Training Accuracy = 79.04%\n",
      "Epoch 2168: Loss = 196.0648, Training Accuracy = 79.01%\n",
      "Epoch 2169: Loss = 195.4447, Training Accuracy = 79.50%\n",
      "Epoch 2170: Loss = 195.6857, Training Accuracy = 79.33%\n",
      "Epoch 2171: Loss = 195.8750, Training Accuracy = 79.26%\n",
      "Epoch 2172: Loss = 196.1003, Training Accuracy = 78.89%\n",
      "Epoch 2173: Loss = 195.9864, Training Accuracy = 78.97%\n",
      "Epoch 2174: Loss = 196.4700, Training Accuracy = 78.98%\n",
      "Epoch 2175: Loss = 195.8359, Training Accuracy = 78.94%\n",
      "Epoch 2176: Loss = 194.7213, Training Accuracy = 79.11%\n",
      "Epoch 2177: Loss = 195.2094, Training Accuracy = 79.17%\n",
      "Epoch 2178: Loss = 194.7245, Training Accuracy = 79.17%\n",
      "Epoch 2179: Loss = 194.3630, Training Accuracy = 79.08%\n",
      "Epoch 2180: Loss = 195.0734, Training Accuracy = 79.01%\n",
      "Epoch 2181: Loss = 195.3557, Training Accuracy = 79.16%\n",
      "Epoch 2182: Loss = 194.7333, Training Accuracy = 79.17%\n",
      "Epoch 2183: Loss = 194.7033, Training Accuracy = 79.21%\n",
      "Epoch 2184: Loss = 194.2878, Training Accuracy = 79.05%\n",
      "Epoch 2185: Loss = 194.5889, Training Accuracy = 79.18%\n",
      "Epoch 2186: Loss = 193.7695, Training Accuracy = 79.26%\n",
      "Epoch 2187: Loss = 192.8765, Training Accuracy = 79.31%\n",
      "Epoch 2188: Loss = 194.0896, Training Accuracy = 79.08%\n",
      "Epoch 2189: Loss = 194.3314, Training Accuracy = 79.01%\n",
      "Epoch 2190: Loss = 193.5658, Training Accuracy = 78.97%\n",
      "Epoch 2191: Loss = 194.0509, Training Accuracy = 78.84%\n",
      "Epoch 2192: Loss = 193.2591, Training Accuracy = 78.96%\n",
      "Epoch 2193: Loss = 193.3661, Training Accuracy = 78.95%\n",
      "Epoch 2194: Loss = 193.4013, Training Accuracy = 78.95%\n",
      "Epoch 2195: Loss = 192.7971, Training Accuracy = 79.09%\n",
      "Epoch 2196: Loss = 193.6634, Training Accuracy = 79.00%\n",
      "Epoch 2197: Loss = 193.4804, Training Accuracy = 78.94%\n",
      "Epoch 2198: Loss = 193.8220, Training Accuracy = 79.02%\n",
      "Epoch 2199: Loss = 193.8861, Training Accuracy = 79.03%\n",
      "Epoch 2200: Loss = 193.6495, Training Accuracy = 79.02%\n",
      "Epoch 2201: Loss = 194.0775, Training Accuracy = 78.60%\n",
      "Epoch 2202: Loss = 194.1358, Training Accuracy = 79.35%\n",
      "Epoch 2203: Loss = 193.6714, Training Accuracy = 78.99%\n",
      "Epoch 2204: Loss = 193.1271, Training Accuracy = 79.08%\n",
      "Epoch 2205: Loss = 193.4110, Training Accuracy = 79.29%\n",
      "Epoch 2206: Loss = 193.2264, Training Accuracy = 79.05%\n",
      "Epoch 2207: Loss = 193.2114, Training Accuracy = 79.12%\n",
      "Epoch 2208: Loss = 193.8340, Training Accuracy = 79.10%\n",
      "Epoch 2209: Loss = 193.4472, Training Accuracy = 78.98%\n",
      "Epoch 2210: Loss = 194.0369, Training Accuracy = 78.98%\n",
      "Epoch 2211: Loss = 193.8396, Training Accuracy = 79.06%\n",
      "Epoch 2212: Loss = 194.1156, Training Accuracy = 79.28%\n",
      "Epoch 2213: Loss = 194.3328, Training Accuracy = 79.27%\n",
      "Epoch 2214: Loss = 193.8556, Training Accuracy = 79.02%\n",
      "Epoch 2215: Loss = 193.9961, Training Accuracy = 79.27%\n",
      "Epoch 2216: Loss = 194.5888, Training Accuracy = 78.73%\n",
      "Epoch 2217: Loss = 194.6999, Training Accuracy = 79.21%\n",
      "Epoch 2218: Loss = 193.8405, Training Accuracy = 79.46%\n",
      "Epoch 2219: Loss = 193.9161, Training Accuracy = 79.10%\n",
      "Epoch 2220: Loss = 194.6318, Training Accuracy = 78.94%\n",
      "Epoch 2221: Loss = 193.5897, Training Accuracy = 79.08%\n",
      "Epoch 2222: Loss = 194.3127, Training Accuracy = 79.14%\n",
      "Epoch 2223: Loss = 193.7609, Training Accuracy = 79.24%\n",
      "Epoch 2224: Loss = 194.0693, Training Accuracy = 79.29%\n",
      "Epoch 2225: Loss = 194.5085, Training Accuracy = 78.79%\n",
      "Epoch 2226: Loss = 193.5045, Training Accuracy = 79.17%\n",
      "Epoch 2227: Loss = 193.4271, Training Accuracy = 79.19%\n",
      "Epoch 2228: Loss = 193.7649, Training Accuracy = 79.06%\n",
      "Epoch 2229: Loss = 194.3990, Training Accuracy = 78.96%\n",
      "Epoch 2230: Loss = 194.1349, Training Accuracy = 79.05%\n",
      "Epoch 2231: Loss = 194.2055, Training Accuracy = 79.09%\n",
      "Epoch 2232: Loss = 194.1339, Training Accuracy = 78.89%\n",
      "Epoch 2233: Loss = 194.5735, Training Accuracy = 78.91%\n",
      "Epoch 2234: Loss = 194.0582, Training Accuracy = 78.97%\n",
      "Epoch 2235: Loss = 194.2135, Training Accuracy = 79.05%\n",
      "Epoch 2236: Loss = 194.4393, Training Accuracy = 79.02%\n",
      "Epoch 2237: Loss = 194.6167, Training Accuracy = 78.95%\n",
      "Epoch 2238: Loss = 194.1380, Training Accuracy = 78.74%\n",
      "Epoch 2239: Loss = 194.2297, Training Accuracy = 79.26%\n",
      "Epoch 2240: Loss = 194.3497, Training Accuracy = 79.21%\n",
      "Epoch 2241: Loss = 194.4628, Training Accuracy = 79.18%\n",
      "Epoch 2242: Loss = 194.6732, Training Accuracy = 79.18%\n",
      "Epoch 2243: Loss = 194.2352, Training Accuracy = 79.02%\n",
      "Epoch 2244: Loss = 194.8156, Training Accuracy = 78.97%\n",
      "Epoch 2245: Loss = 194.9146, Training Accuracy = 79.40%\n",
      "Epoch 2246: Loss = 194.7149, Training Accuracy = 79.46%\n",
      "Epoch 2247: Loss = 194.8113, Training Accuracy = 79.24%\n",
      "Epoch 2248: Loss = 194.8415, Training Accuracy = 79.20%\n",
      "Epoch 2249: Loss = 195.1815, Training Accuracy = 79.19%\n",
      "Epoch 2250: Loss = 194.9605, Training Accuracy = 79.16%\n",
      "Epoch 2251: Loss = 194.8190, Training Accuracy = 79.29%\n",
      "Epoch 2252: Loss = 194.8098, Training Accuracy = 79.36%\n",
      "Epoch 2253: Loss = 194.9687, Training Accuracy = 79.31%\n",
      "Epoch 2254: Loss = 194.8433, Training Accuracy = 79.15%\n",
      "Epoch 2255: Loss = 195.1159, Training Accuracy = 79.43%\n",
      "Epoch 2256: Loss = 194.8787, Training Accuracy = 79.37%\n",
      "Epoch 2257: Loss = 194.3107, Training Accuracy = 79.46%\n",
      "Epoch 2258: Loss = 194.4646, Training Accuracy = 79.36%\n",
      "Epoch 2259: Loss = 195.1296, Training Accuracy = 79.27%\n",
      "Epoch 2260: Loss = 195.1084, Training Accuracy = 79.71%\n",
      "Epoch 2261: Loss = 195.0178, Training Accuracy = 79.68%\n",
      "Epoch 2262: Loss = 195.1940, Training Accuracy = 79.77%\n",
      "Epoch 2263: Loss = 195.0959, Training Accuracy = 79.58%\n",
      "Epoch 2264: Loss = 195.2697, Training Accuracy = 79.41%\n",
      "Epoch 2265: Loss = 195.2926, Training Accuracy = 79.62%\n",
      "Epoch 2266: Loss = 195.6781, Training Accuracy = 79.61%\n",
      "Epoch 2267: Loss = 195.4765, Training Accuracy = 79.43%\n",
      "Epoch 2268: Loss = 195.9301, Training Accuracy = 79.54%\n",
      "Epoch 2269: Loss = 196.0378, Training Accuracy = 79.47%\n",
      "Epoch 2270: Loss = 194.5380, Training Accuracy = 79.65%\n",
      "Epoch 2271: Loss = 194.3361, Training Accuracy = 79.75%\n",
      "Epoch 2272: Loss = 193.7399, Training Accuracy = 79.69%\n",
      "Epoch 2273: Loss = 193.9583, Training Accuracy = 79.58%\n",
      "Epoch 2274: Loss = 193.7739, Training Accuracy = 79.80%\n",
      "Epoch 2275: Loss = 193.8385, Training Accuracy = 79.75%\n",
      "Epoch 2276: Loss = 194.2115, Training Accuracy = 79.79%\n",
      "Epoch 2277: Loss = 193.5173, Training Accuracy = 79.72%\n",
      "Epoch 2278: Loss = 193.8065, Training Accuracy = 79.80%\n",
      "Epoch 2279: Loss = 194.2712, Training Accuracy = 79.66%\n",
      "Epoch 2280: Loss = 194.3528, Training Accuracy = 79.70%\n",
      "Epoch 2281: Loss = 194.4839, Training Accuracy = 79.46%\n",
      "Epoch 2282: Loss = 193.9255, Training Accuracy = 79.59%\n",
      "Epoch 2283: Loss = 193.9785, Training Accuracy = 79.47%\n",
      "Epoch 2284: Loss = 194.2030, Training Accuracy = 79.74%\n",
      "Epoch 2285: Loss = 194.1424, Training Accuracy = 79.42%\n",
      "Epoch 2286: Loss = 193.5542, Training Accuracy = 79.59%\n",
      "Epoch 2287: Loss = 194.0226, Training Accuracy = 79.51%\n",
      "Epoch 2288: Loss = 193.6556, Training Accuracy = 79.36%\n",
      "Epoch 2289: Loss = 193.4235, Training Accuracy = 79.50%\n",
      "Epoch 2290: Loss = 194.2081, Training Accuracy = 79.22%\n",
      "Epoch 2291: Loss = 193.1240, Training Accuracy = 79.80%\n",
      "Epoch 2292: Loss = 193.3211, Training Accuracy = 79.86%\n",
      "Epoch 2293: Loss = 193.9969, Training Accuracy = 79.47%\n",
      "Epoch 2294: Loss = 193.7001, Training Accuracy = 79.86%\n",
      "Epoch 2295: Loss = 193.9688, Training Accuracy = 79.46%\n",
      "Epoch 2296: Loss = 193.6459, Training Accuracy = 79.55%\n",
      "Epoch 2297: Loss = 194.0203, Training Accuracy = 79.65%\n",
      "Epoch 2298: Loss = 193.7655, Training Accuracy = 79.52%\n",
      "Epoch 2299: Loss = 193.8688, Training Accuracy = 79.59%\n",
      "Epoch 2300: Loss = 193.3399, Training Accuracy = 79.75%\n",
      "Epoch 2301: Loss = 193.8991, Training Accuracy = 79.74%\n",
      "Epoch 2302: Loss = 193.5818, Training Accuracy = 79.58%\n",
      "Epoch 2303: Loss = 193.4930, Training Accuracy = 79.58%\n",
      "Epoch 2304: Loss = 192.6533, Training Accuracy = 79.64%\n",
      "Epoch 2305: Loss = 192.2773, Training Accuracy = 79.67%\n",
      "Epoch 2306: Loss = 193.1515, Training Accuracy = 79.50%\n",
      "Epoch 2307: Loss = 192.7423, Training Accuracy = 79.85%\n",
      "Epoch 2308: Loss = 192.5087, Training Accuracy = 79.95%\n",
      "Epoch 2309: Loss = 193.2502, Training Accuracy = 79.88%\n",
      "Epoch 2310: Loss = 193.5527, Training Accuracy = 79.58%\n",
      "Epoch 2311: Loss = 192.5345, Training Accuracy = 79.89%\n",
      "Epoch 2312: Loss = 193.3528, Training Accuracy = 79.74%\n",
      "Epoch 2313: Loss = 193.6064, Training Accuracy = 79.92%\n",
      "Epoch 2314: Loss = 193.8872, Training Accuracy = 79.81%\n",
      "Epoch 2315: Loss = 193.9589, Training Accuracy = 79.97%\n",
      "Epoch 2316: Loss = 194.1393, Training Accuracy = 79.83%\n",
      "Epoch 2317: Loss = 194.3145, Training Accuracy = 79.75%\n",
      "Epoch 2318: Loss = 194.4849, Training Accuracy = 79.77%\n",
      "Epoch 2319: Loss = 193.7581, Training Accuracy = 79.79%\n",
      "Epoch 2320: Loss = 194.4710, Training Accuracy = 79.69%\n",
      "Epoch 2321: Loss = 194.3387, Training Accuracy = 79.94%\n",
      "Epoch 2322: Loss = 194.8544, Training Accuracy = 79.90%\n",
      "Epoch 2323: Loss = 194.8072, Training Accuracy = 79.76%\n",
      "Epoch 2324: Loss = 195.1739, Training Accuracy = 79.81%\n",
      "Epoch 2325: Loss = 195.4011, Training Accuracy = 80.02%\n",
      "Epoch 2326: Loss = 195.3651, Training Accuracy = 79.74%\n",
      "Epoch 2327: Loss = 194.9738, Training Accuracy = 79.94%\n",
      "Epoch 2328: Loss = 195.0714, Training Accuracy = 79.92%\n",
      "Epoch 2329: Loss = 195.2311, Training Accuracy = 80.00%\n",
      "Epoch 2330: Loss = 195.8031, Training Accuracy = 79.95%\n",
      "Epoch 2331: Loss = 195.8300, Training Accuracy = 79.58%\n",
      "Epoch 2332: Loss = 195.4153, Training Accuracy = 80.00%\n",
      "Epoch 2333: Loss = 195.3566, Training Accuracy = 79.94%\n",
      "Epoch 2334: Loss = 195.2046, Training Accuracy = 79.87%\n",
      "Epoch 2335: Loss = 195.0152, Training Accuracy = 79.93%\n",
      "Epoch 2336: Loss = 194.7022, Training Accuracy = 80.05%\n",
      "Epoch 2337: Loss = 195.2926, Training Accuracy = 79.85%\n",
      "Epoch 2338: Loss = 194.2731, Training Accuracy = 80.09%\n",
      "Epoch 2339: Loss = 194.9170, Training Accuracy = 80.11%\n",
      "Epoch 2340: Loss = 194.5785, Training Accuracy = 80.20%\n",
      "Epoch 2341: Loss = 194.9568, Training Accuracy = 80.25%\n",
      "Epoch 2342: Loss = 195.1401, Training Accuracy = 80.22%\n",
      "Epoch 2343: Loss = 195.0682, Training Accuracy = 80.22%\n",
      "Epoch 2344: Loss = 194.8434, Training Accuracy = 80.08%\n",
      "Epoch 2345: Loss = 194.9053, Training Accuracy = 80.25%\n",
      "Epoch 2346: Loss = 195.0577, Training Accuracy = 80.12%\n",
      "Epoch 2347: Loss = 194.9427, Training Accuracy = 80.26%\n",
      "Epoch 2348: Loss = 195.4362, Training Accuracy = 80.06%\n",
      "Epoch 2349: Loss = 195.2202, Training Accuracy = 79.92%\n",
      "Epoch 2350: Loss = 195.2526, Training Accuracy = 80.01%\n",
      "Epoch 2351: Loss = 195.2902, Training Accuracy = 79.99%\n",
      "Epoch 2352: Loss = 195.0870, Training Accuracy = 79.97%\n",
      "Epoch 2353: Loss = 195.3175, Training Accuracy = 80.05%\n",
      "Epoch 2354: Loss = 195.2580, Training Accuracy = 80.11%\n",
      "Epoch 2355: Loss = 195.2494, Training Accuracy = 80.07%\n",
      "Epoch 2356: Loss = 195.6166, Training Accuracy = 80.06%\n",
      "Epoch 2357: Loss = 195.1091, Training Accuracy = 80.13%\n",
      "Epoch 2358: Loss = 194.8067, Training Accuracy = 80.03%\n",
      "Epoch 2359: Loss = 194.4191, Training Accuracy = 80.16%\n",
      "Epoch 2360: Loss = 195.3920, Training Accuracy = 79.95%\n",
      "Epoch 2361: Loss = 195.7975, Training Accuracy = 79.87%\n",
      "Epoch 2362: Loss = 195.5085, Training Accuracy = 80.08%\n",
      "Epoch 2363: Loss = 195.6341, Training Accuracy = 79.85%\n",
      "Epoch 2364: Loss = 195.4775, Training Accuracy = 79.88%\n",
      "Epoch 2365: Loss = 195.3370, Training Accuracy = 80.08%\n",
      "Epoch 2366: Loss = 195.0809, Training Accuracy = 80.15%\n",
      "Epoch 2367: Loss = 194.5174, Training Accuracy = 80.22%\n",
      "Epoch 2368: Loss = 195.1275, Training Accuracy = 80.04%\n",
      "Epoch 2369: Loss = 195.1168, Training Accuracy = 80.06%\n",
      "Epoch 2370: Loss = 195.2993, Training Accuracy = 80.18%\n",
      "Epoch 2371: Loss = 195.4428, Training Accuracy = 79.97%\n",
      "Epoch 2372: Loss = 194.8876, Training Accuracy = 79.90%\n",
      "Epoch 2373: Loss = 195.3094, Training Accuracy = 79.97%\n",
      "Epoch 2374: Loss = 194.2088, Training Accuracy = 80.10%\n",
      "Epoch 2375: Loss = 194.1890, Training Accuracy = 79.95%\n",
      "Epoch 2376: Loss = 194.3768, Training Accuracy = 79.89%\n",
      "Epoch 2377: Loss = 194.4531, Training Accuracy = 79.95%\n",
      "Epoch 2378: Loss = 193.7368, Training Accuracy = 79.93%\n",
      "Epoch 2379: Loss = 193.9558, Training Accuracy = 79.85%\n",
      "Epoch 2380: Loss = 194.4713, Training Accuracy = 79.94%\n",
      "Epoch 2381: Loss = 194.0094, Training Accuracy = 79.94%\n",
      "Epoch 2382: Loss = 194.4213, Training Accuracy = 80.06%\n",
      "Epoch 2383: Loss = 194.6644, Training Accuracy = 79.94%\n",
      "Epoch 2384: Loss = 194.4033, Training Accuracy = 80.01%\n",
      "Epoch 2385: Loss = 194.2280, Training Accuracy = 80.07%\n",
      "Epoch 2386: Loss = 194.0297, Training Accuracy = 80.15%\n",
      "Epoch 2387: Loss = 194.3889, Training Accuracy = 79.92%\n",
      "Epoch 2388: Loss = 194.5489, Training Accuracy = 80.19%\n",
      "Epoch 2389: Loss = 194.2831, Training Accuracy = 80.10%\n",
      "Epoch 2390: Loss = 194.3420, Training Accuracy = 80.44%\n",
      "Epoch 2391: Loss = 194.1874, Training Accuracy = 80.08%\n",
      "Epoch 2392: Loss = 193.7459, Training Accuracy = 80.07%\n",
      "Epoch 2393: Loss = 193.9248, Training Accuracy = 80.12%\n",
      "Epoch 2394: Loss = 194.1968, Training Accuracy = 80.16%\n",
      "Epoch 2395: Loss = 194.1549, Training Accuracy = 79.99%\n",
      "Epoch 2396: Loss = 194.2941, Training Accuracy = 80.22%\n",
      "Epoch 2397: Loss = 194.4409, Training Accuracy = 80.24%\n",
      "Epoch 2398: Loss = 194.3725, Training Accuracy = 80.09%\n",
      "Epoch 2399: Loss = 194.2686, Training Accuracy = 79.95%\n",
      "Epoch 2400: Loss = 193.9695, Training Accuracy = 80.01%\n",
      "Epoch 2401: Loss = 194.0088, Training Accuracy = 80.06%\n",
      "Epoch 2402: Loss = 194.5981, Training Accuracy = 80.04%\n",
      "Epoch 2403: Loss = 194.6482, Training Accuracy = 80.01%\n",
      "Epoch 2404: Loss = 194.1676, Training Accuracy = 80.22%\n",
      "Epoch 2405: Loss = 194.3504, Training Accuracy = 80.12%\n",
      "Epoch 2406: Loss = 194.5967, Training Accuracy = 79.90%\n",
      "Epoch 2407: Loss = 194.6737, Training Accuracy = 80.05%\n",
      "Epoch 2408: Loss = 194.5067, Training Accuracy = 80.07%\n",
      "Epoch 2409: Loss = 195.0292, Training Accuracy = 80.22%\n",
      "Epoch 2410: Loss = 194.8906, Training Accuracy = 80.05%\n",
      "Epoch 2411: Loss = 195.0312, Training Accuracy = 80.02%\n",
      "Epoch 2412: Loss = 195.1226, Training Accuracy = 80.07%\n",
      "Epoch 2413: Loss = 194.5410, Training Accuracy = 80.07%\n",
      "Epoch 2414: Loss = 194.6729, Training Accuracy = 79.79%\n",
      "Epoch 2415: Loss = 195.1833, Training Accuracy = 79.84%\n",
      "Epoch 2416: Loss = 195.1711, Training Accuracy = 79.96%\n",
      "Epoch 2417: Loss = 195.2696, Training Accuracy = 79.76%\n",
      "Epoch 2418: Loss = 194.4836, Training Accuracy = 79.86%\n",
      "Epoch 2419: Loss = 194.5922, Training Accuracy = 79.89%\n",
      "Epoch 2420: Loss = 194.7792, Training Accuracy = 79.92%\n",
      "Epoch 2421: Loss = 195.1841, Training Accuracy = 79.99%\n",
      "Epoch 2422: Loss = 195.2966, Training Accuracy = 79.62%\n",
      "Epoch 2423: Loss = 195.4017, Training Accuracy = 79.91%\n",
      "Epoch 2424: Loss = 195.5785, Training Accuracy = 79.77%\n",
      "Epoch 2425: Loss = 195.0056, Training Accuracy = 79.84%\n",
      "Epoch 2426: Loss = 195.0290, Training Accuracy = 79.88%\n",
      "Epoch 2427: Loss = 194.9970, Training Accuracy = 79.93%\n",
      "Epoch 2428: Loss = 195.1128, Training Accuracy = 79.94%\n",
      "Epoch 2429: Loss = 194.7638, Training Accuracy = 79.84%\n",
      "Epoch 2430: Loss = 194.9698, Training Accuracy = 79.97%\n",
      "Epoch 2431: Loss = 194.9946, Training Accuracy = 79.72%\n",
      "Epoch 2432: Loss = 195.4306, Training Accuracy = 79.79%\n",
      "Epoch 2433: Loss = 193.8488, Training Accuracy = 80.06%\n",
      "Epoch 2434: Loss = 195.3220, Training Accuracy = 79.89%\n",
      "Epoch 2435: Loss = 195.3162, Training Accuracy = 79.83%\n",
      "Epoch 2436: Loss = 194.4314, Training Accuracy = 80.03%\n",
      "Epoch 2437: Loss = 194.6674, Training Accuracy = 80.07%\n",
      "Epoch 2438: Loss = 194.3430, Training Accuracy = 80.03%\n",
      "Epoch 2439: Loss = 194.2962, Training Accuracy = 79.88%\n",
      "Epoch 2440: Loss = 193.9030, Training Accuracy = 80.07%\n",
      "Epoch 2441: Loss = 194.0210, Training Accuracy = 80.17%\n",
      "Epoch 2442: Loss = 194.1944, Training Accuracy = 80.25%\n",
      "Epoch 2443: Loss = 193.6020, Training Accuracy = 79.84%\n",
      "Epoch 2444: Loss = 193.8082, Training Accuracy = 79.80%\n",
      "Epoch 2445: Loss = 193.7906, Training Accuracy = 80.21%\n",
      "Epoch 2446: Loss = 194.1533, Training Accuracy = 79.97%\n",
      "Epoch 2447: Loss = 192.9101, Training Accuracy = 80.11%\n",
      "Epoch 2448: Loss = 193.3242, Training Accuracy = 80.10%\n",
      "Epoch 2449: Loss = 193.5458, Training Accuracy = 80.01%\n",
      "Epoch 2450: Loss = 193.9431, Training Accuracy = 79.73%\n",
      "Epoch 2451: Loss = 193.8961, Training Accuracy = 79.72%\n",
      "Epoch 2452: Loss = 194.2243, Training Accuracy = 80.03%\n",
      "Epoch 2453: Loss = 193.9839, Training Accuracy = 80.03%\n",
      "Epoch 2454: Loss = 194.0216, Training Accuracy = 79.75%\n",
      "Epoch 2455: Loss = 194.2278, Training Accuracy = 79.73%\n",
      "Epoch 2456: Loss = 194.7802, Training Accuracy = 79.56%\n",
      "Epoch 2457: Loss = 194.5882, Training Accuracy = 79.69%\n",
      "Epoch 2458: Loss = 194.7010, Training Accuracy = 79.85%\n",
      "Epoch 2459: Loss = 195.1546, Training Accuracy = 79.72%\n",
      "Epoch 2460: Loss = 195.0574, Training Accuracy = 79.69%\n",
      "Epoch 2461: Loss = 194.7886, Training Accuracy = 79.75%\n",
      "Epoch 2462: Loss = 194.2604, Training Accuracy = 79.79%\n",
      "Epoch 2463: Loss = 194.5384, Training Accuracy = 79.72%\n",
      "Epoch 2464: Loss = 194.8584, Training Accuracy = 79.84%\n",
      "Epoch 2465: Loss = 194.5535, Training Accuracy = 79.91%\n",
      "Epoch 2466: Loss = 194.0172, Training Accuracy = 79.92%\n",
      "Epoch 2467: Loss = 195.2660, Training Accuracy = 79.87%\n",
      "Epoch 2468: Loss = 195.2615, Training Accuracy = 80.05%\n",
      "Epoch 2469: Loss = 194.6192, Training Accuracy = 79.70%\n",
      "Epoch 2470: Loss = 194.8446, Training Accuracy = 79.73%\n",
      "Epoch 2471: Loss = 195.2924, Training Accuracy = 79.75%\n",
      "Epoch 2472: Loss = 194.9658, Training Accuracy = 79.74%\n",
      "Epoch 2473: Loss = 195.0788, Training Accuracy = 79.86%\n",
      "Epoch 2474: Loss = 195.0018, Training Accuracy = 79.64%\n",
      "Epoch 2475: Loss = 195.2973, Training Accuracy = 79.91%\n",
      "Epoch 2476: Loss = 195.4510, Training Accuracy = 79.76%\n",
      "Epoch 2477: Loss = 195.6439, Training Accuracy = 79.70%\n",
      "Epoch 2478: Loss = 195.0760, Training Accuracy = 79.75%\n",
      "Epoch 2479: Loss = 195.5812, Training Accuracy = 79.80%\n",
      "Epoch 2480: Loss = 195.1120, Training Accuracy = 79.88%\n",
      "Epoch 2481: Loss = 195.4091, Training Accuracy = 79.89%\n",
      "Epoch 2482: Loss = 195.6841, Training Accuracy = 79.83%\n",
      "Epoch 2483: Loss = 195.5056, Training Accuracy = 79.96%\n",
      "Epoch 2484: Loss = 194.9541, Training Accuracy = 79.90%\n",
      "Epoch 2485: Loss = 195.1978, Training Accuracy = 79.80%\n",
      "Epoch 2486: Loss = 194.9601, Training Accuracy = 79.90%\n",
      "Epoch 2487: Loss = 195.2359, Training Accuracy = 79.89%\n",
      "Epoch 2488: Loss = 195.2146, Training Accuracy = 80.05%\n",
      "Epoch 2489: Loss = 195.2272, Training Accuracy = 79.96%\n",
      "Epoch 2490: Loss = 194.8437, Training Accuracy = 79.95%\n",
      "Epoch 2491: Loss = 195.3643, Training Accuracy = 79.88%\n",
      "Epoch 2492: Loss = 194.9039, Training Accuracy = 79.87%\n",
      "Epoch 2493: Loss = 195.4426, Training Accuracy = 80.00%\n",
      "Epoch 2494: Loss = 195.2907, Training Accuracy = 79.97%\n",
      "Epoch 2495: Loss = 195.3898, Training Accuracy = 79.93%\n",
      "Epoch 2496: Loss = 194.7901, Training Accuracy = 79.94%\n",
      "Epoch 2497: Loss = 194.4433, Training Accuracy = 79.99%\n",
      "Epoch 2498: Loss = 194.8187, Training Accuracy = 79.99%\n",
      "Epoch 2499: Loss = 195.1020, Training Accuracy = 79.99%\n",
      "Epoch 2500: Loss = 194.9832, Training Accuracy = 79.82%\n",
      "Epoch 2501: Loss = 195.1994, Training Accuracy = 79.75%\n",
      "Epoch 2502: Loss = 195.0558, Training Accuracy = 80.04%\n",
      "Epoch 2503: Loss = 195.1185, Training Accuracy = 80.01%\n",
      "Epoch 2504: Loss = 194.6296, Training Accuracy = 80.02%\n",
      "Epoch 2505: Loss = 194.3237, Training Accuracy = 80.08%\n",
      "Epoch 2506: Loss = 194.5318, Training Accuracy = 79.90%\n",
      "Epoch 2507: Loss = 194.9644, Training Accuracy = 79.88%\n",
      "Epoch 2508: Loss = 194.7392, Training Accuracy = 80.02%\n",
      "Epoch 2509: Loss = 195.0226, Training Accuracy = 80.19%\n",
      "Epoch 2510: Loss = 194.4850, Training Accuracy = 80.16%\n",
      "Epoch 2511: Loss = 194.4697, Training Accuracy = 80.18%\n",
      "Epoch 2512: Loss = 194.6739, Training Accuracy = 80.19%\n",
      "Epoch 2513: Loss = 194.8279, Training Accuracy = 79.99%\n",
      "Epoch 2514: Loss = 194.9062, Training Accuracy = 80.20%\n",
      "Epoch 2515: Loss = 193.9905, Training Accuracy = 80.33%\n",
      "Epoch 2516: Loss = 193.9722, Training Accuracy = 80.41%\n",
      "Epoch 2517: Loss = 193.6956, Training Accuracy = 80.40%\n",
      "Epoch 2518: Loss = 194.1738, Training Accuracy = 80.35%\n",
      "Epoch 2519: Loss = 194.4831, Training Accuracy = 80.29%\n",
      "Epoch 2520: Loss = 194.9458, Training Accuracy = 80.10%\n",
      "Epoch 2521: Loss = 195.0498, Training Accuracy = 80.27%\n",
      "Epoch 2522: Loss = 195.3581, Training Accuracy = 80.05%\n",
      "Epoch 2523: Loss = 195.1607, Training Accuracy = 80.15%\n",
      "Epoch 2524: Loss = 195.3887, Training Accuracy = 80.15%\n",
      "Epoch 2525: Loss = 195.4575, Training Accuracy = 80.31%\n",
      "Epoch 2526: Loss = 195.3612, Training Accuracy = 80.28%\n",
      "Epoch 2527: Loss = 195.6972, Training Accuracy = 80.27%\n",
      "Epoch 2528: Loss = 195.6144, Training Accuracy = 80.22%\n",
      "Epoch 2529: Loss = 195.2040, Training Accuracy = 80.43%\n",
      "Epoch 2530: Loss = 194.7893, Training Accuracy = 80.45%\n",
      "Epoch 2531: Loss = 195.1788, Training Accuracy = 80.28%\n",
      "Epoch 2532: Loss = 195.0408, Training Accuracy = 80.32%\n",
      "Epoch 2533: Loss = 195.0675, Training Accuracy = 80.48%\n",
      "Epoch 2534: Loss = 195.4334, Training Accuracy = 80.26%\n",
      "Epoch 2535: Loss = 195.3563, Training Accuracy = 80.15%\n",
      "Epoch 2536: Loss = 195.7147, Training Accuracy = 80.16%\n",
      "Epoch 2537: Loss = 194.9761, Training Accuracy = 80.15%\n",
      "Epoch 2538: Loss = 195.8736, Training Accuracy = 80.17%\n",
      "Epoch 2539: Loss = 195.7278, Training Accuracy = 79.97%\n",
      "Epoch 2540: Loss = 195.3910, Training Accuracy = 80.17%\n",
      "Epoch 2541: Loss = 195.3836, Training Accuracy = 80.18%\n",
      "Epoch 2542: Loss = 195.7839, Training Accuracy = 80.16%\n",
      "Epoch 2543: Loss = 196.0186, Training Accuracy = 80.36%\n",
      "Epoch 2544: Loss = 194.8602, Training Accuracy = 80.39%\n",
      "Epoch 2545: Loss = 195.2596, Training Accuracy = 80.28%\n",
      "Epoch 2546: Loss = 195.5806, Training Accuracy = 79.91%\n",
      "Epoch 2547: Loss = 195.3646, Training Accuracy = 80.45%\n",
      "Epoch 2548: Loss = 196.1437, Training Accuracy = 80.33%\n",
      "Epoch 2549: Loss = 196.5267, Training Accuracy = 79.92%\n",
      "Epoch 2550: Loss = 196.1941, Training Accuracy = 79.89%\n",
      "Epoch 2551: Loss = 195.8550, Training Accuracy = 80.03%\n",
      "Epoch 2552: Loss = 196.1888, Training Accuracy = 80.02%\n",
      "Epoch 2553: Loss = 196.2708, Training Accuracy = 79.84%\n",
      "Epoch 2554: Loss = 195.7457, Training Accuracy = 80.00%\n",
      "Epoch 2555: Loss = 195.7260, Training Accuracy = 80.05%\n",
      "Epoch 2556: Loss = 195.6553, Training Accuracy = 80.01%\n",
      "Epoch 2557: Loss = 195.6937, Training Accuracy = 79.93%\n",
      "Epoch 2558: Loss = 195.8795, Training Accuracy = 79.99%\n",
      "Epoch 2559: Loss = 195.4821, Training Accuracy = 80.11%\n",
      "Epoch 2560: Loss = 195.5321, Training Accuracy = 80.08%\n",
      "Epoch 2561: Loss = 195.5776, Training Accuracy = 80.11%\n",
      "Epoch 2562: Loss = 195.5306, Training Accuracy = 80.25%\n",
      "Epoch 2563: Loss = 196.1081, Training Accuracy = 80.12%\n",
      "Epoch 2564: Loss = 195.9434, Training Accuracy = 80.11%\n",
      "Epoch 2565: Loss = 196.4433, Training Accuracy = 80.17%\n",
      "Epoch 2566: Loss = 196.1236, Training Accuracy = 80.07%\n",
      "Epoch 2567: Loss = 195.8472, Training Accuracy = 79.96%\n",
      "Epoch 2568: Loss = 196.0401, Training Accuracy = 79.97%\n",
      "Epoch 2569: Loss = 196.1775, Training Accuracy = 80.13%\n",
      "Epoch 2570: Loss = 196.3551, Training Accuracy = 79.75%\n",
      "Epoch 2571: Loss = 195.9796, Training Accuracy = 79.79%\n",
      "Epoch 2572: Loss = 196.2263, Training Accuracy = 79.63%\n",
      "Epoch 2573: Loss = 195.5555, Training Accuracy = 79.95%\n",
      "Epoch 2574: Loss = 196.1673, Training Accuracy = 79.88%\n",
      "Epoch 2575: Loss = 195.7944, Training Accuracy = 79.64%\n",
      "Epoch 2576: Loss = 195.3135, Training Accuracy = 79.87%\n",
      "Epoch 2577: Loss = 195.0764, Training Accuracy = 79.98%\n",
      "Epoch 2578: Loss = 194.7872, Training Accuracy = 80.07%\n",
      "Epoch 2579: Loss = 195.3168, Training Accuracy = 80.05%\n",
      "Epoch 2580: Loss = 195.6147, Training Accuracy = 80.05%\n",
      "Epoch 2581: Loss = 195.1102, Training Accuracy = 80.08%\n",
      "Epoch 2582: Loss = 194.9063, Training Accuracy = 80.09%\n",
      "Epoch 2583: Loss = 195.3550, Training Accuracy = 79.95%\n",
      "Epoch 2584: Loss = 195.5374, Training Accuracy = 80.05%\n",
      "Epoch 2585: Loss = 195.4911, Training Accuracy = 80.08%\n",
      "Epoch 2586: Loss = 194.7493, Training Accuracy = 80.10%\n",
      "Epoch 2587: Loss = 194.8776, Training Accuracy = 80.16%\n",
      "Epoch 2588: Loss = 195.1741, Training Accuracy = 80.20%\n",
      "Epoch 2589: Loss = 195.0967, Training Accuracy = 80.25%\n",
      "Epoch 2590: Loss = 194.7049, Training Accuracy = 80.16%\n",
      "Epoch 2591: Loss = 194.7098, Training Accuracy = 80.10%\n",
      "Epoch 2592: Loss = 194.8407, Training Accuracy = 80.01%\n",
      "Epoch 2593: Loss = 195.8521, Training Accuracy = 79.95%\n",
      "Epoch 2594: Loss = 195.5607, Training Accuracy = 80.01%\n",
      "Epoch 2595: Loss = 195.2069, Training Accuracy = 80.06%\n",
      "Epoch 2596: Loss = 194.8819, Training Accuracy = 80.25%\n",
      "Epoch 2597: Loss = 195.1097, Training Accuracy = 80.10%\n",
      "Epoch 2598: Loss = 194.6033, Training Accuracy = 80.15%\n",
      "Epoch 2599: Loss = 194.1797, Training Accuracy = 80.31%\n",
      "Epoch 2600: Loss = 194.6026, Training Accuracy = 80.29%\n",
      "Epoch 2601: Loss = 194.9724, Training Accuracy = 80.42%\n",
      "Epoch 2602: Loss = 195.0099, Training Accuracy = 80.39%\n",
      "Epoch 2603: Loss = 194.7542, Training Accuracy = 80.14%\n",
      "Epoch 2604: Loss = 194.6875, Training Accuracy = 80.28%\n",
      "Epoch 2605: Loss = 195.2263, Training Accuracy = 80.26%\n",
      "Epoch 2606: Loss = 195.2136, Training Accuracy = 80.27%\n",
      "Epoch 2607: Loss = 195.1265, Training Accuracy = 80.25%\n",
      "Epoch 2608: Loss = 194.9475, Training Accuracy = 80.18%\n",
      "Epoch 2609: Loss = 194.4997, Training Accuracy = 80.39%\n",
      "Epoch 2610: Loss = 194.5246, Training Accuracy = 80.33%\n",
      "Epoch 2611: Loss = 194.0155, Training Accuracy = 80.29%\n",
      "Epoch 2612: Loss = 194.6179, Training Accuracy = 80.08%\n",
      "Epoch 2613: Loss = 194.8458, Training Accuracy = 80.41%\n",
      "Epoch 2614: Loss = 194.6852, Training Accuracy = 80.29%\n",
      "Epoch 2615: Loss = 194.9773, Training Accuracy = 80.47%\n",
      "Epoch 2616: Loss = 194.7210, Training Accuracy = 80.34%\n",
      "Epoch 2617: Loss = 194.4597, Training Accuracy = 80.42%\n",
      "Epoch 2618: Loss = 194.3057, Training Accuracy = 80.46%\n",
      "Epoch 2619: Loss = 194.2354, Training Accuracy = 80.48%\n",
      "Epoch 2620: Loss = 194.0070, Training Accuracy = 80.62%\n",
      "Epoch 2621: Loss = 194.1990, Training Accuracy = 80.69%\n",
      "Epoch 2622: Loss = 194.2862, Training Accuracy = 80.69%\n",
      "Epoch 2623: Loss = 194.3565, Training Accuracy = 80.52%\n",
      "Epoch 2624: Loss = 194.6163, Training Accuracy = 80.47%\n",
      "Epoch 2625: Loss = 194.4908, Training Accuracy = 80.61%\n",
      "Epoch 2626: Loss = 194.0518, Training Accuracy = 80.44%\n",
      "Epoch 2627: Loss = 194.0879, Training Accuracy = 80.48%\n",
      "Epoch 2628: Loss = 193.9477, Training Accuracy = 80.46%\n",
      "Epoch 2629: Loss = 193.1977, Training Accuracy = 80.52%\n",
      "Epoch 2630: Loss = 193.0379, Training Accuracy = 80.62%\n",
      "Epoch 2631: Loss = 193.4812, Training Accuracy = 80.65%\n",
      "Epoch 2632: Loss = 193.5886, Training Accuracy = 80.61%\n",
      "Epoch 2633: Loss = 193.5253, Training Accuracy = 80.48%\n",
      "Epoch 2634: Loss = 193.5991, Training Accuracy = 80.63%\n",
      "Epoch 2635: Loss = 193.6207, Training Accuracy = 80.70%\n",
      "Epoch 2636: Loss = 193.3975, Training Accuracy = 80.66%\n",
      "Epoch 2637: Loss = 193.4993, Training Accuracy = 80.70%\n",
      "Epoch 2638: Loss = 193.6501, Training Accuracy = 80.58%\n",
      "Epoch 2639: Loss = 193.3336, Training Accuracy = 80.73%\n",
      "Epoch 2640: Loss = 193.4810, Training Accuracy = 80.71%\n",
      "Epoch 2641: Loss = 193.8262, Training Accuracy = 80.69%\n",
      "Epoch 2642: Loss = 193.7135, Training Accuracy = 80.65%\n",
      "Epoch 2643: Loss = 193.0723, Training Accuracy = 80.81%\n",
      "Epoch 2644: Loss = 193.9149, Training Accuracy = 80.65%\n",
      "Epoch 2645: Loss = 193.1933, Training Accuracy = 80.76%\n",
      "Epoch 2646: Loss = 192.7715, Training Accuracy = 80.80%\n",
      "Epoch 2647: Loss = 192.6235, Training Accuracy = 80.73%\n",
      "Epoch 2648: Loss = 192.6891, Training Accuracy = 80.84%\n",
      "Epoch 2649: Loss = 193.0492, Training Accuracy = 80.84%\n",
      "Epoch 2650: Loss = 192.9419, Training Accuracy = 80.81%\n",
      "Epoch 2651: Loss = 192.8189, Training Accuracy = 80.68%\n",
      "Epoch 2652: Loss = 192.0958, Training Accuracy = 80.87%\n",
      "Epoch 2653: Loss = 193.0451, Training Accuracy = 80.82%\n",
      "Epoch 2654: Loss = 193.0314, Training Accuracy = 80.87%\n",
      "Epoch 2655: Loss = 191.9855, Training Accuracy = 80.99%\n",
      "Epoch 2656: Loss = 192.1535, Training Accuracy = 80.88%\n",
      "Epoch 2657: Loss = 192.4668, Training Accuracy = 80.80%\n",
      "Epoch 2658: Loss = 191.7491, Training Accuracy = 80.84%\n",
      "Epoch 2659: Loss = 191.7647, Training Accuracy = 80.82%\n",
      "Epoch 2660: Loss = 192.2419, Training Accuracy = 80.76%\n",
      "Epoch 2661: Loss = 192.2599, Training Accuracy = 80.92%\n",
      "Epoch 2662: Loss = 191.9289, Training Accuracy = 81.00%\n",
      "Epoch 2663: Loss = 191.4692, Training Accuracy = 80.72%\n",
      "Epoch 2664: Loss = 191.0343, Training Accuracy = 81.01%\n",
      "Epoch 2665: Loss = 191.1457, Training Accuracy = 80.66%\n",
      "Epoch 2666: Loss = 191.1107, Training Accuracy = 80.76%\n",
      "Epoch 2667: Loss = 191.6450, Training Accuracy = 80.64%\n",
      "Epoch 2668: Loss = 191.3757, Training Accuracy = 80.67%\n",
      "Epoch 2669: Loss = 191.2343, Training Accuracy = 80.76%\n",
      "Epoch 2670: Loss = 191.2741, Training Accuracy = 80.69%\n",
      "Epoch 2671: Loss = 191.9590, Training Accuracy = 80.77%\n",
      "Epoch 2672: Loss = 192.1264, Training Accuracy = 80.44%\n",
      "Epoch 2673: Loss = 191.9004, Training Accuracy = 80.54%\n",
      "Epoch 2674: Loss = 192.2456, Training Accuracy = 80.59%\n",
      "Epoch 2675: Loss = 192.3735, Training Accuracy = 80.53%\n",
      "Epoch 2676: Loss = 192.2030, Training Accuracy = 80.54%\n",
      "Epoch 2677: Loss = 191.9619, Training Accuracy = 80.51%\n",
      "Epoch 2678: Loss = 191.7018, Training Accuracy = 80.47%\n",
      "Epoch 2679: Loss = 191.9527, Training Accuracy = 80.48%\n",
      "Epoch 2680: Loss = 191.8598, Training Accuracy = 80.50%\n",
      "Epoch 2681: Loss = 191.3372, Training Accuracy = 80.76%\n",
      "Epoch 2682: Loss = 190.7902, Training Accuracy = 80.62%\n",
      "Epoch 2683: Loss = 191.8948, Training Accuracy = 80.52%\n",
      "Epoch 2684: Loss = 191.2629, Training Accuracy = 80.69%\n",
      "Epoch 2685: Loss = 191.2060, Training Accuracy = 80.68%\n",
      "Epoch 2686: Loss = 191.7428, Training Accuracy = 80.64%\n",
      "Epoch 2687: Loss = 191.4350, Training Accuracy = 80.71%\n",
      "Epoch 2688: Loss = 191.3760, Training Accuracy = 80.72%\n",
      "Epoch 2689: Loss = 191.1167, Training Accuracy = 80.78%\n",
      "Epoch 2690: Loss = 191.2053, Training Accuracy = 80.85%\n",
      "Epoch 2691: Loss = 191.2370, Training Accuracy = 80.72%\n",
      "Epoch 2692: Loss = 190.6423, Training Accuracy = 80.74%\n",
      "Epoch 2693: Loss = 191.4228, Training Accuracy = 80.80%\n",
      "Epoch 2694: Loss = 191.3772, Training Accuracy = 80.59%\n",
      "Epoch 2695: Loss = 191.3041, Training Accuracy = 80.77%\n",
      "Epoch 2696: Loss = 190.8700, Training Accuracy = 80.76%\n",
      "Epoch 2697: Loss = 190.8377, Training Accuracy = 80.73%\n",
      "Epoch 2698: Loss = 191.0987, Training Accuracy = 80.81%\n",
      "Epoch 2699: Loss = 191.1197, Training Accuracy = 80.76%\n",
      "Epoch 2700: Loss = 190.8058, Training Accuracy = 80.76%\n",
      "Epoch 2701: Loss = 191.5893, Training Accuracy = 80.75%\n",
      "Epoch 2702: Loss = 191.7209, Training Accuracy = 80.89%\n",
      "Epoch 2703: Loss = 191.6434, Training Accuracy = 80.80%\n",
      "Epoch 2704: Loss = 191.8533, Training Accuracy = 80.71%\n",
      "Epoch 2705: Loss = 191.7396, Training Accuracy = 80.94%\n",
      "Epoch 2706: Loss = 191.7357, Training Accuracy = 80.94%\n",
      "Epoch 2707: Loss = 191.4644, Training Accuracy = 80.86%\n",
      "Epoch 2708: Loss = 191.6410, Training Accuracy = 80.87%\n",
      "Epoch 2709: Loss = 191.6305, Training Accuracy = 80.81%\n",
      "Epoch 2710: Loss = 191.6718, Training Accuracy = 80.73%\n",
      "Epoch 2711: Loss = 191.2635, Training Accuracy = 80.67%\n",
      "Epoch 2712: Loss = 191.0192, Training Accuracy = 80.40%\n",
      "Epoch 2713: Loss = 191.1655, Training Accuracy = 80.50%\n",
      "Epoch 2714: Loss = 191.5682, Training Accuracy = 80.41%\n",
      "Epoch 2715: Loss = 191.7904, Training Accuracy = 80.40%\n",
      "Epoch 2716: Loss = 191.5984, Training Accuracy = 80.47%\n",
      "Epoch 2717: Loss = 191.9672, Training Accuracy = 81.03%\n",
      "Epoch 2718: Loss = 191.7270, Training Accuracy = 80.94%\n",
      "Epoch 2719: Loss = 191.5894, Training Accuracy = 80.86%\n",
      "Epoch 2720: Loss = 191.7157, Training Accuracy = 80.82%\n",
      "Epoch 2721: Loss = 191.7483, Training Accuracy = 81.06%\n",
      "Epoch 2722: Loss = 191.9408, Training Accuracy = 80.99%\n",
      "Epoch 2723: Loss = 191.7522, Training Accuracy = 81.08%\n",
      "Epoch 2724: Loss = 191.7643, Training Accuracy = 81.09%\n",
      "Epoch 2725: Loss = 191.6208, Training Accuracy = 81.04%\n",
      "Epoch 2726: Loss = 191.6701, Training Accuracy = 81.03%\n",
      "Epoch 2727: Loss = 191.5605, Training Accuracy = 81.12%\n",
      "Epoch 2728: Loss = 191.7337, Training Accuracy = 81.09%\n",
      "Epoch 2729: Loss = 191.5397, Training Accuracy = 81.06%\n",
      "Epoch 2730: Loss = 191.4900, Training Accuracy = 81.15%\n",
      "Epoch 2731: Loss = 191.5105, Training Accuracy = 81.09%\n",
      "Epoch 2732: Loss = 191.3071, Training Accuracy = 80.80%\n",
      "Epoch 2733: Loss = 191.6313, Training Accuracy = 80.98%\n",
      "Epoch 2734: Loss = 191.9124, Training Accuracy = 80.79%\n",
      "Epoch 2735: Loss = 191.4756, Training Accuracy = 80.99%\n",
      "Epoch 2736: Loss = 191.4872, Training Accuracy = 80.83%\n",
      "Epoch 2737: Loss = 191.4424, Training Accuracy = 81.06%\n",
      "Epoch 2738: Loss = 191.6257, Training Accuracy = 81.00%\n",
      "Epoch 2739: Loss = 191.8723, Training Accuracy = 80.80%\n",
      "Epoch 2740: Loss = 191.9142, Training Accuracy = 80.92%\n",
      "Epoch 2741: Loss = 191.6160, Training Accuracy = 80.95%\n",
      "Epoch 2742: Loss = 191.6111, Training Accuracy = 80.98%\n",
      "Epoch 2743: Loss = 191.3307, Training Accuracy = 80.80%\n",
      "Epoch 2744: Loss = 191.5733, Training Accuracy = 80.98%\n",
      "Epoch 2745: Loss = 191.4780, Training Accuracy = 80.86%\n",
      "Epoch 2746: Loss = 190.9279, Training Accuracy = 80.85%\n",
      "Epoch 2747: Loss = 191.1386, Training Accuracy = 80.96%\n",
      "Epoch 2748: Loss = 190.5223, Training Accuracy = 80.84%\n",
      "Epoch 2749: Loss = 191.0161, Training Accuracy = 80.85%\n",
      "Epoch 2750: Loss = 191.4235, Training Accuracy = 80.78%\n",
      "Epoch 2751: Loss = 191.0749, Training Accuracy = 80.79%\n",
      "Epoch 2752: Loss = 191.3414, Training Accuracy = 80.61%\n",
      "Epoch 2753: Loss = 191.4576, Training Accuracy = 80.73%\n",
      "Epoch 2754: Loss = 190.9602, Training Accuracy = 80.76%\n",
      "Epoch 2755: Loss = 191.0292, Training Accuracy = 80.54%\n",
      "Epoch 2756: Loss = 191.1683, Training Accuracy = 80.77%\n",
      "Epoch 2757: Loss = 190.4093, Training Accuracy = 80.86%\n",
      "Epoch 2758: Loss = 191.0568, Training Accuracy = 80.79%\n",
      "Epoch 2759: Loss = 191.1895, Training Accuracy = 80.66%\n",
      "Epoch 2760: Loss = 191.3817, Training Accuracy = 80.60%\n",
      "Epoch 2761: Loss = 191.3400, Training Accuracy = 80.66%\n",
      "Epoch 2762: Loss = 191.0324, Training Accuracy = 80.68%\n",
      "Epoch 2763: Loss = 191.6369, Training Accuracy = 80.71%\n",
      "Epoch 2764: Loss = 191.5222, Training Accuracy = 80.58%\n",
      "Epoch 2765: Loss = 191.0745, Training Accuracy = 80.74%\n",
      "Epoch 2766: Loss = 190.9170, Training Accuracy = 80.85%\n",
      "Epoch 2767: Loss = 191.0082, Training Accuracy = 80.68%\n",
      "Epoch 2768: Loss = 191.4119, Training Accuracy = 80.70%\n",
      "Epoch 2769: Loss = 191.7143, Training Accuracy = 80.38%\n",
      "Epoch 2770: Loss = 191.2827, Training Accuracy = 80.71%\n",
      "Epoch 2771: Loss = 191.4455, Training Accuracy = 80.47%\n",
      "Epoch 2772: Loss = 191.0854, Training Accuracy = 80.87%\n",
      "Epoch 2773: Loss = 191.6035, Training Accuracy = 80.68%\n",
      "Epoch 2774: Loss = 191.6784, Training Accuracy = 80.84%\n",
      "Epoch 2775: Loss = 192.1042, Training Accuracy = 80.78%\n",
      "Epoch 2776: Loss = 192.3043, Training Accuracy = 80.69%\n",
      "Epoch 2777: Loss = 192.3960, Training Accuracy = 80.73%\n",
      "Epoch 2778: Loss = 192.0233, Training Accuracy = 80.69%\n",
      "Epoch 2779: Loss = 191.8115, Training Accuracy = 80.88%\n",
      "Epoch 2780: Loss = 192.0484, Training Accuracy = 80.85%\n",
      "Epoch 2781: Loss = 191.9226, Training Accuracy = 80.75%\n",
      "Epoch 2782: Loss = 191.6550, Training Accuracy = 80.82%\n",
      "Epoch 2783: Loss = 191.8648, Training Accuracy = 80.81%\n",
      "Epoch 2784: Loss = 191.5386, Training Accuracy = 80.72%\n",
      "Epoch 2785: Loss = 191.5633, Training Accuracy = 80.90%\n",
      "Epoch 2786: Loss = 191.5159, Training Accuracy = 80.69%\n",
      "Epoch 2787: Loss = 191.8451, Training Accuracy = 80.68%\n",
      "Epoch 2788: Loss = 191.1548, Training Accuracy = 80.62%\n",
      "Epoch 2789: Loss = 191.5069, Training Accuracy = 80.55%\n",
      "Epoch 2790: Loss = 191.5003, Training Accuracy = 80.70%\n",
      "Epoch 2791: Loss = 191.0794, Training Accuracy = 80.63%\n",
      "Epoch 2792: Loss = 191.5733, Training Accuracy = 80.58%\n",
      "Epoch 2793: Loss = 191.7859, Training Accuracy = 80.46%\n",
      "Epoch 2794: Loss = 191.7425, Training Accuracy = 80.44%\n",
      "Epoch 2795: Loss = 192.2897, Training Accuracy = 80.41%\n",
      "Epoch 2796: Loss = 191.9745, Training Accuracy = 80.63%\n",
      "Epoch 2797: Loss = 192.5109, Training Accuracy = 80.40%\n",
      "Epoch 2798: Loss = 192.3974, Training Accuracy = 80.36%\n",
      "Epoch 2799: Loss = 192.4092, Training Accuracy = 80.30%\n",
      "Epoch 2800: Loss = 192.2245, Training Accuracy = 80.47%\n",
      "Epoch 2801: Loss = 191.9496, Training Accuracy = 80.62%\n",
      "Epoch 2802: Loss = 191.9405, Training Accuracy = 80.55%\n",
      "Epoch 2803: Loss = 191.7196, Training Accuracy = 80.47%\n",
      "Epoch 2804: Loss = 192.0980, Training Accuracy = 80.78%\n",
      "Epoch 2805: Loss = 192.2672, Training Accuracy = 80.40%\n",
      "Epoch 2806: Loss = 192.2678, Training Accuracy = 80.40%\n",
      "Epoch 2807: Loss = 192.3907, Training Accuracy = 80.71%\n",
      "Epoch 2808: Loss = 192.1895, Training Accuracy = 80.65%\n",
      "Epoch 2809: Loss = 192.1030, Training Accuracy = 80.51%\n",
      "Epoch 2810: Loss = 192.0333, Training Accuracy = 80.52%\n",
      "Epoch 2811: Loss = 191.9727, Training Accuracy = 80.54%\n",
      "Epoch 2812: Loss = 191.8723, Training Accuracy = 80.59%\n",
      "Epoch 2813: Loss = 191.6172, Training Accuracy = 80.62%\n",
      "Epoch 2814: Loss = 191.8178, Training Accuracy = 80.49%\n",
      "Epoch 2815: Loss = 191.4981, Training Accuracy = 80.69%\n",
      "Epoch 2816: Loss = 191.6645, Training Accuracy = 80.62%\n",
      "Epoch 2817: Loss = 191.4176, Training Accuracy = 80.72%\n",
      "Epoch 2818: Loss = 191.6018, Training Accuracy = 80.67%\n",
      "Epoch 2819: Loss = 191.3207, Training Accuracy = 80.71%\n",
      "Epoch 2820: Loss = 190.6379, Training Accuracy = 80.84%\n",
      "Epoch 2821: Loss = 190.0143, Training Accuracy = 80.90%\n",
      "Epoch 2822: Loss = 190.4920, Training Accuracy = 80.90%\n",
      "Epoch 2823: Loss = 190.5632, Training Accuracy = 80.87%\n",
      "Epoch 2824: Loss = 191.1820, Training Accuracy = 80.78%\n",
      "Epoch 2825: Loss = 191.0797, Training Accuracy = 80.78%\n",
      "Epoch 2826: Loss = 191.4410, Training Accuracy = 80.82%\n",
      "Epoch 2827: Loss = 191.4616, Training Accuracy = 80.80%\n",
      "Epoch 2828: Loss = 191.4232, Training Accuracy = 80.82%\n",
      "Epoch 2829: Loss = 191.0117, Training Accuracy = 80.81%\n",
      "Epoch 2830: Loss = 190.9412, Training Accuracy = 80.62%\n",
      "Epoch 2831: Loss = 190.7269, Training Accuracy = 80.91%\n",
      "Epoch 2832: Loss = 190.6298, Training Accuracy = 80.54%\n",
      "Epoch 2833: Loss = 190.7867, Training Accuracy = 80.69%\n",
      "Epoch 2834: Loss = 190.8041, Training Accuracy = 80.68%\n",
      "Epoch 2835: Loss = 190.2143, Training Accuracy = 80.77%\n",
      "Epoch 2836: Loss = 190.7570, Training Accuracy = 80.72%\n",
      "Epoch 2837: Loss = 190.8346, Training Accuracy = 80.72%\n",
      "Epoch 2838: Loss = 190.7293, Training Accuracy = 80.41%\n",
      "Epoch 2839: Loss = 190.7781, Training Accuracy = 80.73%\n",
      "Epoch 2840: Loss = 190.9560, Training Accuracy = 80.66%\n",
      "Epoch 2841: Loss = 191.2647, Training Accuracy = 80.73%\n",
      "Epoch 2842: Loss = 191.3541, Training Accuracy = 80.82%\n",
      "Epoch 2843: Loss = 191.5463, Training Accuracy = 80.74%\n",
      "Epoch 2844: Loss = 191.5524, Training Accuracy = 80.79%\n",
      "Epoch 2845: Loss = 191.7249, Training Accuracy = 80.77%\n",
      "Epoch 2846: Loss = 191.5563, Training Accuracy = 80.77%\n",
      "Epoch 2847: Loss = 191.4925, Training Accuracy = 80.89%\n",
      "Epoch 2848: Loss = 191.5193, Training Accuracy = 81.01%\n",
      "Epoch 2849: Loss = 191.5705, Training Accuracy = 80.94%\n",
      "Epoch 2850: Loss = 191.6528, Training Accuracy = 80.87%\n",
      "Epoch 2851: Loss = 191.2906, Training Accuracy = 80.76%\n",
      "Epoch 2852: Loss = 191.0792, Training Accuracy = 80.83%\n",
      "Epoch 2853: Loss = 191.1571, Training Accuracy = 80.99%\n",
      "Epoch 2854: Loss = 191.6436, Training Accuracy = 80.97%\n",
      "Epoch 2855: Loss = 191.4708, Training Accuracy = 80.90%\n",
      "Epoch 2856: Loss = 191.7194, Training Accuracy = 80.81%\n",
      "Epoch 2857: Loss = 191.2465, Training Accuracy = 80.88%\n",
      "Epoch 2858: Loss = 191.7565, Training Accuracy = 80.83%\n",
      "Epoch 2859: Loss = 191.6658, Training Accuracy = 80.72%\n",
      "Epoch 2860: Loss = 192.0146, Training Accuracy = 80.72%\n",
      "Epoch 2861: Loss = 191.9484, Training Accuracy = 80.66%\n",
      "Epoch 2862: Loss = 192.0022, Training Accuracy = 80.68%\n",
      "Epoch 2863: Loss = 191.6919, Training Accuracy = 80.78%\n",
      "Epoch 2864: Loss = 191.8969, Training Accuracy = 80.76%\n",
      "Epoch 2865: Loss = 191.8615, Training Accuracy = 80.83%\n",
      "Epoch 2866: Loss = 191.6314, Training Accuracy = 80.84%\n",
      "Epoch 2867: Loss = 191.5158, Training Accuracy = 80.78%\n",
      "Epoch 2868: Loss = 191.4387, Training Accuracy = 80.79%\n",
      "Epoch 2869: Loss = 191.2089, Training Accuracy = 80.84%\n",
      "Epoch 2870: Loss = 191.3550, Training Accuracy = 80.87%\n",
      "Epoch 2871: Loss = 191.2739, Training Accuracy = 80.87%\n",
      "Epoch 2872: Loss = 191.2686, Training Accuracy = 80.67%\n",
      "Epoch 2873: Loss = 191.6414, Training Accuracy = 80.66%\n",
      "Epoch 2874: Loss = 190.7412, Training Accuracy = 80.74%\n",
      "Epoch 2875: Loss = 192.0631, Training Accuracy = 80.68%\n",
      "Epoch 2876: Loss = 191.7501, Training Accuracy = 80.75%\n",
      "Epoch 2877: Loss = 191.3743, Training Accuracy = 80.75%\n",
      "Epoch 2878: Loss = 191.3253, Training Accuracy = 80.77%\n",
      "Epoch 2879: Loss = 191.2518, Training Accuracy = 80.81%\n",
      "Epoch 2880: Loss = 191.0339, Training Accuracy = 80.81%\n",
      "Epoch 2881: Loss = 191.0319, Training Accuracy = 80.79%\n",
      "Epoch 2882: Loss = 192.1055, Training Accuracy = 80.80%\n",
      "Epoch 2883: Loss = 192.4782, Training Accuracy = 80.67%\n",
      "Epoch 2884: Loss = 192.4869, Training Accuracy = 80.77%\n",
      "Epoch 2885: Loss = 192.2764, Training Accuracy = 80.56%\n",
      "Epoch 2886: Loss = 192.2399, Training Accuracy = 80.67%\n",
      "Epoch 2887: Loss = 192.8596, Training Accuracy = 80.50%\n",
      "Epoch 2888: Loss = 192.3272, Training Accuracy = 80.52%\n",
      "Epoch 2889: Loss = 192.0360, Training Accuracy = 80.94%\n",
      "Epoch 2890: Loss = 192.5494, Training Accuracy = 80.77%\n",
      "Epoch 2891: Loss = 192.5735, Training Accuracy = 80.74%\n",
      "Epoch 2892: Loss = 192.6090, Training Accuracy = 80.69%\n",
      "Epoch 2893: Loss = 192.6875, Training Accuracy = 80.74%\n",
      "Epoch 2894: Loss = 192.4021, Training Accuracy = 80.76%\n",
      "Epoch 2895: Loss = 192.1598, Training Accuracy = 81.06%\n",
      "Epoch 2896: Loss = 191.8609, Training Accuracy = 80.72%\n",
      "Epoch 2897: Loss = 192.1643, Training Accuracy = 80.88%\n",
      "Epoch 2898: Loss = 192.2452, Training Accuracy = 80.97%\n",
      "Epoch 2899: Loss = 192.2980, Training Accuracy = 81.02%\n",
      "Epoch 2900: Loss = 192.4423, Training Accuracy = 80.67%\n",
      "Epoch 2901: Loss = 192.7228, Training Accuracy = 80.71%\n",
      "Epoch 2902: Loss = 192.7431, Training Accuracy = 80.87%\n",
      "Epoch 2903: Loss = 192.9343, Training Accuracy = 80.86%\n",
      "Epoch 2904: Loss = 192.4113, Training Accuracy = 80.93%\n",
      "Epoch 2905: Loss = 192.1524, Training Accuracy = 80.91%\n",
      "Epoch 2906: Loss = 192.7804, Training Accuracy = 80.94%\n",
      "Epoch 2907: Loss = 193.1187, Training Accuracy = 80.77%\n",
      "Epoch 2908: Loss = 192.8856, Training Accuracy = 80.88%\n",
      "Epoch 2909: Loss = 192.6709, Training Accuracy = 80.75%\n",
      "Epoch 2910: Loss = 192.6597, Training Accuracy = 80.89%\n",
      "Epoch 2911: Loss = 192.4374, Training Accuracy = 80.94%\n",
      "Epoch 2912: Loss = 192.5837, Training Accuracy = 80.68%\n",
      "Epoch 2913: Loss = 193.0011, Training Accuracy = 80.68%\n",
      "Epoch 2914: Loss = 193.3337, Training Accuracy = 80.54%\n",
      "Epoch 2915: Loss = 192.9320, Training Accuracy = 80.90%\n",
      "Epoch 2916: Loss = 193.0150, Training Accuracy = 80.77%\n",
      "Epoch 2917: Loss = 193.4404, Training Accuracy = 80.80%\n",
      "Epoch 2918: Loss = 193.6329, Training Accuracy = 80.80%\n",
      "Epoch 2919: Loss = 193.3184, Training Accuracy = 80.92%\n",
      "Epoch 2920: Loss = 193.2764, Training Accuracy = 80.89%\n",
      "Epoch 2921: Loss = 193.1358, Training Accuracy = 80.85%\n",
      "Epoch 2922: Loss = 193.2937, Training Accuracy = 80.90%\n",
      "Epoch 2923: Loss = 193.6308, Training Accuracy = 80.38%\n",
      "Epoch 2924: Loss = 193.6788, Training Accuracy = 80.44%\n",
      "Epoch 2925: Loss = 193.8149, Training Accuracy = 80.47%\n",
      "Epoch 2926: Loss = 193.8212, Training Accuracy = 80.49%\n",
      "Epoch 2927: Loss = 193.4657, Training Accuracy = 80.62%\n",
      "Epoch 2928: Loss = 193.8954, Training Accuracy = 80.58%\n",
      "Epoch 2929: Loss = 193.3864, Training Accuracy = 80.68%\n",
      "Epoch 2930: Loss = 194.1503, Training Accuracy = 80.47%\n",
      "Epoch 2931: Loss = 193.5263, Training Accuracy = 80.62%\n",
      "Epoch 2932: Loss = 193.4501, Training Accuracy = 80.59%\n",
      "Epoch 2933: Loss = 192.8344, Training Accuracy = 80.60%\n",
      "Epoch 2934: Loss = 193.2384, Training Accuracy = 80.67%\n",
      "Epoch 2935: Loss = 193.0598, Training Accuracy = 80.55%\n",
      "Epoch 2936: Loss = 193.1348, Training Accuracy = 80.77%\n",
      "Epoch 2937: Loss = 193.2130, Training Accuracy = 80.54%\n",
      "Epoch 2938: Loss = 192.9161, Training Accuracy = 80.45%\n",
      "Epoch 2939: Loss = 193.1214, Training Accuracy = 80.60%\n",
      "Epoch 2940: Loss = 192.6599, Training Accuracy = 80.54%\n",
      "Epoch 2941: Loss = 192.3154, Training Accuracy = 80.58%\n",
      "Epoch 2942: Loss = 192.5273, Training Accuracy = 80.53%\n",
      "Epoch 2943: Loss = 192.0007, Training Accuracy = 80.61%\n",
      "Epoch 2944: Loss = 191.7346, Training Accuracy = 80.59%\n",
      "Epoch 2945: Loss = 192.3438, Training Accuracy = 80.54%\n",
      "Epoch 2946: Loss = 192.4245, Training Accuracy = 80.72%\n",
      "Epoch 2947: Loss = 192.4147, Training Accuracy = 80.39%\n",
      "Epoch 2948: Loss = 192.3958, Training Accuracy = 80.52%\n",
      "Epoch 2949: Loss = 192.5937, Training Accuracy = 80.60%\n",
      "Epoch 2950: Loss = 192.6582, Training Accuracy = 80.66%\n",
      "Epoch 2951: Loss = 192.5793, Training Accuracy = 80.71%\n",
      "Epoch 2952: Loss = 192.7869, Training Accuracy = 80.52%\n",
      "Epoch 2953: Loss = 193.0562, Training Accuracy = 80.49%\n",
      "Epoch 2954: Loss = 192.8797, Training Accuracy = 80.69%\n",
      "Epoch 2955: Loss = 192.9133, Training Accuracy = 80.72%\n",
      "Epoch 2956: Loss = 193.0938, Training Accuracy = 80.69%\n",
      "Epoch 2957: Loss = 192.3652, Training Accuracy = 80.73%\n",
      "Epoch 2958: Loss = 192.3523, Training Accuracy = 80.72%\n",
      "Epoch 2959: Loss = 192.4100, Training Accuracy = 80.59%\n",
      "Epoch 2960: Loss = 192.4637, Training Accuracy = 80.64%\n",
      "Epoch 2961: Loss = 192.3477, Training Accuracy = 80.84%\n",
      "Epoch 2962: Loss = 192.7326, Training Accuracy = 80.62%\n",
      "Epoch 2963: Loss = 192.2847, Training Accuracy = 80.77%\n",
      "Epoch 2964: Loss = 192.6094, Training Accuracy = 80.87%\n",
      "Epoch 2965: Loss = 192.9919, Training Accuracy = 80.86%\n",
      "Epoch 2966: Loss = 193.0161, Training Accuracy = 80.75%\n",
      "Epoch 2967: Loss = 192.7975, Training Accuracy = 80.78%\n",
      "Epoch 2968: Loss = 192.5261, Training Accuracy = 80.89%\n",
      "Epoch 2969: Loss = 192.8241, Training Accuracy = 80.84%\n",
      "Epoch 2970: Loss = 192.3964, Training Accuracy = 80.74%\n",
      "Epoch 2971: Loss = 192.6434, Training Accuracy = 80.56%\n",
      "Epoch 2972: Loss = 192.5064, Training Accuracy = 80.86%\n",
      "Epoch 2973: Loss = 192.7874, Training Accuracy = 80.80%\n",
      "Epoch 2974: Loss = 192.7861, Training Accuracy = 80.93%\n",
      "Epoch 2975: Loss = 192.8934, Training Accuracy = 80.93%\n",
      "Epoch 2976: Loss = 192.9338, Training Accuracy = 80.92%\n",
      "Epoch 2977: Loss = 192.1650, Training Accuracy = 81.00%\n",
      "Epoch 2978: Loss = 192.6185, Training Accuracy = 81.02%\n",
      "Epoch 2979: Loss = 192.7236, Training Accuracy = 80.95%\n",
      "Epoch 2980: Loss = 192.7717, Training Accuracy = 80.79%\n",
      "Epoch 2981: Loss = 192.9176, Training Accuracy = 80.77%\n",
      "Epoch 2982: Loss = 192.9585, Training Accuracy = 80.98%\n",
      "Epoch 2983: Loss = 192.5832, Training Accuracy = 80.98%\n",
      "Epoch 2984: Loss = 192.6857, Training Accuracy = 80.99%\n",
      "Epoch 2985: Loss = 193.1395, Training Accuracy = 80.92%\n",
      "Epoch 2986: Loss = 192.6638, Training Accuracy = 80.90%\n",
      "Epoch 2987: Loss = 193.0642, Training Accuracy = 80.81%\n",
      "Epoch 2988: Loss = 192.6002, Training Accuracy = 80.79%\n",
      "Epoch 2989: Loss = 192.4384, Training Accuracy = 80.84%\n",
      "Epoch 2990: Loss = 192.4550, Training Accuracy = 81.06%\n",
      "Epoch 2991: Loss = 192.5141, Training Accuracy = 81.05%\n",
      "Epoch 2992: Loss = 192.5877, Training Accuracy = 80.91%\n",
      "Epoch 2993: Loss = 192.3649, Training Accuracy = 81.04%\n",
      "Epoch 2994: Loss = 192.4156, Training Accuracy = 81.08%\n",
      "Epoch 2995: Loss = 192.6608, Training Accuracy = 81.02%\n",
      "Epoch 2996: Loss = 192.7466, Training Accuracy = 81.10%\n",
      "Epoch 2997: Loss = 192.7758, Training Accuracy = 81.15%\n",
      "Epoch 2998: Loss = 193.0171, Training Accuracy = 81.12%\n",
      "Epoch 2999: Loss = 193.0550, Training Accuracy = 81.03%\n",
      "Epoch 3000: Loss = 193.3239, Training Accuracy = 80.98%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Choose device: use MPS if available (Apple Silicon), else CPU.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Instantiate the model on the chosen device.\n",
    "model = MultiClassLogisticRegressionWrapper(input_dim=785, num_classes=10, device=device)\n",
    "\n",
    "# Import your EvolutionOptimizer from EVO.py (unchanged).\n",
    "from EVO import EvolutionOptimizer\n",
    "\n",
    "# Instantiate the evolutionary optimizer.\n",
    "optimizer = EvolutionOptimizer(model)\n",
    "optimizer.set_population_size(40)\n",
    "optimizer.set_mutation_rate(0.8)\n",
    "optimizer.set_mutation_intensity(1)\n",
    "\n",
    "# Ensure your expanded training data is on the same device.\n",
    "X_train_exp = X_train_exp.to(device)   # X_train_exp should have shape (N_train, 7850)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "num_epochs = 3000\n",
    "losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.step(X_train_exp, y_train)\n",
    "    \n",
    "    # Compute the current loss and accuracy on the training set.\n",
    "    loss_val = model.loss(X_train_exp, y_train).item()\n",
    "    losses.append(loss_val)\n",
    "    \n",
    "    preds = model.predict(X_train_exp)\n",
    "    acc = (preds == y_train).float().mean().item() * 100\n",
    "    train_accs.append(acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}: Loss = {loss_val:.4f}, Training Accuracy = {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ed8cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(323.9041, device='mps:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_pairwise_distance(population):\n",
    "    n = len(population)\n",
    "    total_dist = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dist = torch.norm(population[i] - population[j])\n",
    "            total_dist += dist\n",
    "            count += 1\n",
    "\n",
    "    return total_dist / count if count > 0 else 0\n",
    "\n",
    "average_pairwise_distance(optimizer.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a455847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy on Training Set: 81.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# List to collect predictions from every candidate in the population.\n",
    "pop_predictions = []\n",
    "\n",
    "# Loop over each candidate weight vector in the optimizer's population.\n",
    "for candidate in optimizer.population:\n",
    "    # Compute scores using the candidate weight vector.\n",
    "    scores = model.score_with(X_train_exp, candidate)\n",
    "    # Obtain predictions (class indices, 0 to 9) by taking the argmax.\n",
    "    preds = torch.argmax(scores, dim=1)  # shape: (N_train,)\n",
    "    pop_predictions.append(preds.unsqueeze(0))  # add a new dimension for stacking\n",
    "\n",
    "# Stack predictions to form a tensor of shape (pop_size, N_train)\n",
    "pop_preds_tensor = torch.cat(pop_predictions, dim=0)\n",
    "\n",
    "# Compute the mode on the CPU as a fallback.\n",
    "majority_preds, _ = torch.mode(pop_preds_tensor.cpu(), dim=0)\n",
    "\n",
    "# Move the majority predictions back to the device (optional).\n",
    "majority_preds = majority_preds.to(X_train_exp.device)\n",
    "\n",
    "# Compute majority vote accuracy.\n",
    "majority_vote_accuracy = (majority_preds == y_train).float().mean().item() * 100\n",
    "print(f\"Majority Vote Accuracy on Training Set: {majority_vote_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18f3897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_majority_vote_accuracy(model, X, y):\n",
    "    \"\"\"\n",
    "    For each sample, collect predictions from all individuals in the population,\n",
    "    take the majority vote, and compare to ground truth labels.\n",
    "    \"\"\"\n",
    "    n = X.size(0)\n",
    "    votes = torch.zeros((len(model.population), n))\n",
    "\n",
    "    for i, w in enumerate(model.population):\n",
    "        logits = X @ w\n",
    "        preds = (logits > 0).float()\n",
    "        votes[i] = preds\n",
    "\n",
    "    # Sum over voters and apply majority rule (>50%)\n",
    "    majority_preds = (votes.mean(dim=0) > 0.5).float()\n",
    "    accuracy = (majority_preds == y).float().mean().item() * 100\n",
    "    return accuracy\n",
    "\n",
    "def average_pairwise_distance(population):\n",
    "    n = len(population)\n",
    "    total_dist = 0\n",
    "    count = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dist = torch.norm(population[i] - population[j])\n",
    "            total_dist += dist\n",
    "            count += 1\n",
    "\n",
    "    return total_dist / count if count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 14.3147 | Best Acc: 9.84% | Majority Vote Acc: 9.84%\n",
      "Epoch 02 - Loss: 14.2409 | Best Acc: 9.84% | Majority Vote Acc: 9.84%\n",
      "Epoch 03 - Loss: 14.2358 | Best Acc: 9.84% | Majority Vote Acc: 9.84%\n",
      "Epoch 04 - Loss: 14.1415 | Best Acc: 9.84% | Majority Vote Acc: 9.84%\n",
      "Epoch 05 - Loss: 13.9552 | Best Acc: 9.93% | Majority Vote Acc: 9.84%\n",
      "Epoch 06 - Loss: 13.8366 | Best Acc: 10.11% | Majority Vote Acc: 9.84%\n",
      "Epoch 07 - Loss: 13.7735 | Best Acc: 10.14% | Majority Vote Acc: 9.84%\n",
      "Epoch 08 - Loss: 13.6082 | Best Acc: 10.20% | Majority Vote Acc: 9.84%\n",
      "Epoch 09 - Loss: 13.0851 | Best Acc: 13.85% | Majority Vote Acc: 9.84%\n",
      "Epoch 10 - Loss: 12.8729 | Best Acc: 14.77% | Majority Vote Acc: 9.86%\n",
      "Epoch 11 - Loss: 12.6154 | Best Acc: 15.81% | Majority Vote Acc: 10.68%\n",
      "Epoch 12 - Loss: 12.1688 | Best Acc: 18.75% | Majority Vote Acc: 13.15%\n",
      "Epoch 13 - Loss: 11.9527 | Best Acc: 19.26% | Majority Vote Acc: 15.37%\n",
      "Epoch 14 - Loss: 11.4085 | Best Acc: 21.15% | Majority Vote Acc: 16.84%\n",
      "Epoch 15 - Loss: 11.0993 | Best Acc: 21.52% | Majority Vote Acc: 18.15%\n",
      "Epoch 16 - Loss: 10.2693 | Best Acc: 24.96% | Majority Vote Acc: 19.28%\n",
      "Epoch 17 - Loss: 9.0804 | Best Acc: 29.67% | Majority Vote Acc: 21.26%\n",
      "Epoch 18 - Loss: 8.6923 | Best Acc: 29.14% | Majority Vote Acc: 23.12%\n",
      "Epoch 19 - Loss: 7.3135 | Best Acc: 37.61% | Majority Vote Acc: 25.14%\n",
      "Epoch 20 - Loss: 6.0997 | Best Acc: 45.01% | Majority Vote Acc: 29.24%\n",
      "Epoch 21 - Loss: 4.8238 | Best Acc: 54.62% | Majority Vote Acc: 35.01%\n",
      "Epoch 22 - Loss: 4.4354 | Best Acc: 57.28% | Majority Vote Acc: 39.85%\n",
      "Epoch 23 - Loss: 3.7486 | Best Acc: 61.99% | Majority Vote Acc: 45.35%\n",
      "Epoch 24 - Loss: 2.4157 | Best Acc: 70.78% | Majority Vote Acc: 52.81%\n",
      "Epoch 25 - Loss: 1.7256 | Best Acc: 78.00% | Majority Vote Acc: 61.14%\n",
      "Epoch 26 - Loss: 0.8951 | Best Acc: 87.70% | Majority Vote Acc: 69.84%\n",
      "Epoch 27 - Loss: 1.1028 | Best Acc: 87.42% | Majority Vote Acc: 75.61%\n",
      "Epoch 28 - Loss: 0.9339 | Best Acc: 89.79% | Majority Vote Acc: 80.89%\n",
      "Epoch 29 - Loss: 0.7641 | Best Acc: 90.80% | Majority Vote Acc: 85.22%\n",
      "Epoch 30 - Loss: 0.8111 | Best Acc: 89.32% | Majority Vote Acc: 87.52%\n",
      "Epoch 31 - Loss: 0.7421 | Best Acc: 91.18% | Majority Vote Acc: 89.71%\n",
      "Epoch 32 - Loss: 0.6215 | Best Acc: 91.33% | Majority Vote Acc: 90.48%\n",
      "Epoch 33 - Loss: 0.6074 | Best Acc: 91.73% | Majority Vote Acc: 91.57%\n",
      "Epoch 34 - Loss: 0.5332 | Best Acc: 92.56% | Majority Vote Acc: 91.68%\n",
      "Epoch 35 - Loss: 0.6154 | Best Acc: 92.12% | Majority Vote Acc: 92.32%\n",
      "Epoch 36 - Loss: 0.5677 | Best Acc: 93.31% | Majority Vote Acc: 92.88%\n",
      "Epoch 37 - Loss: 0.5271 | Best Acc: 93.10% | Majority Vote Acc: 93.33%\n",
      "Epoch 38 - Loss: 0.4971 | Best Acc: 93.94% | Majority Vote Acc: 93.81%\n",
      "Epoch 39 - Loss: 0.4921 | Best Acc: 94.08% | Majority Vote Acc: 94.08%\n",
      "Epoch 40 - Loss: 0.4694 | Best Acc: 94.30% | Majority Vote Acc: 94.29%\n",
      "Epoch 41 - Loss: 0.4292 | Best Acc: 94.91% | Majority Vote Acc: 94.72%\n",
      "Epoch 42 - Loss: 0.4035 | Best Acc: 94.98% | Majority Vote Acc: 94.93%\n",
      "Epoch 43 - Loss: 0.3926 | Best Acc: 94.85% | Majority Vote Acc: 95.17%\n",
      "Epoch 44 - Loss: 0.4139 | Best Acc: 94.92% | Majority Vote Acc: 95.35%\n",
      "Epoch 45 - Loss: 0.3804 | Best Acc: 94.96% | Majority Vote Acc: 95.42%\n",
      "Epoch 46 - Loss: 0.3082 | Best Acc: 96.24% | Majority Vote Acc: 95.66%\n",
      "Epoch 47 - Loss: 0.3095 | Best Acc: 96.34% | Majority Vote Acc: 95.85%\n",
      "Epoch 48 - Loss: 0.2829 | Best Acc: 96.17% | Majority Vote Acc: 96.31%\n",
      "Epoch 49 - Loss: 0.2551 | Best Acc: 96.53% | Majority Vote Acc: 96.60%\n",
      "Epoch 50 - Loss: 0.2727 | Best Acc: 96.85% | Majority Vote Acc: 96.63%\n",
      "Epoch 51 - Loss: 0.2368 | Best Acc: 96.79% | Majority Vote Acc: 96.76%\n",
      "Epoch 52 - Loss: 0.2374 | Best Acc: 96.35% | Majority Vote Acc: 96.94%\n",
      "Epoch 53 - Loss: 0.2446 | Best Acc: 96.70% | Majority Vote Acc: 97.03%\n",
      "Epoch 54 - Loss: 0.2375 | Best Acc: 96.38% | Majority Vote Acc: 97.06%\n",
      "Epoch 55 - Loss: 0.2081 | Best Acc: 97.11% | Majority Vote Acc: 97.08%\n",
      "Epoch 56 - Loss: 0.2334 | Best Acc: 97.03% | Majority Vote Acc: 97.18%\n",
      "Epoch 57 - Loss: 0.2142 | Best Acc: 97.15% | Majority Vote Acc: 97.20%\n",
      "Epoch 58 - Loss: 0.2239 | Best Acc: 96.31% | Majority Vote Acc: 97.24%\n",
      "Epoch 59 - Loss: 0.2237 | Best Acc: 97.01% | Majority Vote Acc: 97.30%\n",
      "Epoch 60 - Loss: 0.2099 | Best Acc: 96.86% | Majority Vote Acc: 97.28%\n",
      "Epoch 61 - Loss: 0.1931 | Best Acc: 97.38% | Majority Vote Acc: 97.45%\n",
      "Epoch 62 - Loss: 0.1965 | Best Acc: 97.24% | Majority Vote Acc: 97.49%\n",
      "Epoch 63 - Loss: 0.1799 | Best Acc: 97.39% | Majority Vote Acc: 97.54%\n",
      "Epoch 64 - Loss: 0.1898 | Best Acc: 97.43% | Majority Vote Acc: 97.64%\n",
      "Epoch 65 - Loss: 0.1779 | Best Acc: 97.37% | Majority Vote Acc: 97.69%\n",
      "Epoch 66 - Loss: 0.1907 | Best Acc: 97.44% | Majority Vote Acc: 97.74%\n",
      "Epoch 67 - Loss: 0.1830 | Best Acc: 97.54% | Majority Vote Acc: 97.78%\n",
      "Epoch 68 - Loss: 0.1716 | Best Acc: 97.40% | Majority Vote Acc: 97.82%\n",
      "Epoch 69 - Loss: 0.1529 | Best Acc: 97.62% | Majority Vote Acc: 97.86%\n",
      "Epoch 70 - Loss: 0.1609 | Best Acc: 97.69% | Majority Vote Acc: 97.79%\n",
      "Epoch 71 - Loss: 0.1684 | Best Acc: 97.56% | Majority Vote Acc: 97.81%\n",
      "Epoch 72 - Loss: 0.1700 | Best Acc: 97.68% | Majority Vote Acc: 97.85%\n",
      "Epoch 73 - Loss: 0.1643 | Best Acc: 97.47% | Majority Vote Acc: 97.97%\n",
      "Epoch 74 - Loss: 0.1661 | Best Acc: 97.54% | Majority Vote Acc: 98.01%\n",
      "Epoch 75 - Loss: 0.1602 | Best Acc: 97.70% | Majority Vote Acc: 97.99%\n",
      "Epoch 76 - Loss: 0.1622 | Best Acc: 97.52% | Majority Vote Acc: 98.06%\n",
      "Epoch 77 - Loss: 0.1558 | Best Acc: 98.00% | Majority Vote Acc: 98.12%\n",
      "Epoch 78 - Loss: 0.1541 | Best Acc: 97.95% | Majority Vote Acc: 98.08%\n",
      "Epoch 79 - Loss: 0.1557 | Best Acc: 97.76% | Majority Vote Acc: 98.07%\n",
      "Epoch 80 - Loss: 0.1508 | Best Acc: 97.86% | Majority Vote Acc: 98.13%\n",
      "Epoch 81 - Loss: 0.1376 | Best Acc: 98.04% | Majority Vote Acc: 98.17%\n",
      "Epoch 82 - Loss: 0.1507 | Best Acc: 97.93% | Majority Vote Acc: 98.17%\n",
      "Epoch 83 - Loss: 0.1494 | Best Acc: 98.03% | Majority Vote Acc: 98.17%\n",
      "Epoch 84 - Loss: 0.1518 | Best Acc: 97.89% | Majority Vote Acc: 98.18%\n",
      "Epoch 85 - Loss: 0.1442 | Best Acc: 98.16% | Majority Vote Acc: 98.19%\n",
      "Epoch 86 - Loss: 0.1533 | Best Acc: 97.88% | Majority Vote Acc: 98.13%\n",
      "Epoch 87 - Loss: 0.1512 | Best Acc: 97.84% | Majority Vote Acc: 98.19%\n",
      "Epoch 88 - Loss: 0.1420 | Best Acc: 98.04% | Majority Vote Acc: 98.25%\n",
      "Epoch 89 - Loss: 0.1382 | Best Acc: 98.17% | Majority Vote Acc: 98.24%\n",
      "Epoch 90 - Loss: 0.1409 | Best Acc: 98.11% | Majority Vote Acc: 98.26%\n",
      "Epoch 91 - Loss: 0.1370 | Best Acc: 98.08% | Majority Vote Acc: 98.25%\n",
      "Epoch 92 - Loss: 0.1335 | Best Acc: 98.09% | Majority Vote Acc: 98.33%\n",
      "Epoch 93 - Loss: 0.1300 | Best Acc: 98.26% | Majority Vote Acc: 98.38%\n",
      "Epoch 94 - Loss: 0.1280 | Best Acc: 98.36% | Majority Vote Acc: 98.37%\n",
      "Epoch 95 - Loss: 0.1261 | Best Acc: 98.40% | Majority Vote Acc: 98.33%\n",
      "Epoch 96 - Loss: 0.1314 | Best Acc: 98.42% | Majority Vote Acc: 98.35%\n",
      "Epoch 97 - Loss: 0.1346 | Best Acc: 98.34% | Majority Vote Acc: 98.42%\n",
      "Epoch 98 - Loss: 0.1360 | Best Acc: 98.27% | Majority Vote Acc: 98.41%\n",
      "Epoch 99 - Loss: 0.1327 | Best Acc: 98.18% | Majority Vote Acc: 98.41%\n",
      "Epoch 100 - Loss: 0.1296 | Best Acc: 98.27% | Majority Vote Acc: 98.42%\n",
      "Epoch 101 - Loss: 0.1298 | Best Acc: 98.30% | Majority Vote Acc: 98.43%\n",
      "Epoch 102 - Loss: 0.1313 | Best Acc: 98.32% | Majority Vote Acc: 98.45%\n",
      "Epoch 103 - Loss: 0.1280 | Best Acc: 98.30% | Majority Vote Acc: 98.42%\n",
      "Epoch 104 - Loss: 0.1266 | Best Acc: 98.36% | Majority Vote Acc: 98.45%\n",
      "Epoch 105 - Loss: 0.1285 | Best Acc: 98.40% | Majority Vote Acc: 98.46%\n",
      "Epoch 106 - Loss: 0.1223 | Best Acc: 98.32% | Majority Vote Acc: 98.49%\n",
      "Epoch 107 - Loss: 0.1258 | Best Acc: 98.36% | Majority Vote Acc: 98.51%\n",
      "Epoch 108 - Loss: 0.1243 | Best Acc: 98.27% | Majority Vote Acc: 98.53%\n",
      "Epoch 109 - Loss: 0.1229 | Best Acc: 98.34% | Majority Vote Acc: 98.51%\n",
      "Epoch 110 - Loss: 0.1228 | Best Acc: 98.48% | Majority Vote Acc: 98.56%\n",
      "Epoch 111 - Loss: 0.1238 | Best Acc: 98.30% | Majority Vote Acc: 98.54%\n",
      "Epoch 112 - Loss: 0.1256 | Best Acc: 98.22% | Majority Vote Acc: 98.54%\n",
      "Epoch 113 - Loss: 0.1243 | Best Acc: 98.39% | Majority Vote Acc: 98.53%\n",
      "Epoch 114 - Loss: 0.1189 | Best Acc: 98.39% | Majority Vote Acc: 98.56%\n",
      "Epoch 115 - Loss: 0.1201 | Best Acc: 98.39% | Majority Vote Acc: 98.57%\n",
      "Epoch 116 - Loss: 0.1182 | Best Acc: 98.48% | Majority Vote Acc: 98.59%\n",
      "Epoch 117 - Loss: 0.1189 | Best Acc: 98.45% | Majority Vote Acc: 98.59%\n",
      "Epoch 118 - Loss: 0.1166 | Best Acc: 98.60% | Majority Vote Acc: 98.60%\n",
      "Epoch 119 - Loss: 0.1142 | Best Acc: 98.44% | Majority Vote Acc: 98.63%\n",
      "Epoch 120 - Loss: 0.1182 | Best Acc: 98.58% | Majority Vote Acc: 98.63%\n",
      "Epoch 121 - Loss: 0.1163 | Best Acc: 98.58% | Majority Vote Acc: 98.61%\n",
      "Epoch 122 - Loss: 0.1201 | Best Acc: 98.55% | Majority Vote Acc: 98.64%\n",
      "Epoch 123 - Loss: 0.1190 | Best Acc: 98.51% | Majority Vote Acc: 98.65%\n",
      "Epoch 124 - Loss: 0.1140 | Best Acc: 98.59% | Majority Vote Acc: 98.65%\n",
      "Epoch 125 - Loss: 0.1138 | Best Acc: 98.45% | Majority Vote Acc: 98.65%\n",
      "Epoch 126 - Loss: 0.1204 | Best Acc: 98.38% | Majority Vote Acc: 98.66%\n",
      "Epoch 127 - Loss: 0.1175 | Best Acc: 98.62% | Majority Vote Acc: 98.66%\n",
      "Epoch 128 - Loss: 0.1152 | Best Acc: 98.56% | Majority Vote Acc: 98.65%\n",
      "Epoch 129 - Loss: 0.1150 | Best Acc: 98.57% | Majority Vote Acc: 98.66%\n",
      "Epoch 130 - Loss: 0.1170 | Best Acc: 98.47% | Majority Vote Acc: 98.66%\n",
      "Epoch 131 - Loss: 0.1155 | Best Acc: 98.55% | Majority Vote Acc: 98.67%\n",
      "Epoch 132 - Loss: 0.1140 | Best Acc: 98.59% | Majority Vote Acc: 98.67%\n",
      "Epoch 133 - Loss: 0.1142 | Best Acc: 98.58% | Majority Vote Acc: 98.69%\n",
      "Epoch 134 - Loss: 0.1108 | Best Acc: 98.62% | Majority Vote Acc: 98.68%\n",
      "Epoch 135 - Loss: 0.1123 | Best Acc: 98.58% | Majority Vote Acc: 98.65%\n",
      "Epoch 136 - Loss: 0.1047 | Best Acc: 98.62% | Majority Vote Acc: 98.67%\n",
      "Epoch 137 - Loss: 0.1122 | Best Acc: 98.50% | Majority Vote Acc: 98.72%\n",
      "Epoch 138 - Loss: 0.1108 | Best Acc: 98.40% | Majority Vote Acc: 98.71%\n",
      "Epoch 139 - Loss: 0.1112 | Best Acc: 98.44% | Majority Vote Acc: 98.71%\n",
      "Epoch 140 - Loss: 0.1103 | Best Acc: 98.50% | Majority Vote Acc: 98.70%\n",
      "Epoch 141 - Loss: 0.1092 | Best Acc: 98.49% | Majority Vote Acc: 98.65%\n",
      "Epoch 142 - Loss: 0.1064 | Best Acc: 98.65% | Majority Vote Acc: 98.63%\n",
      "Epoch 143 - Loss: 0.1117 | Best Acc: 98.43% | Majority Vote Acc: 98.64%\n",
      "Epoch 144 - Loss: 0.1127 | Best Acc: 98.43% | Majority Vote Acc: 98.66%\n",
      "Epoch 145 - Loss: 0.1135 | Best Acc: 98.53% | Majority Vote Acc: 98.73%\n",
      "Epoch 146 - Loss: 0.1090 | Best Acc: 98.59% | Majority Vote Acc: 98.72%\n",
      "Epoch 147 - Loss: 0.1056 | Best Acc: 98.62% | Majority Vote Acc: 98.73%\n",
      "Epoch 148 - Loss: 0.1070 | Best Acc: 98.57% | Majority Vote Acc: 98.74%\n",
      "Epoch 149 - Loss: 0.1011 | Best Acc: 98.62% | Majority Vote Acc: 98.73%\n",
      "Epoch 150 - Loss: 0.1039 | Best Acc: 98.58% | Majority Vote Acc: 98.76%\n"
     ]
    }
   ],
   "source": [
    "# --- Train with Evolutionary Optimizer ---\n",
    "model = LogisticRegression()\n",
    "optimizer = EvolutionOptimizer(model)\n",
    "optimizer.set_population_size(50)\n",
    "optimizer.set_mutation_rate(0.01)\n",
    "optimizer.set_mutation_intensity(2)\n",
    "\n",
    "best_accs = []\n",
    "majority_accs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(150):\n",
    "    optimizer.step(X_train, y_train)\n",
    "\n",
    "    # Accuracy from best model (model.w)\n",
    "    y_hat_best = model.predict(X_train)\n",
    "    acc_best = (y_hat_best == y_train).float().mean().item() * 100\n",
    "\n",
    "    # Accuracy from majority vote\n",
    "    acc_majority = population_majority_vote_accuracy(model, X_train, y_train)\n",
    "\n",
    "    # Loss of best model\n",
    "    current_loss = model.loss(X_train, y_train).item()\n",
    "\n",
    "    # Store values\n",
    "    best_accs.append(acc_best)\n",
    "    majority_accs.append(acc_majority)\n",
    "    losses.append(current_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} - Loss: {current_loss:.4f} | Best Acc: {acc_best:.2f}% | Majority Vote Acc: {acc_majority:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb8e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity: 0.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiversity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiversity\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Accuracy of the best individual model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_pred_best \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_val\u001b[49m)\n\u001b[1;32m      6\u001b[0m acc_best \u001b[38;5;241m=\u001b[39m (y_pred_best \u001b[38;5;241m==\u001b[39m y_val)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Accuracy of the ensemble via majority vote\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "diversity = average_pairwise_distance(model.population)\n",
    "print(f\"Diversity: {diversity:.4f}\")\n",
    "\n",
    "# Accuracy of the best individual model\n",
    "y_pred_best = model.predict(X_val)\n",
    "acc_best = (y_pred_best == y_val).float().mean().item() * 100\n",
    "\n",
    "# Accuracy of the ensemble via majority vote\n",
    "acc_majority = population_majority_vote_accuracy(model, X_val, y_val)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Validation Accuracy - Best Model: {acc_best:.2f}%\")\n",
    "print(f\"Validation Accuracy - Majority Vote: {acc_majority:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fde9c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_diverse_pair(population):\n",
    "    max_dist = -1\n",
    "    pair = (None, None)\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        for j in range(i+1, len(population)):\n",
    "            dist = torch.norm(population[i] - population[j])\n",
    "            if dist > max_dist:\n",
    "                max_dist = dist\n",
    "                pair = (population[i], population[j])\n",
    "    \n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a1c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions_on_random_samples(X_val, y_val, original_images, individual_A, individual_B, n=10):\n",
    "    indices = random.sample(range(X_val.size(0)), n)\n",
    "\n",
    "    fig, axs = plt.subplots(n, 3, figsize=(8, n * 2))\n",
    "    fig.suptitle(\"Most Diverse Individuals: Predictions\", fontsize=16)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        x = X_val[idx].unsqueeze(0)  # shape (1, 785)\n",
    "        img = original_images[idx].view(28, 28)\n",
    "\n",
    "        # Predict with both individuals\n",
    "        pred_A = (x @ individual_A > 0).float().item()\n",
    "        pred_B = (x @ individual_B > 0).float().item()\n",
    "        true_label = int(y_val[idx].item())\n",
    "\n",
    "        axs[i, 0].imshow(img, cmap='gray')\n",
    "        axs[i, 0].axis('off')\n",
    "        axs[i, 0].set_title(f\"Label: {true_label}\")\n",
    "\n",
    "        axs[i, 1].text(0.5, 0.5, f\"{int(pred_A)}\", fontsize=16, ha='center')\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 1].set_title(\"Indiv A\")\n",
    "\n",
    "        axs[i, 2].text(0.5, 0.5, f\"{int(pred_B)}\", fontsize=16, ha='center')\n",
    "        axs[i, 2].axis('off')\n",
    "        axs[i, 2].set_title(\"Indiv B\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4703db6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected mat.is_mps() to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m original_val_images \u001b[38;5;241m=\u001b[39m X_test[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# remove bias term for visualization\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mvisualize_predictions_on_random_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_val_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindiv_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindiv_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m, in \u001b[0;36mvisualize_predictions_on_random_samples\u001b[0;34m(X_val, y_val, original_images, individual_A, individual_B, n)\u001b[0m\n\u001b[1;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m original_images[idx]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Predict with both individuals\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m pred_A \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindividual_A\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m pred_B \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m@\u001b[39m individual_B \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m true_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y_val[idx]\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected mat.is_mps() to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x2000 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indiv_A, indiv_B = find_most_diverse_pair(optimizer.population)\n",
    "original_val_images = X_test[:, :-1]  # remove bias term for visualization\n",
    "import random\n",
    "\n",
    "visualize_predictions_on_random_samples(X_test_exp, y_test, original_val_images, indiv_A, indiv_B, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5587769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = X_train[0]  # Get the first image\n",
    "plt.imshow(img[:-1].view(28, 28), cmap='gray')  # Exclude the bias term (last column)\n",
    "plt.title(f\"Label: {y_train[0].item()}\")  # Show the corresponding label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b075615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
