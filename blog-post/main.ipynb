{
 "cells": [
  {
   "cell_type": "raw",
   "id": "07689bb5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Evolution Based Weight Vector Optimization\n",
    "author: James Cummings, Jiffy Lesica, Yahya Rahhawi, Lukka Wolff\n",
    "date: '2025-19-05'\n",
    "image: \"image.jpg\"\n",
    "description: \"Implementation of Evolution Based Weight Vector Optimization\"\n",
    "bibliography: refs.bib\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b96871",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c536edd",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This blog post explores how features of evolution in nature can inspire solutions to overcoming the shortcomings of gradient descent. Gradient Descent only works on differentiable loss functions, meaning it can become stuck in local loss minima when attempting to model non-convex loss functions. In other words, gradient descent cannot explore the entire solution space on nondifferentiable loss functions. This limitation can be overcome by harnessing the characteristics of evolution and natural selection in nature. Evolution has a wide variety of applications concerning Machine Learning, but this project focuses on its applications to weight vector optimization @Talikani2021evolutionary.\n",
    "\n",
    "\n",
    "Lewontin identifies 3 key population characteristics for evolution: phenotypic variation in a population, differential fitness, and fitness must be heritable @Lewontin1970units. With these 3 characteristics, evolution then occurs as ‘fitter’ individuals are better able to pass on their traits to future generations, while less fit individuals are not. At the individual level, evolution requires a blueprint, self-replication, mutation, and selection. By applying these principles to machine learning models, this blog post explores the strengths and limitations of evolutionary principles when applied to weight vector optimization in machine learning. To satisfy the requirement of phenotypic variation, each evolutionary optimizer has an entire population of weight vectors storing different weights. The different weights result in different losses, which in combination with selection pressures regarding the resulting different losses, satisfy the differential fitness requirement. With weight vectors serving as our genetic blueprint, those weight vectors can be duplicated to create or refill the population of weight vectors. Slight random adjustments to those weight vectors during replication serve as the mutations, ensuring the continuation of phenotypic variation. A variety of methods can be used to eliminate population vectors during an iteration, including loss and diversity, which function as selection. Eliminating high-loss weight vectors allows only vectors with high accuracy to pass on their characteristics, while eliminating low diversity can ensure that the solution space is adequately explored. Through the implementation of hyperparameters, many variations of evolutionary machine learning algorithms are explored to better understand their strengths and weaknesses.\n",
    "\n",
    "\n",
    "The many hyperparameters are then tested on both generated and real data from the MNIST dataset to develop initial hypotheses regarding the optimal parameterization for evolutionary weight vector optimization to succeed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71563c",
   "metadata": {},
   "source": [
    "# Values Statement\n",
    "\n",
    "The potential users of the evolutionary-based weight vector optimization class are researchers, data scientists, and developers, especially those who work on non-differentiable problems with which gradient descent-based solutions struggle. Our class provides both a potential solution to overcoming the limitations of gradient descent on non-differentiable classification problems and serves as a potential benchmark against which other algorithms can be compared. \n",
    "\n",
    "\n",
    "One major potential impact of the widespread use of our algorithm, or similar ones, is the increase in computational power required to run them. Because each epoch of an evolutionary algorithm requires the computation of an entire population of new weight vectors, the computational power required for an epoch is higher than most algorithms. This has potential positive implications for the manufacturers of computational chips and the owners of servers. On the other hand, the potential negative effects of increased energy and material consumption to perform these computations cannot be overlooked either. \n",
    "\n",
    "\n",
    "Because the majority of our work was focused on the creation of a class, and not the optimization of a specific algorithm, the potential for positive and negative impacts of our class depends on who gains access to the class and what they decide to do with it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39b496",
   "metadata": {},
   "source": [
    "# Materials and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb76753",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f66bc",
   "metadata": {},
   "source": [
    "### Proof of concept/vanilla evolution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49edadd",
   "metadata": {},
   "source": [
    "### Selection/Elitism/Sneakers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d728a",
   "metadata": {},
   "source": [
    "### Inheritance and Parent Quantity:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c63324",
   "metadata": {},
   "source": [
    "At each iteration of our evolutionary optimization, following the creation of a ‘gene pool’ in the selection stage, the population must be replenished with new individuals. There are three ways that this can be accomplished. 1: All new individuals are new randomized weight vectors with no input from the gene pool. 2: Each new individual has a single parent randomly selected from the gene pool, from which its weights are inherited with random mutations. \n",
    "\n",
    "<img src=\"images/Multi-Parent/Single_Parent_Inheritance.png\" width=\"400\" style=\"display:block; margin:auto;\" />\n",
    "\n",
    "\n",
    "3: Each individual has n parents randomly selected from the gene pool. Each feature weight is then inherited from the corresponding feature weight of a random one of its parents. \n",
    "\n",
    "<img src=\"images/Multi-Parent/Multi-parent_Inheritance.png\" width=\"400\" style=\"display:block; margin:auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2acc1",
   "metadata": {},
   "source": [
    "As discussed in the results section, the choice of the number of parents can have sa significant impact on loss, accuracy, and diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480a0a4",
   "metadata": {},
   "source": [
    "### Hybridizing evolution with gradient descent:\n",
    "\n",
    "Our approach to evolutionary optimization incorporates a gradient-based refinement step that allows individuals to local optimize their performance (slightly) after being created. In essence, this hybrid evolutionary-gradient approach combines the global search strengths of evolutionary algorithms with the precise, local updates enabled by backpropagation. For each new individual generated during the evolutionary step, we apply a single gradient update to refine its weights. This is accomplished using a method implemented within the model that performs a forward pass, calculates cross-entropy, and uses PyTorch’s automatic differentiation to compute gradients. Weights are then updated according to the direction of the negative gradient, and scaled by a learning rate set to 0.5.\n",
    "\n",
    "The backpropagation step is called once per individual in the evolutionary loop, immediately after crossover and mutation have produced a new weight vector candidate. The updated individual is then re-inserted into the population. By integrating this light update of gradient descent, the optimizer benefits from enhancing convergence rates - while still being able to prioritize diversity - with fewer generations of evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b3936",
   "metadata": {},
   "source": [
    "### Computing Diversity and Diversity-Based Loss:\n",
    "\n",
    "Our evolutionary optimization implementation includes a mechanism for encouraging population diversity by directly incorporating a diversity term into the model’s loss function. Diversity is measured over the entire population of weight vectors, with four distinct methods implemented to quantify it. These include Euclidean distance, cosine dissimilarity, standard deviation, and variance. The Euclidean distance metric calculates the mean spatial difference between every pair of individuals in the population. Cosine dissimilarity measures the angular dissimilarity of weight vectors by computing one mines the cosine similarity between weight vectors. The standard deviation and variance metrics, on the other hand, operate across the whole population of weight vectors by computing the average distribution/variance of all weight vectors within a generation.\n",
    "\n",
    "Once computed, the diversity score is used to modify the model’s loss. Specifically, during each evaluation of an individual weight vector in the population, the standard cross-entropy loss is calculated and then a diversity term is subtracted from it. This diversity term equals the above mentioned diversity value scaled by a user-set diversity coefficient. The effect of this subtraction is that models with higher diversity scores receive a lower total loss, incentivizing the optimizer to explore a broader range of solutions. This diversity-aware loss is only applied when explicitly enabled through a boolean flag in the model, giving flexibility for experiments that compare/evaluate the performance of diversity-based and non-diversity based evolutionary optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffc1f4",
   "metadata": {},
   "source": [
    "### Adjustment from binary to multi-class classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293aeddc",
   "metadata": {},
   "source": [
    "Because our target task is classification on the MNIST dataset - which involves 10 possible output classes (digits 0 through 9), we implemented multiclass classification using Pytorch’s CrossEntropyLoss function. Unlike binary cross-entropy, which assumes a binary classification problem and compares scalar outputs to binary labels, cross-entropy loss compares a vector of probabilities (logits) against a single target value label. This function internally applies a softmax operation which evaluates the likelihood of each logit being the right output class.\n",
    "\n",
    "In our implementation, the CrossEntropyLoss function is used in both the model’s forward loss evaluation and backpropagation step. This ensures that each prediction is treated as a multiclass decision and that the model can properly learn to distinguish between all 10 classes in the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb03f69",
   "metadata": {},
   "source": [
    "### Mutation Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a59802",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb09b3",
   "metadata": {},
   "source": [
    "### Proof of concept/vanilla evolution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b906f",
   "metadata": {},
   "source": [
    "### Selection/Elitism/Sneakers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a79b2",
   "metadata": {},
   "source": [
    "### Inheritance and Parent Quantity:\n",
    "\n",
    "##### Generated Data Experiment:\n",
    "\n",
    "As a proof of concept, a multi parent classification experiment was run on generated 2 dimensional data with 0.2 noise and 300 points. The accuracy, loss, and euclidean diversity was tracked across 300 iterations. The experiment was run with the hyperparameter num_parents set to 0, 1, 2, 3, 5, and 10.\n",
    "\n",
    "<img src=\"images/Multi-Parent/MP_Generated_all_metrics_300_iter.png\" width=\"1500\" style=\"display:block; margin:auto;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca59e86",
   "metadata": {},
   "source": [
    "As seen in the above visualization, Loss and Accuracy were comparable across all quantities of parents, while diversity varied significantly. In particular, with num_parents set to 0 and to a lesser extent 1, diversity was much lower than all other quantities of parents. The accuracy of the 0 parent model also lagged behind the other models over more iterations. Without functioning parents, evolution is replaced by random chance, as the heritability, defined as a requirement for evolution by @Lewontin1970units, is eliminated. \n",
    "\n",
    "While this had a much smaller impact on this relatively simple experiment of generated data, the implications on a much more complex classification problem, such as MNIST, could be significant. \n",
    "\n",
    "##### MNIST Experiment:\n",
    "\n",
    "A similar experiment, performed on a subset 1000 images from the MNIST dataset was performed on num_parents = 0, 1, 2, 5, 10 over 1000 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94909bf",
   "metadata": {},
   "source": [
    "<img src=\"images/Multi-Parent/MP_MNIST_Charts.png\" width=\"1500\" style=\"display:block; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd046c",
   "metadata": {},
   "source": [
    "The benefits of inheritance are reaffirmed, as the 0 parent model has significantly higher loss and lower accuracy throughout the 1000 iterations. Additionally, the benefits of multi-parent inheritance are demonstrated by the declining improvement in accuracy when num_parents = 1. This makes sense given the lower diversity compared to the other models, and the importance of diversity in evolutionary algorithms in allowing for the exploration of the solution space. With lower diversity, the 1 parents model is less likely to find a global minimum. While it does find some form of a local minimum, the lack of diversity results in a drop off in improvement at around 600 iterations, while the models with 2, 5, and 10 parents continue to have spikes in improvement. \n",
    "\n",
    "In the context of classification of the MNIST dataset, evolutionary models benefit from the added diversity resulting from the use of larger quantities of parents contributing weights to each new child in the subsequent generation. While more computing power, and more iterations are required to truly optimize this hyperparameter, these experiments clearly demonstrate the benefits of multi-parent inheritance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e7fe4f",
   "metadata": {},
   "source": [
    "### Quantifying Diversity and Diversity-Based Loss:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b8e3b",
   "metadata": {},
   "source": [
    "This section evaluates the effect of diversity-aware loss functions in evolutionary training of a neural network classifier on a subset of the MNIST handwritten dataset. We experimented with four diversity metrics - Euclidean Distance, Cosine Dissimilarity, Standard Deviation (STD) and variance - and measured their influence on test accuracy, cross-entropy loss, and diversity levels in our weight population over 200 generations. Additional hyperparameter tuning was performed for the Cosine diversity metric to explore how mutation rate, mutation intensity, population size, and diversity coefficient influence outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0f1de",
   "metadata": {},
   "source": [
    "The first experiment (figure 1) compared the test accuracy, loss, and normalized diversity across all four diversity metrics under a fixed training setup. All metrics enabled the model to reach between 75%-81% accuracy over 200 generations, with all other hyperparameters held constant. euclidean distance and STD slightly outperformed others in final diversity. All methods reduced loss substantially within 60 generations. When it came to Normalized diversity, all metrics except for, interestingly, cosine dissimilarity between weight vectors increased/maintained high diversity over time. Cosine dissimilarity diversity rapidly decayed to near-zero within 100 generations, while STD, variance  and euclidean distance maintained high diversity levels, suggesting that cosine may be more prone to premature convergence or intrinsically mediates the impact of diverse weight populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b045d09",
   "metadata": {},
   "source": [
    "#### *Figure 1*\n",
    "\n",
    "<img src=\"images/NormalizeDiversity/output.png\" width=\"1500\" style=\"display:block; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471a804",
   "metadata": {},
   "source": [
    "To better understand the behavior of the cosine dissimilarity metric, we ran additional training with varied diversity coefficients, population sizes, and mutation hyperparameters. The default hyperparameters used were population size 50, mutation rate 0.4, mutation intensity 0.5 and diversity coefficient 0.1. Increasing the diversity coefficient to 0.3 (figure 4) significantly improved diversity values - up to 0.2 - over each generation, confirming that the penalty term has a regulating effect on population diversity. When the diversity coefficient was set to 0.0 (figure 3), the model still trained to reasonable accuracy but showed completely flat diversity values, indicating the diversity term is implemented correctly to at least affect our metric value. Increasing population size to 100 (figure 5) improved diversity over each generation, especially in the first 100 generations, but did not substantially improve test accuracy. This suggests diminishing returns from larger populations in this setting. Raising mutation rate to 0.7 and intensity to 0.8 (figure 6) had a negligible to slightly positive impact on accuracy while maintaining diversity at moderate levels. Accuracy did experience more noisiness under these conditions, but ultimately achieved reasonable levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0692e6d",
   "metadata": {},
   "source": [
    "#### *Figure 3*\n",
    "\n",
    "<img src=\"images/NormalizeDiversity/output2.png\" width=\"1500\" style=\"display:block; margin:auto;\" />\n",
    "\n",
    "#### *Figure 4*\n",
    "\n",
    "<img src=\"images/NormalizeDiversity/output4.png\" width=\"1500\" style=\"display:block; margin:auto;\" />\n",
    "\n",
    "#### *Figure 5*\n",
    "\n",
    "<img src=\"images/NormalizeDiversity/output3.png\" width=\"1500\" style=\"display:block; margin:auto;\" />\n",
    "\n",
    "#### *Figure 6*\n",
    "\n",
    "<img src=\"images/NormalizeDiversity/output5.png\" width=\"1500\" style=\"display:block; margin:auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbc49a",
   "metadata": {},
   "source": [
    "In summary, all four diversity metrics led to successful convergence and comparable final test accuracies, with euclidean distance and STD slightly ahead. Cosine dissimilarity driven diversity tends to descend quickly, requiring further parameter tuning to explore what it takes to keep diversity high. Enabling the diversity penalty to loss had a clear and measurable effect on both training behavior and final diversity levels, validating its implementation. Mutation and population hyperparameters affected convergence stability and final accuracy but had less influence than the choice of diversity metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c1878",
   "metadata": {},
   "source": [
    "This study was constrained by computational limitations, which restricted the breadth of hyperparameter combinations we could explore. In particular, both the population size and the number of generations were limited in order to keep training time feasible. Larger populations and longer training schedules could potentially yield more robust insights into the effects of diversity-aware loss function. Further investigation into the behavior of cosine dissimilarity is warranted. Across multiple experiments we observed a consistent decline in diversity when using this metric. One possible explanation for this is that cosine dissimilarity only measures angular differences between vectors, ignoring their magnitudes. As a result, the population may converge to a set of similarly oriented but differently scaled vectors, which could be interpreted as low diversity by this metric. This limitation could implicitly constrain the optimizer’s ability to maintain variation during training, and future work could test this hypothesis more directly or explore hybrid metrics that include both angular and magnitude components. Additionally, we were limited in the size of training and test batches, which may influence generalization performance. It would be valuable to evaluate how increasing batch size or dataset subset size impact both diversity value and resulting model accuracy. Please note, all of these experiementes were run on a hybridized version of the evolution optimized DNNs which included, for every step of training one gradient descent step on each weight vector. This was done in hopes to reduce runtimes without straying too far from pure evolution. Pure evolution, we speculated, would have needed to require high data inputs, generation numbers, and population sizes to produce valuable results, which did not fit the computational capacities of our computers, nor our time constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00dbbd2",
   "metadata": {},
   "source": [
    "### Mutation Methods:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141ef80",
   "metadata": {},
   "source": [
    "### Final MNIST Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5151adf",
   "metadata": {},
   "source": [
    "# Concluding Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d92e9",
   "metadata": {},
   "source": [
    "# Group Contributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5567652",
   "metadata": {},
   "source": [
    "### Jiffy: \n",
    "\n",
    "For this project, I contributed to both the conceptual development and the technical implementation of our evolutionary optimization framework. Early in the project, I created a demo notebook (evolution_demo_warmup.ipynb) that introduced the basic principles of evolutionary algorithms using synthetic data, aiming to outline a clear conceptual framework of evolution’s purpose and potential in our project. I was primarily responsible for implementing and optimizing the diversity-aware loss framework, including vectorized versions of the Euclidean distance and cosine dissimilarity metrics, as well as additional metrics based on standard deviation and variance. I added support for toggling these metrics and integrating them into the final loss calculation. I also extended our codebase to support multiclass classification, enabling us to apply our models to the MNIST dataset. Much of my experimentation involved running classification trials with varying diversity metrics and hyperparameters - mutation rate, intensity, and diversity coefficient - which I documented in a jupyter notebook (ExploringDiversity.ipynb). I wrote an initial training logic and data loading code for MNIST, and developed visualization tools using matplotlib to track accuracy, loss, and diversity across generations. I also implemented the hybrid optimization step, which combines evolution with gradient descent via backpropagation. For the final blog post, I focused on writing detailed technical explanations of the algorithmic components I implemented, along with reporting and analyzing the results of my experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a71cf",
   "metadata": {},
   "source": [
    "# Personal Reflection:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
